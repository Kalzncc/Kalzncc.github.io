{"meta":{"title":"Kalzn的个人博客","subtitle":"","description":"","author":"Kalzn","url":"http://Kalzncc.github.io","root":"/"},"pages":[{"title":"文章归档","date":"2022-11-20T07:23:09.203Z","updated":"2022-11-20T07:23:09.203Z","comments":true,"path":"archives.html","permalink":"http://kalzncc.github.io/archives.html","excerpt":"","text":""},{"title":"荧图","date":"2024-11-26T08:38:16.832Z","updated":"2024-11-26T08:38:16.832Z","comments":true,"path":"img_src.html","permalink":"http://kalzncc.github.io/img_src.html","excerpt":"","text":""}],"posts":[{"title":"B站同款可动头图做法⬆️","slug":"header_anime","date":"2024-11-27T13:49:00.000Z","updated":"2024-11-27T14:22:39.182Z","comments":true,"path":"2024/11/27/header_anime/","link":"","permalink":"http://kalzncc.github.io/2024/11/27/header_anime/","excerpt":"","text":"B站同款可动头图做法 背景 B站很久之前的头图都变成了可动的，感觉很漂亮，于是就想自己复现一下。但是本人并不是太会前端，所以也只能便摸索便搞。不过最终还是成功搞出来了，感觉效果还不错。 原理和准备 可动头图是由多个图层组合而来的，然后每个图层的位移不同，营造一种前后深度。这里我是用自设形象跑的AI，以下是原图。使用模型是自搭建的SD服务，模型是waiANINSFWPONYXL，骑扫帚融了Lora:riding_broom。然后还需要一个背景，背景也是用这个基模跑的。 然后利用PS抠图，将图片分出几个可动图层，注意这里要把背景弄成透明的，按照png格式保存。 动画 这里通过监听mouseenter,mousemove,mouseleave三者动作，具体而言： mouseenter当光标进入头图区域时，将过渡动画关闭，并记录进入时的横坐标，并开始计算光标相对进入时的坐标位移。 mousemove当光标在移动时，记录光标相对进入头图时的坐标位移，然后根据位移大小更新各个图层的位移大小。 mouseleave当光标退出头图区域时，将过渡动画打开，并将所有图层归为初始位置。 此外对每一个图层加入上下浮动的动画，并在人物跟随光标移动时加入旋转效果。 这里要注意的是，离镜头越远的图层的位移速度越小。 参考源码 12345678910&lt;div class=\"header_anime\" id=\"anime_area\"&gt; &lt;!-- 各图层 --&gt; &lt;img src=\"/static/pic/header_img/header_moutain.png\" class=\"header_moutain_block block\" id=\"header_div_mt\"/&gt; &lt;img src=\"/static/pic/header_img/bf3.png\" class=\"bf3_block block\" id=\"header_div_bf3\"/&gt; &lt;img src=\"/static/pic/header_img/bf2.png\" class=\"bf2_block block\" id=\"header_div_bf2\"/&gt; &lt;img src=\"/static/pic/header_img/witch.png\" class=\"fiska_block block\" id=\"header_div_fiska\"/&gt; &lt;img src=\"/static/pic/header_img/bf1.png\" class=\"bf1_block block\" id=\"header_div_bf1\"/&gt; &lt;img src=\"/static/pic/header_img/bf4.png\" class=\"bf4_block block\" id=\"header_div_bf4\"/&gt; &lt;/div&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125function set_block_position(rate, fullWidth) { fiska_block = document.getElementById(\"header_div_fiska\") bf1_block = document.getElementById(\"header_div_bf1\") bf2_block = document.getElementById(\"header_div_bf2\") bf3_block = document.getElementById(\"header_div_bf3\") bf4_block = document.getElementById(\"header_div_bf4\") back_m_block = document.getElementById(\"header_div_mt\") back_block = document.getElementById(\"anime_area\") if (rate == -1) { console.log(\"Heelo!!!\") switch_anime(true) fiska_block.style.left = (1.0 * fullWidth * 0.4) + 'px' fiska_block.style.transform = 'rotate(0deg)' bf1_block.style.left = (1.0 * fullWidth * 0.7) + 'px' bf2_block.style.left = (1.0 * fullWidth * 0.6) + 'px' bf3_block.style.left = (1.0 * fullWidth * 0.2) + 'px' bf4_block.style.left = (1.0 * fullWidth * 0.25) + 'px' back_block.style.backgroundPosition = '-100px -110px' back_m_block.style.left = '-120px' } else if (rate &lt; 0) { rate = -rate fiska_block.style.left = (1.0 * fullWidth * 0.4 * (1 - rate * 0.8)) + 'px' bf1_block.style.left = (1.0 * fullWidth * 0.7 * (1 - rate * 0.4)) + 'px' bf2_block.style.left = (1.0 * fullWidth * 0.6 * (1 - rate * 0.02)) + 'px' bf3_block.style.left = (1.0 * fullWidth * 0.2 * (1 - rate * 0.02)) + 'px' bf4_block.style.left = (1.0 * fullWidth * 0.25 * (1 - rate * 0.85)) + 'px' back_m_block.style.left = ((-120) - (rate * 30)) + 'px' back_block.style.backgroundPosition =(-100-(rate * 10)) + 'px -110px' if (rate &lt; 0.3) { fiska_block.style.transform = 'rotate(' + 40 * rate + 'deg)' } else { fiska_block.style.transform = 'rotate(' + 40 * 0.3 + 'deg)' } } else { fiska_block.style.left = (1.0 * fullWidth * (0.4 + (rate * 0.8) * 0.4)) + 'px' bf1_block.style.left = (1.0 * fullWidth * (0.7 + rate * 0.1)) + 'px' bf2_block.style.left = (1.0 * fullWidth * (0.6 + rate * 0.02)) + 'px' bf3_block.style.left = (1.0 * fullWidth * (0.2 + rate * 0.02)) + 'px' bf4_block.style.left = (1.0 * fullWidth * (0.25 + rate * 0.15)) + 'px' back_block.style.backgroundPosition = (-100 + (rate * 10)) + 'px -110px' back_m_block.style.left = ((-120) + (rate * 20)) + 'px' if (rate &lt; 0.3) { fiska_block.style.transform = 'rotate(' + -25 * rate + 'deg)' } else { fiska_block.style.transform = 'rotate(' + -25 * 0.3 + 'deg)' } }}function switch_anime(flag) { blocks = document.getElementsByClassName(\"block\") back_block = document.getElementById(\"anime_area\") if (flag) { for (var i = 0; i &lt; blocks.length; i++) { blocks[i].style.transition = 'left 0.5s ease-in-out 0.0s, transform 0.5s ease-in-out 0.0s' } back_block.style.transition = 'background-position 0.5s ease-in-out 0.0s' // fiska_block.style.transition = 'left 0.5s ease-in-out 0.0s, transform 0.5s ease-in-out 0.0s' // bf1_block.style.transition = 'left 0.5s ease-in-out 0.0s, transform 0.5s ease-in-out 0.0s' // bf1_block.style.transition = 'left 0.5s ease-in-out 0.0s, transform 0.5s ease-in-out 0.0s' } else { for (var i = 0; i &lt; blocks.length; i++) { blocks[i].style.transition = '' } back_block.style.transition = '' // fiska_block.style.transition = '' // bf1_block.style.transition = '' }}function header_anime() { var status = \"-out\" var enterX = 0 var enterY = 0 var curX = 0 var curY = 0 var inFlag = false const resizeObserver = new ResizeObserver(entries =&gt; { for (let entry of entries) { const { width, height } = entry.contentRect; set_block_position(0, width) } }); resizeObserver.observe(document.getElementById(\"anime_area\")) document.addEventListener('mousemove', function(event) { ani_div = document.getElementById(\"anime_area\") var text = 'Mouse position:' + event.clientX + \",\" + event.clientY + status curX = event.clientX curY = event.clientY if (!inFlag) return var curDivWith = ani_div.offsetWidth text += \" (Full Width \" + curDivWith + \") \" var movePx = curX - enterX if (movePx &lt; 0) { text += \" : Move &lt;- \" + (-movePx) } else { text += \" : Move -&gt; \" + (movePx) } left_block = document.getElementById(\"left_padding_block\") right_block = document.getElementById(\"right_padding_block\") var moveRate = 1.0 * movePx / curDivWith set_block_position(moveRate, curDivWith) document.getElementById(\"debug_info_area\").innerText = text }); document.getElementById(\"anime_area\").addEventListener('mouseenter', function(event) { enterX = curX enterY = curY switch_anime(false) console.log(\"in in pos: \" + enterX + \",\" + enterY) inFlag = true }) document.getElementById(\"anime_area\").addEventListener('mouseleave', function(event) { console.log(\"out\") inFlag = false ani_div = document.getElementById(\"anime_area\") var curDivWith = ani_div.offsetWidth set_block_position(-1, curDivWith) })}header_anime() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899.fiska_block { height: 120px; float: center; position: absolute; left: 200px; margin-top: 0px; margin-bottom: 0px; animation: floatBlock 10s infinite ease-in-out; }.bf1_block { height: 60px; float: center; position: absolute; left: 50px; margin-top: 0px; margin-bottom: 0px; animation: floatBlockBf 8s infinite ease-in-out; }.bf2_block { height: 70px; float: center; position: absolute; left: 480px; margin-top: 0px; margin-bottom: 0px; animation: floatBlockBf 13s infinite ease-in-out;}.bf3_block { height: 40px; float: center; position: absolute; left: 50px; margin-top: 0px; margin-bottom: 0px; animation: floatBlockBf 8s infinite ease-in-out;}.bf4_block { height: 170px; float: center; position: absolute; left: 50px; margin-top: 0px; margin-bottom: 0px; animation: floatBlockBf 8s infinite ease-in-out;}.header_moutain_block { height: 240px; float: center; position: relative; /* clip-path: inset(100px 0px); */ left: -90px; top: 0px; padding-top: 0px; margin-top: 0px; margin-bottom: 0px;}.header_anime { background-image: url('/static/pic/header_img/header_back.png'); background-size: cover; /* 背景图片覆盖整个元素 */ background-position: -100px -110px; /* 背景图片居中 */ background-repeat: no-repeat; /* 背景图片不重复 */ background-size: 125%; padding-bottom: 20px margin-bottom: 30px; border-radius: 16px; border: 3px solid rgb(23,44,54); display: flex; overflow: hidden; align-items: center; height: 120px; /* 使容器的高度为视口高度 */}@keyframes floatBlockBf { 0%, 100% { margin-top: 5px; margin-bottom: 0px; } 50% { margin-top: 0px; margin-bottom: 20px; }}@keyframes floatBlock { 0%, 100% { margin-top: 10px; margin-bottom: 0px; } 50% { margin-top: 0px; margin-bottom: 45px; }}","categories":[{"name":"项目","slug":"项目","permalink":"http://kalzncc.github.io/categories/%E9%A1%B9%E7%9B%AE/"}],"tags":[{"name":"置顶","slug":"置顶","permalink":"http://kalzncc.github.io/tags/%E7%BD%AE%E9%A1%B6/"},{"name":"工具","slug":"工具","permalink":"http://kalzncc.github.io/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"Csdn2Local:将csdn的博客保存到本地markdown格式","slug":"csdn2local","date":"2024-11-27T03:49:00.000Z","updated":"2024-11-27T03:52:02.625Z","comments":true,"path":"2024/11/27/csdn2local/","link":"","permalink":"http://kalzncc.github.io/2024/11/27/csdn2local/","excerpt":"","text":"CSDN2Local 一个帮助你将你自己的CSDN博客保存到本地markdown格式的脚本。方便博客归档和迁移。 使用教程 1.登录CSND 打开创作中心-&gt;内容管理 2.打开F12开发工具，并刷新界面 3.复制你的cookie，并将其保存到config.yaml的cookie字段中。 4.运行main.py 注意事项 只支持保存自己的CSDN博客哦。 配置文件 1234567891011121314# 按照readme中的指示找到你的cookie并保存于此cookie: ''# 文件保存的位置，工程有一个示例output_path: './articles'# 是否将图片一并保存到本地save_pic_to_local: true# 将文章meta信息写入到markdown的header部分markdown_header_meta: title: title categories: category postTime: date","categories":[{"name":"项目","slug":"项目","permalink":"http://kalzncc.github.io/categories/%E9%A1%B9%E7%9B%AE/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://kalzncc.github.io/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"软件工程与设计模式相关，Spring简介","slug":"se-dm","date":"2024-11-26T08:42:52.000Z","updated":"2024-11-26T08:50:20.823Z","comments":true,"path":"2024/11/26/se-dm/","link":"","permalink":"http://kalzncc.github.io/2024/11/26/se-dm/","excerpt":"","text":"软件工程与设计模式相关，Spring简介 1.编程思想 1.1 面向过程编程 面向过程编程（Procedural Programming）是一种以过程为中心的编程风格。在面向过程编程中，程序被分解为一系列的函数或过程，每个函数执行特定的任务。这种编程风格强调按照一定的顺序执行一系列步骤来解决问题。函数可以接受输入参数并返回输出结果。数据通常是通过参数传递给函数，而函数之间的通信是通过函数调用来实现。 优 直接、简单，易于学习和理解，尤其适合初学者。 可以提供较高的执行效率，因为它避免了面向对象编程中的一些额外开销。 更容易进行代码调试和测试，因为函数之间的依赖关系相对简单。 性能相较于面向对象，较好。 缺 随着项目规模的增大，代码可能变得难以维护和扩展。函数之间的依赖关系可能变得复杂，代码可读性可能下降。 全局变量的使用可能导致命名冲突和不可预测的副作用。 面向过程编程缺乏一些面向对象编程的高级特性，如封装、继承和多态，这些特性可以提高代码的组织性和重用性。 1.2 面向对象编程 面向对象(Object Oriented)是软件开发方法，一种编程范式。对现实世界抽象，将属性（数据）、行为（操作数据的函数或方法）封装成类。 优 提供了更好的组织性和可维护性，通过对象的封装、继承和多态等概念，使得程序更易于理解、扩展和重用。 支持代码的模块化开发，不同对象之间的耦合性较低，使得团队合作更加容易。 可以通过继承和多态实现代码的灵活性和可扩展性。 缺 面向对象编程的学习曲线相对较陡峭，对初学者来说可能需要更多的时间和精力来理解和掌握相关概念。 面向对象编程中的一些高级特性和设计模式可能会导致额外的开销和复杂性。 在某些情况下，面向对象编程可能会导致性能下降，尤其是当不恰当地使用继承和多态时。 1.2.1 面向对象编程三大特征 封装 通常认为封装是把数据和操作数据的方法封装起来，对数据的访问只能通过已定义的接口。 继承 继承是从已有类得到继承信息创建新类的过程。提供继承信息的类被称为父类（超类 /基类），得到继承信息的被称为子类（派生类）。 多态 分为编译时多态（方法重载）和运行时多态（方法重写）。要实现多态需要做两件事：⼀是子类继承父类并重写父类中的方法，⼆是用父类型引用子类型对象，这样同样的引用调用同样的方法就会根据子类对象的不同而表现出不同的行为。 方法重载 vs 方法重写 方法重载（Overload）发生在编译阶段，表现为在同一类中编写多个名称相同但参数不同的方法。方法重写（Override）发生在运行时，表现为父子类中同时编写多个名称、参数相同的方法。在运行时调用不同子类的不同的方法。 以JAVA语言为例，多态的实现利用运行时类型判定（RTTI）技术，它的作用是在我们不知道某个对象的确切的类型信息时（即某个对象是哪个类的实例），可以通过 RTTI 相关的机制帮助我们在编译时获取对象的类型信息。ps.此部分详细解释移步jvm.md。 面向过程编程 vs 面向对象编程 面向对象是⼀种基于面向过程的编程思想，是向现实世界模型的自然延伸，这是⼀种“ 万物皆对象”的编程思想。由执行者变为指挥者，在现实⽣活中的任何物体都可以归为⼀类事物，而每⼀个个体都是⼀类事物的实例。面向对象的编程是以对象为中心，以消息为驱动。 区别 组织方式：面向过程编程以函数为基本单位，按照一定的顺序和步骤解决问题；而面向对象编程以对象为基本单位，通过对象的属性和方法来解决问题，更强调数据和行为的封装。 数据处理：面向过程编程通常以过程为中心，通过处理数据来达到目标；而面向对象编程则将数据和相关的操作封装在对象中，通过对象之间的交互来处理数据。 代码复用：面向过程编程侧重于函数的重用，而面向对象编程侧重于对象的重用，通过继承、多态等机制实现代码的复用和扩展。 抽象和封装：面向对象编程具有更高的抽象能力，能够将真实世界的概念映射到程序设计中，通过类和对象的封装来表示问题领域的模型。 1.3 面向切面编程 面向切面编程（AOP）是一种软件开发范式，旨在通过横切关注点（cross-cutting concerns）的方式来解耦系统中的各个模块。横切关注点指的是那些不属于业务逻辑本身，但是会影响多个模块的代码，比如日志记录、事务管理、安全性等。 AOP的核心思想是将这些横切关注点从业务逻辑中分离出来，形成独立的切面（Aspect）。切面包含了横切关注点的代码，当程序执行到特定的点（切点）时，切面的代码就会被执行，从而实现了与业务逻辑的解耦。 1.3.1 原理 AOP通过在程序执行的不同阶段织入切面代码来实现其功能。织入（weaving）是指将切面代码与目标代码合并的过程。 有两种主要的织入方式：编译时织入和运行时织入。编译时织入是在程序编译的时候将切面代码织入目标代码中，而运行时织入则是在程序运行的时候动态地将切面代码织入目标代码中。 在AOP中，常见的概念还包括切点（Pointcut）、通知（Advice）、连接点（Joinpoint）等。切点定义了在何处执行切面代码，通知定义了切面代码的具体行为，连接点则是在程序执行过程中能够插入切面代码的点。 1.3.2 大白话？ 鉴于目前网上的文章都说得异常抽象，这里就用大白话过一遍。 意思就是说，有些时候我们希望在一组函数、方法或语句执行前都执行一段相同（相似）的代码，例如日志代码，鉴权代码等等。该怎么办呢？一个粗暴的方法就是在每次调用此函数/方法/语句之前都加上这一段代码。那这样会造成问题：模块之间的解耦过高，如果在每次调用之前都加上一段代码，那这段代码（或封装的模块）和整体得业务代码是高度耦合的（内容耦合），大大降低了工程的可维护性。而且如果在工程中期突然要求在某个函数/方法之前加入特定语句，那么这样一处处地修改代码异常繁琐，也违反了开闭原则。 所以AOP即使为了解决此问题。将我们需要运行的代码（切面 Aspect）动态的插入（切入）到指定的地方。 即在业务代码中设置切点（Pointcut），当运行到这些切点时，我们对程序进行拦截，然后通过通知（Advice） 来执行需要运行的代码。 1.3.3 名词解释 Joinpoint（连接点）：指业务中被拦截的点。 Pointcut（切入点）：指我们要对哪些 Joinpoint 进行拦截的定义。 连接点被增强了，它就变成切入点 提示：所有切入点都是连接点，但是，所有连接点不都是切入点。 Advice（翻译–建议，理解为增强可能好一点）：指拦截到 Joinpoint 之后所要做的事情就是建议。 这里建议分为：前置建议、后置建议、异常建议、最终建议、环绕建议。 Introduction（引进）: 引进是一种特殊的建议在不修改类代码的前提下, Introduction 可以在运行期为类动态地添加一些方法或 Field Target（目标）: 代理的目标对象。 Weaving（织入）: 是指把建议应用到目标对象来创建新的代理对象的过程。 Spring 采用动态代理织入，而 AspectJ 采用编译期织入和类装载期织入 Proxy（代理）: 一个类被 AOP 织入建议后，就产生一个结果代理类。 Aspect（切面）: 是切入点和建议（引进）的结合。 1.3.4 实现 利用预编译（编译阶段）和动态代理（运行阶段）的方式实现。详见下面章节有关代理模式（Proxy Pattern）的介绍。 2. 耦合与内聚 软件工程追求模块之间低耦合，模块内部高内聚。 2.1 耦合性 耦合性是指软件结构中模块相互连接的紧密程度，是模块间相互连接性的度量耦合强度的大小是由模块间接口的复杂程度决定的。 具体从三个方面衡量: ① 方式——块间联系方式由“直接引用”或“过程语句调用”。 ② 作用——块间传送的共用信息(参数)类型，可为“数据型”、“控制型”或“混合型” (数据/控制型) ③ 数量——块间传送的共用信息的数量。 内容耦合 一个模块直接访问另一模块的内部数据。 一个模块不通过正常入口转到另一模块的内部。 一个模块有多个入口。 两个模块有部分代码重迭。 内容耦合在高级语言尤其是面向对象语言中是不允许出现的。 公共耦合 若干模块访问一个公共的数据环境(全局数据结构、共享的通信区、内存的公共覆盖区等)。耦合的复杂程度随耦合模块的数量的增加而显著增加。 公共耦合的两种情况: 松散公共耦合: 模块同时只对公共数据环境进行读或写一种操作。（一个模块要么只读公共数据区，要么只写公共数据区。） 紧密公共耦合: 若干模块对公共数据环境同时读和写操作,这种耦合使公共数据区的变化影响所有公共耦合模块，严重影响模块的可靠性和可适应，降低软件的可读性。这是一种强耦合方式。 一般来说，仅当模块间共享的数据很多，且通过参数的传递很不方便时才使用公共耦合。 外部耦合 一组模块都访问同一全局简单变量（而不是同一全局数据结构），而且不是通过参数表传递该全局变量的信息。 外部耦合 vs 公共耦合？外部耦合是共享一个简单变量，而公共耦合是共享一个公共数据环境。 控制耦合 一个模块传递给另一模块的信息是用于控制该模块内部逻辑的控制信号。显然，对被控制模块的任何修改，都会影响控制模块。 如何改变？将控制信号转到上层函数中处理，即定义两个函数，一个计算平均分，一个计算最高分。然后在上层函数中按需调用不同函数。即可降低至数据耦合 标记耦合（特征耦合） 一个模块传送给另一个模块的参数是一个复合的数据结构。模块间共享了数据结构，如高级语言中的数组名、记录名等，其实传递的是这些数据结构的地址。标记耦合会使某些本来无关的模块产生相互依赖性，同时由于某些模块包含了不需要的数据，也给纠错带来了麻烦。 改进：只传该数据结构中所需要的字段，降级为数据耦合。 数据耦合 一个模块传送给另一个模块的参数是一个单个的数据项或者单个数据项组成的数组。模块间传递的是简单的数据值，相当于高级语言中的值传递。 非直接耦合 两个模块间没有直接的关系，它们分别从属于不同模块的控制与调用，它们之间不传递任何信息。这种耦合程度最弱，模块的独立性最高。 2.2 内聚性 内聚性表示一个模块内部各个元素(数据、处理)之间联系的紧密程度。显然,块内联系愈紧,即内聚性愈高，模块独立性愈好。 偶然内聚 又称为巧合型，为了节约空间，将毫无关系( 或者联系不多)的各元素放在一个模块中。模块元素关系松散，显然不易理解、不易修改。 逻辑内聚 将几个逻辑上相似的功能放在一个模块中，使用时由调用模块传递的参数确定执行的功能。由于要传递控制参数，所以影响了模块的内聚性。如果二者之间是控制耦合，那么被调用模块就是逻辑内聚型的模块。 时间内聚 又称为经典内聚。是把需要同时执行的成分放在一个模块中。比如初始化、中止操作这一类内部结构比较简单的模块。由于判定较少，因此比逻辑内聚高，但是由于内含多个功能，修改和维护困难。 过程内聚 一个模块内的处理元素是相关的，而且必须以特定的次序执行。 通信内聚 模块中的成分引用共同的输入数据，或者产生相同的输出数据，则称为是通信内聚。 顺序内聚 一个模块内的处理元素都密切相关于同一功能，模块中某个成分的输出是另一成分的输入。由于这类模块是按数据执行顺序,模块的一部分依赖于另外一部分,因此具有较好的内聚性。 功能内聚 一个模块包括而且仅包括完成某一具体功能所必须的所有成分。或者说，模块的所有成分都是为完成该功能而协同工作、紧密联系、不可分割的。 3. 设计模式 设计模式是一套被反复使用的、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。 毫无疑问，设计模式于己于他人于系统都是多赢的，设计模式使代码编制真正工程化，设计模式是软件工程的基石，如同大厦的一块块砖石一样。项目中合理地运用设计模式可以完美地解决很多问题，每种模式在现实中都有相应的原理来与之对应，每种模式都描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案，这也是设计模式能被广泛应用的原因。 根据设计模式的参考书 Design Patterns - Elements of Reusable Object-Oriented Software（中文译名：设计模式 - 可复用的面向对象软件元素） 中所提到的，总共有 23 种设计模式。这些模式可以分为三大类：创建型模式（Creational Patterns）、结构型模式（Structural Patterns）、行为型模式（Behavioral Patterns）。当然，我们还会讨论另一类设计模式：J2EE 设计模式。 3.1 设计模型七大原则 3.1.1 开放-封闭原则（开闭原则） 开闭原则(Open-Closed Principle, OCP)：一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。 注意事项 1.通过接口或者抽象类约束扩展，对扩展进行边界限定，不允许出现在接口或抽象类中不存在的public方法。 2.参数类型、引用对象尽量使用接口或者抽象类，而不是实现类 3.抽象层尽量保持稳定，一旦确定不允许修改。 介绍 1）开闭原则（Open Closed Principle）是编程中最基础、最重要的设计原则 2）一个软件实体如类，模块和函数应该对扩展开放（对提供方），对修改关闭（对使用方）。用抽象构建框架，用实现扩展细节。 3）当软件需要变化时，尽量通过扩展软件实体的行为来实现变化，而不是通过修改已有的代码来实现变化。 4）编程中遵循其它原则，以及使用设计模式的目的就是遵循开闭原则。 3.1.2 单一职责原则 单一职责原则(Single Responsibility Principle, SRP)：一个类只负责一个功能领域中的相应职责，或者可以定义为：就一个类而言，应该只有一个引起它变化的原因。 3.1.3 依赖倒转原则 依赖倒转原则(Dependency Inversion Principle, DIP)：抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。 注意事项 高层模块不应该依赖于低层模块。两个都应该依赖抽象。 抽象不应该依赖结节。细节应依赖于抽象。 依赖倒转（倒置）的中心思想是面向接口编程 依赖倒转原则是基于这样的设计理念：相对于细节的多变性，抽象的东西要稳定的多。以抽象为基础搭建的架构比以细节为基础的架构要稳定的多。在java中，抽象指的是接口或抽象类，细节就是具体的实现类。 使用接口或抽象类的目的是制定好规范，而不涉及任何具体的操作，把展现细节的任务交给他们的实现类去完成。 3.1.4 迪米特法则（最小知识原则） 迪米特法则(Law of Demeter, LoD)：一个软件实体应当尽可能少地与其他实体发生相互作用。 一个软件实体应当尽可能的少与其他实体发生相互作用。每一个软件单位对其他软件单位都只有最少的知识，而且局限于那些与本单位密切相关的软件单位。迪米特法则的初衷在于降低类之间的耦合。由于每个类尽量减少对其他类的依赖，因此，很容易使得系统的功能模块功能独立，相互之间不存在（或很少有）依赖关系。迪米特法则不希望类之间建立直接的联系。如果有真的需要建立联系的，也希望能通过他的友元类来转达。因此，应用迪米特法则有可能造成一个后果就是：系统中存在大量的中介类，这些类之所以存在完全是为了传递类之间的相互关系，这在一定程度上增加了系统的复杂度。 即一个类对自己依赖的类知道的越少越好。也就是说，对于被依赖的类不管多少复杂，都尽量将逻辑封装在类的内部。对外除了提供的public 方法，不对外泄露任何信息。 3.1.5 接口隔离原则 接口隔离原则(Interface Segregation Principle, ISP)：使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。 3.1.6 合成/聚合复用原则 合成/聚合复用原则经常又叫做合成复用原则，就是在一个新的对象里面使用一些已有的对象，使之成为新对象的一部分，新的对象通过这些对象的委派达到复用已有功能的目的。他的设计原则是：要尽量使用合成/聚合，尽量不要使用继承。 3.1.7 里氏代换原则 里氏代换原则(Liskov Substitution Principle, LSP)：所有引用基类（父类）的地方必须能透明地使用其子类的对象。 里氏代换原则是面向对象设计的基本原则之一。即任何基类可以出现的地方，子类一定可以出现。里氏代换原则是继承复用的基石，只有当衍生类可以替换掉基类，软件单位的功能不受影响时，基类才能被真正复用，而衍生类也能够在积累的基础上增加新的行为，里氏代换原则是对“开-闭”原则的补充。实现“开-闭”原则的关键步骤就是抽象化。在基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。 3.2 创建型模式 这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。 下面只给简介了，设计模式具体介绍：设计模式简谈-CSDN博客。这篇博客非常详细。 其中例子我都进行了简化，只截取了与该模式最相关的部分，向查看更详细的例子请去上面的博客。 3.2.1 工厂模式（Factory Pattern） 在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。 简介：定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行。 主要解决：主要解决接口选择的问题。 何时使用：我们明确地计划不同条件下创建不同实例时。 如何解决：让其子类实现工厂接口，返回的也是一个抽象的产品。 关键代码：创建过程在其子类执行。 应用实例： 1、您需要一辆汽车，可以直接从工厂里面提货，而不用去管这辆汽车是怎么做出来的，以及这个汽车里面的具体实现。 2、Hibernate 换数据库只需换方言和驱动就可以。 优点： 1、一个调用者想创建一个对象，只要知道其名称就可以了。 2、扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以。 3、屏蔽产品的具体实现，调用者只关心产品的接口。 缺点：每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。这并不是什么好事。 使用场景： 1、日志记录器：记录可能记录到本地硬盘、系统事件、远程服务器等，用户可以选择记录日志到什么地方。 2、数据库访问，当用户不知道最后系统采用哪一类数据库，以及数据库可能有变化时。 3、设计一个连接服务器的框架，需要三个协议，\"POP3\"、\"IMAP\"、\"HTTP\"，可以把这三个作为产品类，共同实现一个接口。 注意事项：作为一种创建类模式，在任何需要生成复杂对象的地方，都可以使用工厂方法模式。有一点需要注意的地方就是复杂对象适合使用工厂模式，而简单对象，特别是只需要通过 new 就可以完成创建的对象，无需使用工厂模式。如果使用工厂模式，就需要引入一个工厂类，会增加系统的复杂度。 例如，利用工厂从&lt;name&gt;$&lt;school&gt;的模式字符串种创建出Person。 12345678910111213141516171819202122// 需要创建的类public class Person { public String name, school; public Person(String name, String school) { this.name = name; this.school = school; }}// 工厂类public class PersonFactory { public static Person createPersonFromPatternString(String pattern) { String[] pString = pattern.split(\"$\"); return new Person(pString[0], pString[1]); }}// 调用工厂类创建Person对象String personString = \"Alice$UCAS\"Person person = PersonFactory.createPersonFromPatternString(personString); 3.2.2 抽象工厂模式（Abstract Factory Pattern） 抽象工厂模式（Abstract Factory Pattern）是围绕一个超级工厂创建其他工厂。该超级工厂又称为其他工厂的工厂。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 在抽象工厂模式中，接口是负责创建一个相关对象的工厂，不需要显式指定它们的类。每个生成的工厂都能按照工厂模式提供对象。 意图：提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。 主要解决：主要解决接口选择的问题。 何时使用：系统的产品有多于一个的产品族，而系统只消费其中某一族的产品。 如何解决：在一个产品族里面，定义多个产品。 关键代码：在一个工厂里聚合多个同类产品。 应用实例：工作了，为了参加一些聚会，肯定有两套或多套衣服吧，比如说有商务装（成套，一系列具体产品）、时尚装（成套，一系列具体产品），甚至对于一个家庭来说，可能有商务女装、商务男装、时尚女装、时尚男装，这些也都是成套的，即一系列具体产品。假设一种情况（现实中是不存在的，要不然，没法进入共产主义了，但有利于说明抽象工厂模式），在您的家中，某一个衣柜（具体工厂）只能存放某一种这样的衣服（成套，一系列具体产品），每次拿这种成套的衣服时也自然要从这个衣柜中取出了。用 OOP 的思想去理解，所有的衣柜（具体工厂）都是衣柜类的（抽象工厂）某一个，而每一件成套的衣服又包括具体的上衣（某一具体产品），裤子（某一具体产品），这些具体的上衣其实也都是上衣（抽象产品），具体的裤子也都是裤子（另一个抽象产品）。 优点：当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。 缺点：产品族扩展非常困难，要增加一个系列的某一产品，既要在抽象的 Creator 里加代码，又要在具体的里面加代码。 使用场景： 1、QQ 换皮肤，一整套一起换。 2、生成不同操作系统的程序。 注意事项：产品族难扩展，产品等级易扩展。 1234567891011121314151617181920212223242526272829303132// 需要创建的类public class Person { public String name, school; public Person(String name, String school) { this.name = name; this.school = school; }}// 抽象工厂public abstract class PersonFactory { public static Person createPersonFromPatternString(String pattern);}// $分隔符工厂public class DollarSplitPersonFactory extends PersonFactory{ @Override public static Person createPersonFromPatternString(String pattern) { String[] pString = pattern.split(\"$\"); return new Person(pString[0], pString[1]); }}// #分隔符工厂public class PoundSplitPersonFactory extends PersonFactory{ @Override public static Person createPersonFromPatternString(String pattern) { String[] pString = pattern.split(\"#\"); return new Person(pString[0], pString[1]); }} 3.2.3 单例模式（Singleton Pattern） 单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。 注意 1、单例类只能有一个实例。 2、单例类必须自己创建自己的唯一实例。 3、单例类必须给所有其他对象提供这一实例。 123456789101112131415// 单例Monitor类public class Moniter { private static Moniter moniter; public static Moniter getMoniter() { if (moniter != null) { return moniter; } else { moniter = new Moniter(); return moniter;} }}// 获取MonitorMonitor monitor = Moniter.getMonitor(); 3.2.4 建造者模式（Builder Pattern） 建造者模式（Builder Pattern）使用多个简单的对象一步一步构建成一个复杂的对象。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 意图：将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示。 主要解决：主要解决在软件系统中，有时候面临着\"一个复杂对象\"的创建工作，其通常由各个部分的子对象用一定的算法构成；由于需求的变化，这个复杂对象的各个部分经常面临着剧烈的变化，但是将它们组合在一起的算法却相对稳定。 何时使用：一些基本部件不会变，而其组合经常变化的时候。 如何解决：将变与不变分离开。 关键代码：建造者：创建和提供实例，导演：管理建造出来的实例的依赖关系。 应用实例： 1、去肯德基，汉堡、可乐、薯条、炸鸡翅等是不变的，而其组合是经常变化的，生成出所谓的\"套餐\"。 2、JAVA 中的 StringBuilder。 优点： 1、建造者独立，易扩展。 2、便于控制细节风险。 缺点： 1、产品必须有共同点，范围有限制。 2、如内部变化复杂，会有很多的建造类。 使用场景： 1、需要生成的对象具有复杂的内部结构。 2、需要生成的对象内部属性本身相互依赖。 注意事项：与工厂模式的区别是：建造者模式更加关注与零件装配的顺序。 123456789101112131415161718192021222324252627282930// 要build的类public class ColorList { private List&lt;String&gt; colors; public ColorList(List&lt;String&gt; colors) { this.colors = colors; }}// builderpublic class ColorListBuilder { List&lt;String&gt; colors; public ColorListBuilder() { colors = new ArrayList&lt;&gt;(); } public ColorListBuilder addRed() { colors.add(\"red\"); return this; } public ColorListBuilder addGreen() { colors.add(\"green\"); return this; } public ColorList build() { return new ColorList(colors); }}// 调用builder一步步构建出类ColorListBuilder builder = new ColorListBuilder();ColorList colorList = builder.addGreen().addRed().addGreen().build(); 3.2.5 原型模式（Prototype Pattern） 原型模式（Prototype Pattern）是用于创建重复的对象，同时又能保证性能。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。这种模式是实现了一个原型接口，该接口用于创建当前对象的克隆。当直接创建对象的代价比较大时，则采用这种模式。 意图：用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。 主要解决：在运行期建立和删除原型。 何时使用： 1、当一个系统应该独立于它的产品创建，构成和表示时。 2、当要实例化的类是在运行时刻指定时，例如，通过动态装载。 3、为了避免创建一个与产品类层次平行的工厂类层次时。 4、当一个类的实例只能有几个不同状态组合中的一种时。建立相应数目的原型并克隆它们可能比每次用合适的状态手工实例化该类更方便一些。 如何解决：利用已有的一个原型对象，快速地生成和原型对象一样的实例。 关键代码： 1、实现克隆操作，在 JAVA 继承 Cloneable，重写 clone()，在 .NET 中可以使用 Object 类的 MemberwiseClone() 方法来实现对象的浅拷贝或通过序列化的方式来实现深拷贝。 2、原型模式同样用于隔离类对象的使用者和具体类型（易变类）之间的耦合关系，它同样要求这些\"易变类\"拥有稳定的接口。 应用实例： 1、细胞分裂。 2、JAVA 中的 Object clone() 方法。 优点： 1、性能提高。 2、逃避构造函数的约束。 缺点： 1、配备克隆方法需要对类的功能进行通盘考虑，这对于全新的类不是很难，但对于已有的类不一定很容易，特别当一个类引用不支持串行化的间接对象，或者引用含有循环结构的时候。 2、必须实现 Cloneable 接口。 使用场景： 1、资源优化场景。 2、类初始化需要消化非常多的资源，这个资源包括数据、硬件资源等。 3、性能和安全要求的场景。 4、通过 new 产生一个对象需要非常繁琐的数据准备或访问权限，则可以使用原型模式。 5、一个对象多个修改者的场景。 6、一个对象需要提供给其他对象访问，而且各个调用者可能都需要修改其值时，可以考虑使用原型模式拷贝多个对象供调用者使用。 7、在实际项目中，原型模式很少单独出现，一般是和工厂方法模式一起出现，通过 clone 的方法创建一个对象，然后由工厂方法提供给调用者。原型模式已经与 Java 融为浑然一体，大家可以随手拿来使用。 注意事项：与通过对一个类进行实例化来构造新对象不同的是，原型模式是通过拷贝一个现有对象生成新对象的。浅拷贝实现 Cloneable，重写clone()，深拷贝是通过实现 Serializable 读取二进制流。 12345678910111213141516171819202122232425// 需要原型管理的类public class Monitor implements Cloneable{ // ... @Override public Object clone() { }}// 原型管理器public class MonitorManager { private static Map&lt;String, Monitor&gt; monitors = new ConcurrentHashMap&lt;&gt;(); public static Monitor getMonitor(String id) { if (!monitors.containsKey(id)) { monitors.put(id, new Monitor()); } return (Monitor) monitors.get(id).clone(); }}// 获取MonitorMonitor monitor1 = MonitorManager.getMonitor(\"1\");Monitor monitor2 = MonitorManager.getMonitor(\"2\");// 第二次获取id=1的monitor直接复制原有对象Monitor monitor3 = MonitorManager.getMonitor(\"1\"); 工厂模式 vs 抽象工厂模式 vs 建造者模式 三者均使用一个外部类完成一个类的构建，其中建造者模式强调建造的顺序，逐步建造出对象。而工厂模式通常是一次性建立出整个完整可用的对象。 实践中似乎工厂模式常常使用静态方法？ 123456// 建造者模式逐步建立起newObjNewObject newObj = new NewObjectBuilder().addConfigA().addConfigB().build();// 工厂模式一次性建立出一个可用对象NewObject newObj = NewObjectFactory.createNewObject(configA, configB); 抽象工厂模式在工厂模式的基础上新增一层抽象工厂层，工厂类继承抽象工厂。抽象工厂声明了一个相似产品族的创建方式。利用抽象工厂模式可以完成一个产品族的创建。 原型模式 vs 单例模式 两者均是一种依靠已经创建好的对象创建新的对象的方式。 原型模式在首次创建出一个对象后，再次请求创建对象时使用Clone方式将一个创建好的对象clone一份，返回clone后的新对象。 单例模式在首次请求创建对象时创建一个新的对象，此后再次请求该对象时仅返回创建好的对象的引用。 原型模式创建了同一个对象的多个副本，单例模式从始至终只有一个对象和多个引用。 3.3 结构型模式 3.3.1 适配器模式 适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。 意图：将一个类的接口转换成客户希望的另外一个接口。适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。 主要解决：主要解决在软件系统中，常常要将一些\"现存的对象\"放到新的环境中，而新环境要求的接口是现对象不能满足的。 何时使用： 1、系统需要使用现有的类，而此类的接口不符合系统的需要。 2、想要建立一个可以重复使用的类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作，这些源类不一定有一致的接口。 3、通过接口转换，将一个类插入另一个类系中。（比如老虎和飞禽，现在多了一个飞虎，在不增加实体的需求下，增加一个适配器，在里面包容一个虎对象，实现飞的接口。） 如何解决：继承或依赖（推荐）。 关键代码：适配器继承或依赖已有的对象，实现想要的目标接口。 应用实例： 1、美国电器 110V，中国 220V，就要有一个适配器将 110V 转化为 220V。 2、JAVA JDK 1.1 提供了 Enumeration 接口，而在 1.2 中提供了 Iterator 接口，想要使用 1.2 的 JDK，则要将以前系统的 Enumeration 接口转化为 Iterator 接口，这时就需要适配器模式。 3、在 LINUX 上运行 WINDOWS 程序。 4、JAVA 中的 jdbc。 优点： 1、可以让任何两个没有关联的类一起运行。 2、提高了类的复用。 3、增加了类的透明度。 4、灵活性好。 缺点： 1、过多地使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是 A 接口，其实内部被适配成了 B 接口的实现，一个系统如果太多出现这种情况，无异于一场灾难。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构。 2.由于 JAVA 至多继承一个类，所以至多只能适配一个适配者类，而且目标类必须是抽象类。 使用场景：有动机地修改一个正常运行的系统的接口，这时应该考虑使用适配器模式。 注意事项：适配器不是在详细设计时添加的，而是解决正在服役的项目的问题。 例如，现在有两个接口： 12345678public interface Drawable { public void draw(String graphType);}public interface BarDrawable { public void drawGreenBar(); public void drawRedBar();} 显然两者虽然很相似，但是无法兼容，如果我们想让BarDrawable的实现也支持Drawable接口，那么最好的办法就是新增一个适配器类。 1234567891011121314public class BarDrawableAapter implements Drawable { private BarDrawable barDrawer; public BarDrawableAapter (BarDrawable barDrawer) { this.barDrawer = barDrawer; } @Override public void draw(String graphType) { if (\"green_bar\".equals(graphType)) { barDrawer.drawGreenBar(); } else if (\"red_bar\".equals(graphType)) { barDrawer.drawRedBar(); } }} 可见，适配器BarDrawableAapter实现了需要兼容的接口Drawable，并将需要被兼容的接口BarDrawable包装起来，对外提供Drawable，这使得BarDrawable对外提供出Drawable接口。完成Drawable对BarDrawable的兼容。 3.3.2 桥接模式 桥接（Bridge）是用于把抽象化与实现化解耦，使得二者可以独立变化。这种类型的设计模式属于结构型模式，它通过提供抽象化和实现化之间的桥接结构，来实现二者的解耦。 这种模式涉及到一个作为桥接的接口，使得实体类的功能独立于接口实现类。这两种类型的类可被结构化改变而互不影响。 ** 意图**：将抽象部分与实现部分分离，使它们都可以独立的变化。 主要解决：在有多种可能会变化的情况下，用继承会造成类爆炸问题，扩展起来不灵活。 何时使用：实现系统可能有多个角度分类，每一种角度都可能变化。 如何解决：把这种多角度分类分离出来，让它们独立变化，减少它们之间耦合。 关键代码：抽象类依赖实现类。 应用实例： 1、猪八戒从天蓬元帅转世投胎到猪，转世投胎的机制将尘世划分为两个等级，即：灵魂和肉体，前者相当于抽象化，后者相当于实现化。生灵通过功能的委派，调用肉体对象的功能，使得生灵可以动态地选择。 2、墙上的开关，可以看到的开关是抽象的，不用管里面具体怎么实现的。 优点： 1、抽象和实现的分离。 2、优秀的扩展能力。 3、实现细节对客户透明。 缺点：桥接模式的引入会增加系统的理解与设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程。 使用场景： 1、如果一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性，避免在两个层次之间建立静态的继承联系，通过桥接模式可以使它们在抽象层建立一个关联关系。 2、对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用。 3、一个类存在两个独立变化的维度，且这两个维度都需要进行扩展。 注意事项：对于两个独立变化的维度，使用桥接模式再适合不过了。 个人感觉桥接模式主要应用于回调高层模块的解偶 例如，让一个任务执行器TaskExecutor在执行完任务后通知视图View，写成这样： 1234567891011121314151617181920// 视图public class View { public void accept() { // ... }}// 任务执行器public class TaskExecutor { public View view; public TaskExecutor(View view) { this.view = view; } public void execute() { // Execute task...... // 任务完成后提交给view view.accept(); }} 但是这么写存在很大问题，因为视图View一般都是高层模组，这么写无疑使得底层模块依赖了高层模块。所以这里利用接口进行桥接， 将抽象accpet方法和View的具体实现进行分离。 1234567891011121314151617181920212223242526// 提交接口public interface Acceptable { public void accept();} // 视图public class Viewer implements Acceptable { @Override public void accept() { // ... }}// 任务执行器public class TaskExecutor { public Acceptable view; public TaskExecutor(Acceptable view) { this.view = view; } public void execute() { // Execute task...... // 任务完成后提交给view view.accept(); }} 3.3.3 过滤器模式 过滤器模式（Filter Pattern）或标准模式（Criteria Pattern）是一种设计模式，这种模式允许开发人员使用不同的标准来过滤一组对象，通过逻辑运算以解耦的方式把它们连接起来。这种类型的设计模式属于结构型模式，它结合多个标准来获得单一标准。 似乎还有约束器模式这一称谓？ 1234567891011121314151617181920212223242526public class Person { private String name; private int sex; private int age; // getter, setter 方法}// 设置一个抽象过滤器public interface PersonFilter { public List&lt;Person&gt; filter(Collection&lt;Person&gt; persons);}// 实现一个性别过滤器，保留女性。public class FemaleFilter implements PersonFilter{ @Override public List&lt;Person&gt; filter(Collection&lt;Person&gt; persons) { List&lt;Person&gt; filteredPersons = new ArrayList&lt;&gt;(); for (Person person : persons) { if (person.getSex() == 0) continue; filteredPersons.add(person); } return filteredPersons; }} 3.3.4 组合模式 组合模式（Composite Pattern），又叫部分整体模式，是用于把一组相似的对象当作一个单一的对象。组合模式依据树形结构来组合对象，用来表示部分以及整体层次。这种类型的设计模式属于结构型模式，它创建了对象组的树形结构。 意图：将对象组合成树形结构以表示\"部分-整体\"的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。 主要解决：它在我们树型结构的问题中，模糊了简单元素和复杂元素的概念，客户程序可以像处理简单元素一样来处理复杂元素，从而使得客户程序与复杂元素的内部结构解耦。 何时使用： 1、您想表示对象的部分-整体层次结构（树形结构）。 2、您希望用户忽略组合对象与单个对象的不同，用户将统一地使用组合结构中的所有对象。 如何解决：树枝和叶子实现统一接口，树枝内部组合该接口。 关键代码：树枝内部组合该接口，并且含有内部属性 List，里面放 Component。 应用实例： 1、算术表达式包括操作数、操作符和另一个操作数，其中，另一个操作数也可以是操作数、操作符和另一个操作数。 2、在 JAVA AWT 和 SWING 中，对于 Button 和 Checkbox 是树叶，Container 是树枝。 优点： 1、高层模块调用简单。 2、节点自由增加。 缺点：在使用组合模式时，其叶子和树枝的声明都是实现类，而不是接口，违反了依赖倒置原则。 使用场景：部分、整体场景，如树形菜单，文件、文件夹的管理。 例子中是国家三级行政区的表示： 1234567891011121314151617181920212223public class Region { public static final int PROVINCE_LEVEL = 0; public static final int CITY_LEVEL = 1; public static final int COUNTY_LEVEL = 2; private int level; private String name; private List&lt;Region&gt; subRegions; public Region(int level, String name, List&lt;Region&gt; subRegions) { //...... } // getter, setter方法}// 创建：山东-青岛-{市南区，崂山区}的层级关系Region shinan = new Region(Region.COUNTY_LEVEL, \"市南区\", null);Region laoshan = new Region(Region.COUNTY_LEVEL, \"崂山区\", null);List&lt;Region&gt; qingdaoSub = new ArrayList&lt;&gt;();qingdaoSub.add(shinan);qingdaoSub.add(laoshan);Region qingdao = new Region(Region.CITY_LEVEL, \"青岛\", qingdaoSub);List&lt;Region&gt; shandongSub = new ArrayList&lt;&gt;();shandongsub.add(qingdao);Region shandong = new Region(Region.PROVINCE_LEVEL, \"山东\", shandongsub); 3.3.5 装饰器模式 装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。这种类型的设计模式属于结构型模式，它是作为现有的类的一个包装。 这种模式创建了一个装饰类，用来包装原有的类，并在保持类方法签名完整性的前提下，提供了额外的功能。 意图：动态地给一个对象添加一些额外的职责。就增加功能来说，装饰器模式相比生成子类更为灵活。 主要解决：一般的，我们为了扩展一个类经常使用继承方式实现，由于继承为类引入静态特征，并且随着扩展功能的增多，子类会很膨胀。 何时使用：在不想增加很多子类的情况下扩展类。 如何解决：将具体功能职责划分，同时继承装饰者模式。 关键代码： 1、Component 类充当抽象角色，不应该具体实现。 2、修饰类引用和继承 Component 类，具体扩展类重写父类方法。 应用实例： 1、孙悟空有 72 变，当他变成\"庙宇\"后，他的根本还是一只猴子，但是他又有了庙宇的功能。 2、不论一幅画有没有画框都可以挂在墙上，但是通常都是有画框的，并且实际上是画框被挂在墙上。在挂在墙上之前，画可以被蒙上玻璃，装到框子里；这时画、玻璃和画框形成了一个物体。 优点：装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能。 缺点：多层装饰比较复杂。 使用场景： 1、扩展一个类的功能。 2、动态增加功能，动态撤销。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public interface Singable { public void sing();}// 歌手唱歌public class Singer implements Singable { public void sing() { // }}// 抽象歌手装饰器类public abstract class SingerDecorator implements Singable { private Singable singer; public SingerDecorator(Singable singer) { this.singer = singer; } public void sing() { singer.sing(); }}// 实现一个装饰器类，使得唱歌后还要跳舞public class SingerDanceDecorator extends SingerDecorator { public SingerDanceDecorator(Singable singer) { super(singer); } private void dance() { // ... } public void sing() { super.sing(); dance(); }}Singable singer = new Singer();Singable decorator = new SingerDanceDecorator(singer);// 歌手只会唱歌singer.sing();// 通过修饰器后，歌手唱歌并跳舞decorator.sing(); 3.3.6 外观模式 外观模式（Facade Pattern）隐藏系统的复杂性，并向客户端提供了一个客户端可以访问系统的接口。这种类型的设计模式属于结构型模式，它向现有的系统添加一个接口，来隐藏系统的复杂性。 这种模式涉及到一个单一的类，该类提供了客户端请求的简化方法和对现有系统类方法的委托调用。 意图：为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。 主要解决：降低访问复杂系统的内部子系统时的复杂度，简化客户端之间的接口。 何时使用： 1、客户端不需要知道系统内部的复杂联系，整个系统只需提供一个\"接待员\"即可。 2、定义系统的入口。 如何解决：客户端不与系统耦合，外观类与系统耦合。 关键代码：在客户端和复杂系统之间再加一层，这一层将调用顺序、依赖关系等处理好。 应用实例： 1、去医院看病，可能要去挂号、门诊、划价、取药，让患者或患者家属觉得很复杂，如果有提供接待人员，只让接待人员来处理，就很方便。 2、JAVA 的三层开发模式。 优点： 1、减少系统相互依赖。 2、提高灵活性。 3、提高了安全性。 缺点：不符合开闭原则，如果要改东西很麻烦，继承重写都不合适。 使用场景： 1、为复杂的模块或子系统提供外界访问的模块。 2、子系统相对独立。 3、预防低水平人员带来的风险。 个人理解是在一层复杂的多样的接口层上再套一层简化后的接口。 12345678910111213141516171819202122// 定义歌手、舞者、演奏者接口public interface Singer { void sing();}public interface Dancer { void dance();}public interface Player { void play();}// 定义剧院接口，开始表演。public class Theatre { Singer singer; Dancer dancer; Player player; public void show() { singer.sing(); dancer.dance(); player.play(); }} 3.3.7 享元模式 享元模式（Flyweight Pattern）主要用于减少创建对象的数量，以减少内存占用和提高性能。这种类型的设计模式属于结构型模式，它提供了减少对象数量从而改善应用所需的对象结构的方式。 享元模式尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象。我们将通过创建 5 个对象来画出 20 个分布于不同位置的圆来演示这种模式。由于只有 5 种可用的颜色，所以 color 属性被用来检查现有的 Circle 对象。 12345678910111213141516171819202122// 需要原型管理的类public class Monitor { // ...}// 原型管理器public class MonitorManager { private static Map&lt;String, Monitor&gt; monitors = new ConcurrentHashMap&lt;&gt;(); public static Monitor getMonitor(String id) { if (!monitors.containsKey(id)) { monitors.put(id, new Monitor()); } return (Monitor) monitors.get(id); }}// 获取MonitorMonitor monitor1 = MonitorManager.getMonitor(\"1\");Monitor monitor2 = MonitorManager.getMonitor(\"2\");// 第二次获取id=1的monitor直接传递已经创建的引用Monitor monitor3 = MonitorManager.getMonitor(\"1\"); 3.3.8 代理模式 在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。 在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。 意图：为其他对象提供一种代理以控制对这个对象的访问。 主要解决：在直接访问对象时带来的问题，比如说：要访问的对象在远程的机器上。在面向对象系统中，有些对象由于某些原因（比如对象创建开销很大，或者某些操作需要安全控制，或者需要进程外的访问），直接访问会给使用者或者系统结构带来很多麻烦，我们可以在访问此对象时加上一个对此对象的访问层。 何时使用：想在访问一个类时做一些控制。 如何解决：增加中间层。 关键代码：实现与被代理类组合。 应用实例： 1、Windows 里面的快捷方式。 2、猪八戒去找高翠兰结果是孙悟空变的，可以这样理解：把高翠兰的外貌抽象出来，高翠兰本人和孙悟空都实现了这个接口，猪八戒访问高翠兰的时候看不出来这个是孙悟空，所以说孙悟空是高翠兰代理类。 3、买火车票不一定在火车站买，也可以去代售点。 4、一张支票或银行存单是账户中资金的代理。支票在市场交易中用来代替现金，并提供对签发人账号上资金的控制。 5、spring aop。 优点： 1、职责清晰。 2、高扩展性。 3、智能化。 缺点： 1、由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢。 2、实现代理模式需要额外的工作，有些代理模式的实现非常复杂。 使用场景：按职责来划分，通常有以下使用场景： 1、远程代理。 2、虚拟代理。 3、Copy-on-Write 代理。 4、保护（Protect or Access）代理。 5、Cache代理。 6、防火墙（Firewall）代理。 7、同步化（Synchronization）代理。 8、智能引用（Smart Reference）代理。 注意事项： 1、和适配器模式的区别：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口。 2、和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制。 代理模式 vs 装饰器模式 1.代理模式对对象实现访问控制而不增强对象本身的功能，装饰器模式是增强对象的功能。 2.代理模式为对象生成一个代理对象，由代理对象访问原对象；装饰器模式更多对原对象的功能进行增强，是继承方案的一个代替。 3.代理模式的重心在于调用对象的某个功能，并做一个和对象本身无关的业务，装饰器模式重心在于扩展自身的功能。 个人疑问：不过Spring的AOP也用代理实现，其宣称是增强功能？所以很奇怪吧？感觉就是个名头的区别而已。 3.4 行为性模式 3.4.1 责任链模式 顾名思义，责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。 在这种模式中，通常每个接收者都包含对另一个接收者的引用。如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推。 意图：避免请求发送者与接收者耦合在一起，让多个对象都有可能接收请求，将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。 主要解决：职责链上的处理者负责处理请求，客户只需要将请求发送到职责链上即可，无须关心请求的处理细节和请求的传递，所以职责链将请求的发送者和请求的处理者解耦了。 何时使用：在处理消息的时候以过滤很多道。 如何解决：拦截的类都实现统一接口。 关键代码：Handler 里面聚合它自己，在 HandlerRequest 里判断是否合适，如果没达到条件则向下传递，向谁传递之前 set 进去。 应用实例： 1、红楼梦中的\"击鼓传花\"。 2、JS 中的事件冒泡。 3、JAVA WEB 中 Apache Tomcat 对 Encoding 的处理，Struts2 的拦截器，jsp servlet 的 Filter。 优点： 1、降低耦合度。它将请求的发送者和接收者解耦。 2、简化了对象。使得对象不需要知道链的结构。 3、增强给对象指派职责的灵活性。通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任。 4、增加新的请求处理类很方便。 缺点： 1、不能保证请求一定被接收。 2、系统性能将受到一定影响，而且在进行代码调试时不太方便，可能会造成循环调用。 3、可能不容易观察运行时的特征，有碍于除错。 使用场景： 1、有多个对象可以处理同一个请求，具体哪个对象处理该请求由运行时刻自动确定。 2、在不明确指定接收者的情况下，向多个对象中的一个提交一个请求。 3、可动态指定一组对象处理请求。 123456789101112131415161718192021222324252627282930313233// 抽象日志类public abstract class AbstractLogger { private AbstractLogger nextLogger; public abstract void w(String info); public void log(String info) { w(info); nextLogger.log(info); } // getter setter}public class ConsoleLogger extends AbstractLogger{ public void w(String info) {}}public class FileLogger extends AbstractLogger{ public void w(String info) {}}public class SocketLogger extends AbstractLogger{ public void w(String info) {}}AbstractLogger consoleLogger = new ConsoleLogger();AbstractLogger fileLogger = new FileLogger();AbstractLogger socketLogger = new SocketLogger();consoleLogger.setNextLogger(fileLogger);fileLogger.setNextLogger(socketLogger);consoleLogger.log(\"Hello!\"); 3.4.2 命令模式 命令模式（Command Pattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。 意图：将一个请求封装成一个对象，从而使您可以用不同的请求对客户进行参数化。 主要解决：在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适。 何时使用：在某些场合，比如要对行为进行\"记录、撤销/重做、事务\"等处理，这种无法抵御变化的紧耦合是不合适的。在这种情况下，如何将\"行为请求者\"与\"行为实现者\"解耦？将一组行为抽象为对象，可以实现二者之间的松耦合。 如何解决：通过调用者调用接受者执行命令，顺序：调用者→命令→接受者。 关键代码：定义三个角色：1、received 真正的命令执行对象 2、Command 3、invoker 使用命令对象的入口 应用实例：struts 1 中的 action 核心控制器 ActionServlet 只有一个，相当于 Invoker，而模型层的类会随着不同的应用有不同的模型类，相当于具体的 Command。 优点： 1、降低了系统耦合度。 2、新的命令可以很容易添加到系统中去。 缺点：使用命令模式可能会导致某些系统有过多的具体命令类。 使用场景：认为是命令的地方都可以使用命令模式，比如： 1、GUI 中每一个按钮都是一条命令。 2、模拟 CMD。 注意事项：系统需要支持命令的撤销(Undo)操作和恢复(Redo)操作，也可以考虑使用命令模式，见命令模式的扩展。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// 定义一个计数器，这是命令执行的主体public class Count { private int count = 0; public void add() { count++; } public void sub() { count--; }}// 定义一个抽象命令类public interface Order { public void execute();}// +1命令public class AddOrder implements Order { private Count count; public AddOrder(Count count) { this.count = count; } @Override public void execute() { this.count.add(); }}// -1命令public class SubOrder implements Order { private Count count; public SubOrder(Count count) { this.count = count; } @Override public void execute() { this.count.sub(); }}// 定义命令执行者public class Invoker { private List&lt;Order&gt; orderList = new ArrayList&lt;Order&gt;(); public void takeOrder(Order order){ orderList.add(order); } public void placeOrders(){ for (Order order : orderList) { order.execute(); } orderList.clear(); }}Count count = new Count();Order addOrder = new AddOrder(count);Order subOrder = new SubOrder(count);Invoker invoker = new Invoker();invoker.takeOrder(addOrder);invoker.takeOrder(subOrder);invoker.placeOrders(); 3.4.3 解释器模式 解释器模式（Interpreter Pattern）提供了评估语言的语法或表达式的方式，它属于行为型模式。这种模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。 意图：给定一个语言，定义它的文法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子。 主要解决：对于一些固定文法构建一个解释句子的解释器。 何时使用：如果一种特定类型的问题发生的频率足够高，那么可能就值得将该问题的各个实例表述为一个简单语言中的句子。这样就可以构建一个解释器，该解释器通过解释这些句子来解决该问题。 如何解决：构建语法树，定义终结符与非终结符。 关键代码：构建环境类，包含解释器之外的一些全局信息，一般是 HashMap。 应用实例：编译器、运算表达式计算。 优点： 1、可扩展性比较好，灵活。 2、增加了新的解释表达式的方式。 3、易于实现简单文法。 缺点： 1、可利用场景比较少。 2、对于复杂的文法比较难维护。 3、解释器模式会引起类膨胀。 4、解释器模式采用递归调用方法。 使用场景： 1、可以将一个需要解释执行的语言中的句子表示为一个抽象语法树。 2、一些重复出现的问题可以用一种简单的语言来进行表达。 3、一个简单语法需要解释的场景。 12345678910111213141516// 设置表达式抽象类public interface Expression { public int interpret(String context); }// 加法表达式public class AdditionExpression implements Expression { @Override public int interpret(String context) { String[] nums = context.split(\"+\"); return Integer.parseInt(nums[0]) + Integer.parseInt(nums[1]); }}// 解析加法表达式，获得加和。Expression et = new AdditionExpression();int sum = et.interpret(\"123+45\"); 3.4.4 迭代器模式 迭代器模式（Iterator Pattern）是 Java 和 .Net 编程环境中非常常用的设计模式。这种模式用于顺序访问集合对象的元素，不需要知道集合对象的底层表示。 意图：提供一种方法顺序访问一个聚合对象中各个元素, 而又无须暴露该对象的内部表示。 主要解决：不同的方式来遍历整个整合对象。 何时使用：遍历一个聚合对象。 如何解决：把在元素之间游走的责任交给迭代器，而不是聚合对象。 关键代码：定义接口：hasNext, next。 应用实例：JAVA 中的 iterator。 优点： 1、它支持以不同的方式遍历一个聚合对象。 2、迭代器简化了聚合类。 3、在同一个聚合上可以有多个遍历。 4、在迭代器模式中，增加新的聚合类和迭代器类都很方便，无须修改原有代码。 缺点：由于迭代器模式将存储数据和遍历数据的职责分离，增加新的聚合类需要对应增加新的迭代器类，类的个数成对增加，这在一定程度上增加了系统的复杂性。 使用场景： 1、访问一个聚合对象的内容而无须暴露它的内部表示。 2、需要为聚合对象提供多种遍历方式。 3、为遍历不同的聚合结构提供一个统一的接口。 注意事项：迭代器模式就是分离了集合对象的遍历行为，抽象出一个迭代器类来负责，这样既可以做到不暴露集合的内部结构，又可让外部代码透明地访问集合内部的数据。 ps.java中有内置的Iterator和Iterable可以继承/实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 迭代器接口public interface Iterator { public boolean hasNext(); public Object next(); }// 容器public interface Container { public Iterator getIterator();}// 可迭代对象public class NameRepository implements Container { public String[] names = {\"Robert\" , \"John\" ,\"Julie\" , \"Lora\"}; @Override public Iterator getIterator() { return new NameIterator(); } private class NameIterator implements Iterator { int index; @Override public boolean hasNext() { if(index &lt; names.length){ return true; } return false; } @Override public Object next() { if(this.hasNext()){ return names[index++]; } return null; } }}for(Iterator iter = namesRepository.getIterator(); iter.hasNext();){ String name = (String)iter.next(); System.out.println(\"Name : \" + name);} 3.4.5 中介者模式 中介者模式（Mediator Pattern）是用来降低多个对象和类之间的通信复杂性。这种模式提供了一个中介类，该类通常处理不同类之间的通信，并支持松耦合，使代码易于维护。中介者模式属于行为型模式。 意图：用一个中介对象来封装一系列的对象交互，中介者使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。 主要解决：对象与对象之间存在大量的关联关系，这样势必会导致系统的结构变得很复杂，同时若一个对象发生改变，我们也需要跟踪与之相关联的对象，同时做出相应的处理。 何时使用：多个类相互耦合，形成了网状结构。 如何解决：将上述网状结构分离为星型结构。 关键代码：对象 Colleague 之间的通信封装到一个类中单独处理。 应用实例： 1、中国加入 WTO 之前是各个国家相互贸易，结构复杂，现在是各个国家通过 WTO 来互相贸易。 2、机场调度系统。 3、MVC 框架，其中C（控制器）就是 M（模型）和 V（视图）的中介者。 优点： 1、降低了类的复杂度，将一对多转化成了一对一。 2、各个类之间的解耦。 3、符合迪米特原则。 缺点：中介者会庞大，变得复杂难以维护。 使用场景： 1、系统中对象之间存在比较复杂的引用关系，导致它们之间的依赖关系结构混乱而且难以复用该对象。 2、想通过一个中间类来封装多个类中的行为，而又不想生成太多的子类。 注意事项：不应当在职责混乱的时候使用。 1234567891011121314151617181920212223// 需要通信的User类public class User { private String name; public User(Stirng name) { this.name = name; } public void sendToRoom(String msg) { ChatRoom.send(name, msg); }}// 聊天室（中介User类的类）public class ChatRoom { public static void send(String name, String msg) { }}// 两者利用聊天室通信User user1 = new User(\"A\");User user2 = new User(\"B\");user1.sendToRoom(\"Hahaha\");user2.sendToRoom(\"Hahaha\"); 3.4.6 备忘录模式 备忘录模式（Memento Pattern）保存一个对象的某个状态，以便在适当的时候恢复对象。备忘录模式属于行为型模式。 意图：在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。 主要解决：所谓备忘录模式就是在不破坏封装的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，这样可以在以后将对象恢复到原先保存的状态。 何时使用：很多时候我们总是需要记录一个对象的内部状态，这样做的目的就是为了允许用户取消不确定或者错误的操作，能够恢复到他原先的状态，使得他有\"后悔药\"可吃。 如何解决：通过一个备忘录类专门存储对象状态。 关键代码：客户不与备忘录类耦合，与备忘录管理类耦合。 应用实例： 1、后悔药。 2、打游戏时的存档。 3、Windows 里的 ctrl + z。 4、IE 中的后退。 5、数据库的事务管理。 优点： 1、给用户提供了一种可以恢复状态的机制，可以使用户能够比较方便地回到某个历史的状态。 2、实现了信息的封装，使得用户不需要关心状态的保存细节。 缺点：消耗资源。如果类的成员变量过多，势必会占用比较大的资源，而且每一次保存都会消耗一定的内存。 使用场景： 1、需要保存/恢复数据的相关状态场景。 2、提供一个可回滚的操作。 注意事项： 1、为了符合迪米特原则，还要增加一个管理备忘录的类。 2、为了节约内存，可使用原型模式+备忘录模式。 3.4.7 观察者模式 当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知依赖它的对象。观察者模式属于行为型模式。 意图：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 主要解决：一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作。 何时使用：一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知。 如何解决：使用面向对象技术，可以将这种依赖关系弱化。 关键代码：在抽象类里有一个 ArrayList 存放观察者们。 应用实例： 1、拍卖的时候，拍卖师观察最高标价，然后通知给其他竞价者竞价。 2、西游记里面悟空请求菩萨降服红孩儿，菩萨洒了一地水招来一个老乌龟，这个乌龟就是观察者，他观察菩萨洒水这个动作。 优点： 1、观察者和被观察者是抽象耦合的。 2、建立一套触发机制。 缺点： 1、如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间。 2、如果在观察者和观察目标之间有循环依赖的话，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。 3、观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。 使用场景：一个抽象模型有两个方面，其中一个方面依赖于另一个方面。将这些方面封装在独立的对象中使它们可以各自独立地改变和复用。 一个对象的改变将导致其他一个或多个对象也发生改变，而不知道具体有多少对象将发生改变，可以降低对象之间的耦合度。 一个对象必须通知其他对象，而并不知道这些对象是谁。 需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。 注意事项： 1、JAVA 中已经有了对观察者模式的支持类。 2、避免循环引用。 3、如果顺序执行，某一观察者错误会导致系统卡壳，一般采用异步方式。 3.4.8 状态模式 3.4.9 空对象模式 3.4.10 策略模式 3.4.11 模板模式 3.4.12 访问者模式 3.5 J2EE模式 3.5.1 MVC模式 3.5.2 业务代码模式 3.5.3 组合实体模式 3.5.4 数据访问对象模式 3.5.5 前端控制器模式 3.5.6 拦截过滤器模式 4. Spring介绍 4.1 介绍 Spring框架是一个开源的Java平台，它为开发者提供了一种方法来简化企业级应用程序的开发。Spring框架的核心是控制反转（IoC）和面向切面编程（AOP）。 控制反转（IoC） 控制反转是一种软件设计模式，在这种模式中，对象的依赖关系不是由应用程序代码直接管理，而是由外部容器来管理。 面向切面编程（AOP） 面向切面编程允许你把系统中的关注点（如日志记录、权限控制等）从主业务逻辑中分离出来 核心组件 Core Container（核心容器）：提供核心功能，包括依赖注入（DI），事件发布，资源访问等。 Data Access/Integration（数据访问/集成）：提供与数据库交互的支持，包括事务管理。 Web：提供构建Web应用的支持，例如Spring MVC。 AOP：提供面向切面编程的支持。 Instrumentation：提供类检测和类加载器实现，用于某些应用服务器。 Test：提供用于测试Spring应用的支持。 常用模块 905bc1bc87fa4a63f14808f94b5a9ca3.jpeg 常见注解 bean 注入与装配的的方式有很多种，可以通过 xml，get set 方式，构造函数或者注解等。简单易用的方式就是使用 Spring 的注解了，Spring 提供了大量的注解方式。 @Controller vs @RestController @RestController包含了@Controller和@ResponseBody两个注解，表明该controller是构建符合RESTful风格api，会将所有处理请求的方法默认解析为将方法返回值直接作为响应体内容返回。 4.2 常见注解 4.2.1 Spring Bean注解 由以下注解标记的类会被识别为Spring Bean，在Spring容器初始化时被创建，并由其管理。 @Component 1234567// Compoent源码@Target({ElementType.TYPE}) // 注解允许被在类、接口、枚举上@Retention(RetentionPolicy.RUNTIME) // 注解在程序运行时仍被保留@Documented // 由其标注的信息会被记录到文档中public @interface Component { String value() default \"\"; // 定义组件名} @Component注解是Spring Bean内所用不同类型的根注解，被其标注的类被Spring识别为Bean，并在App启动时由容器管理。 @Repository 1234567891011// Repository@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Repository { @AliasFor( //别名 annotation = Component.class ) String value() default \"\";} @Repository注解用于标注Dao层实现，本质上还是一个Compoent。 @Service 1234567891011// Service@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Service { @AliasFor( annotation = Component.class ) String value() default \"\";} @Service注解用于标注业务层实现，本质上还是一个Compoent。 @Controller @Controller注解用于标注控制器实现，本质上还是一个Compoent。源码和前面几种一样。 @RestController 12345678@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Controller@ResponseBodypublic @interface RestController { String value() default \"\";} @RestController包含了@Controller和@ResponseBody两个注解，表明该controller是构建符合RESTful风格api，会将所有处理请求的方法默认解析为将方法返回值直接作为响应体内容返回。 @Configuration 由其标注的类时配置类，在Spring容器启动时，依照配置类中的定义配置Bean等配置。源码与上述几个基本一致。 4.2.2 自动装配相关注解 @Autowired 123456789@Target({ElementType.CONSTRUCTOR, ElementType.METHOD, ElementType.PARAMETER, ElementType.FIELD, ElementType.ANNOTATION_TYPE})// 可以标注在构造器、方法、参数、字段和注解上@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Autowired { boolean required() default true; // 必须标记：如果置为false，则Spring容器在尝试装配时，没有找到匹配的Bean对象，则置为Null。// 如果置为true，当Spring无法找到匹配的Bean时会直接报错退出。} 按照类型自动注入，如果bean对象中仅有一个类型与注入变量一致，泽注入成功。 如果用多个类型一样的bean，使用变量名id注入。如果没有对应id的，则报错。 @Qualifier 在按照类型注入的基础上，再按照名称注入。 属性： value 用于指定注入bean的id。 他不能独立使用，要先写一个Autowired。 @Resource 直接按照bean的id注入，可以独立适应， 以上三个注解只能注入bean类型，不能注入基本类型，集合类型的注入，只能通过xml实现。 @Value 直接注入一个值，也支持el表达式，注入配置文件中的值。 4.2.3 配置类注解 @Bean 1234567891011121314151617181920@Target({ElementType.METHOD, ElementType.ANNOTATION_TYPE})@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Bean { @AliasFor(\"name\") // Bean Id String[] value() default {}; @AliasFor(\"value\") // Bean id String[] name() default {}; Autowire autowire() default Autowire.NO; // No：不尝试自动装配Bean中的对象（一般用都用这个，如果想自动装配，在类里面配置） // byName：依次调用setter方法，在容器中寻找Bean装配 // byType，在容器中查找对应成员类型的bean，自动装配 // construct：利用构造函数装配 String initMethod() default \"\"; // 当Bean被创建后，首先调用initMethod方法 String destroyMethod() default \"(inferred)\"; // 当Bean生命周期结束，调用此方法} 在配置类中（@Configuratoin标注的类）出现，标注在一个方法上，表示配置一个bean对象。Spring容器初始化时，扫描到此类方法，将调用方法，并将返回的对象作为bean载入到容器中。在调用方法时，会自动扫描容器中的对象，填充方法参数。 @Import 123456@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Import { Class&lt;?&gt;[] value(); // 要导入的另一个配置类} 在配置类前使用该注解可以导入其他配置类。 @CompoentScan 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Retention(RetentionPolicy.RUNTIME)@Target({ElementType.TYPE})@Documented@Repeatable(ComponentScans.class)public @interface ComponentScan { @AliasFor(\"basePackages\") // 扫描根路径 String[] value() default {}; @AliasFor(\"value\") String[] basePackages() default {}; Class&lt;?&gt;[] basePackageClasses() default {}; Class&lt;? extends BeanNameGenerator&gt; nameGenerator() default BeanNameGenerator.class; Class&lt;? extends ScopeMetadataResolver&gt; scopeResolver() default AnnotationScopeMetadataResolver.class; ScopedProxyMode scopedProxy() default ScopedProxyMode.DEFAULT; String resourcePattern() default \"**/*.class\"; boolean useDefaultFilters() default true; Filter[] includeFilters() default {}; // 包含的组件 Filter[] excludeFilters() default {}; // 排除组件 boolean lazyInit() default false; @Retention(RetentionPolicy.RUNTIME) @Target({}) public @interface Filter { FilterType type() default FilterType.ANNOTATION; // ANNOTATION 按照组件过滤 // ASSIGNABLE_TYPE 扫描给定的类型 // ASPECTJ 使用ASPECTJ表达式 // REGEX 正则 // CUSTOM 自定义规则 @AliasFor(\"classes\") Class&lt;?&gt;[] value() default {}; @AliasFor(\"value\") Class&lt;?&gt;[] classes() default {}; String[] pattern() default {}; }} 指定Spring容器扫描Bean的配置，一般加载配置类或者主类前面。 1234567891011121314151617181920212223242526272829303132333435363738394041// includeFilters 用法 包含Animal.class类可以被扫描到，包括其子类@ComponentScan(value = \"com.spring\" includeFilters = {@ComponentScan.Filter(type = FilterType.ASSIGNABLE_TYPE, classes = {Animal.class})})// excludeFilters 用法 排除包含@Controller注解的类@ComponentScan(value = \"com.spring\" , excludeFilters = { @ComponentScan.Filter(type = FilterType.ANNOTATION , classes = {Controller.class} ),})// ComponentScans用法@ComponentScans( value = { @ComponentScan(value = \"com.spring\" , includeFilters = { @ComponentScan.Filter(type = FilterType.ANNOTATION , classes = {Controller.class} ) }, useDefaultFilters = false) , @ComponentScan(value = \"com.spring\" , excludeFilters = { @ComponentScan.Filter(type = FilterType.ANNOTATION , classes = { Repository.class} ) }) })*/// @ComponentScan // 针对Java8 语法可以指定多个@ComponentScan，Java8以下可以用 //@ComponentScans() 配置多个规则@ComponentScan(value = \"com.spring\" , excludeFilters = { @ComponentScan.Filter(type = FilterType.ANNOTATION , classes = {Controller.class, Controller.class} ),}, includeFilters = { @ComponentScan.Filter(type = FilterType.ANNOTATION , classes = {Controller.class, Controller.class} ),}) @PropertySource 指定一个配置文件源。 4.3 原理 4.3.1 IOC原理 IoC （Inversion of Control ）即控制反转/反转控制。它是一种思想不是一个技术实现。描述的是：Java 开发领域对象的创建以及管理的问题。 Why IOC? 对象之间的耦合度或者说依赖程度降低； 资源变的容易管理；比如你用 Spring 容器提供的话很容易就可以实现一个单例。 IOC in Spring（IOC在Spring框架中的实现） 利用反射技术，遵循工厂设计模式，通过外部配置文件生成对象，并将对象放入容器管理。 4.3.2 AOP原理 4.3.3 MVC原理 4.4 Spring启动过程 4.4.1 前置了解 在了解Spring启动过程之前，需要对Spring最核心组件ApplicationContext和IOC容器底层抽象定义BeanFactory有所了解。 ApplicationContext和BeanFactory都是Spring的抽象接口定义，其中ApplicationContext是BeanFactory的子类。具体关系如下图所示： ApplicationContext 是Spring的主体，具备IOC、AOP、消息发布/订阅、消息源转换等功能。有几种不同的实现，这些实现分别通过不同的方式初始化一个Spring实例。（主要方式就两种，1.通过注解的方式初始化Spring，2.通过xml配置文件的方式初始化Spring。） 这里给出几种常用的ApplicationContext实现类 实现类 说明 AnnotationConfigApplicationContext 从一个或多个基于Java的配置类中加载上下文定义，适用于Java注解的方式 ClassPathXmlApplicationContext 从类路径下的一个或多个xml配置文件中加载上下文定义，适用于xml配置的方式 FileSystemXmlApplicationContext 从文件系统下的一个或多个xml配置文件中加载上下文定义，也就是说系统盘符中加载xml配置文件 AnnotationConfigWebApplicationContext 专门为web应用准备的，适用于注解方式 XmlWebApplicationContext 从Web应用下的一个或多个xml配置文件加载上下文定义，适用于xml配置方式 BeanFactory 4.4.2 启动过程 编写代码，通过注解的方式启动一个Spring实例，观察启动过程。 首先定义两个服务组件，并要求一个要装配另一个。然后实例化一个AnnotationConfigApplicationContext，这个ApplicationContext的实现可以扫描一个package内的组件，完成Spring的创建。 1234567891011121314151617181920212223242526// TestService.java@Componentpublic class TestService { // ......}//AutowiredTestService.java@Componentpublic class AutowiredTestService { @Autowired private TestService testService;}// SpringTestApplication.javapublic class SpringTestApplication { public static void main(String[] args) { ApplicationContext context = new AnnotationConfigApplicationContext(\"kalzn.spring_test.bean\"); AutowiredTestService service = context.getBean(AutowiredTestService.class); }} 进入AnnotationConfigApplicationContext构造方法后，发现其中很简单，主要就是三个步骤：1. 初始化配置 2. 扫描目标package下的注解，登记这些注解 3. 根据这些注解完成Spring的初始化。 1.初始化配置 进入this() BeanDefinitionReader 从xml文件、类路径下使用了@Component系列注解的类、或者从@Configuration注解的配置类，获取BeanDefintiions，然后注册到BeanFactory中。BeanDefintiion其实就是对Bean的一些元数据定义，在扫描组件（第二步）的时候由BeanFactory实现保存进一个Map中，然后在refresh（第三步）中依据这些定义实例化出对象。 几种常见实现： 实现 说明 XmlBeanDefinitionReader 从XML文件读取定义 AnnotatedBeanDefinitionReader 通过注解读取定义 ConfigurationClassBeanDefinitionReader 基于@Configuration注解的类配置（这里注意区分其与AnnotatedBeanDefinitionReader的区别：AnnotatedBeanDefinitionReader是通过类上的组件注解如Service、Component等注册，而ConfigurationClassBeanDefinitionReader是通过@Configuration类内的例如@Bean注解注册） 继续深入，看看BeanDefinitionReader是如何搞出来的： ClassPathBeanDefinitionScanner 指定一个扫描器组件，在对应ClassPath下扫描组件。 BeanDefinitionRegistry ApplicationContext在初始化Reader和Scanner时，将自身作为BeanDefinitionRegistry传入了进去。 一个存放BeanDefinition的注册表,用于存储和管理所有的BeanDefinition。 2. 组件扫描 进入this.scan()，经过数层调用，最终调用了ClassPathBeanDefinitionScanner核心方法doScan 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) { Assert.notEmpty(basePackages, \"At least one base package must be specified\"); Set&lt;BeanDefinitionHolder&gt; beanDefinitions = new LinkedHashSet(); String[] var3 = basePackages; int var4 = basePackages.length; for(int var5 = 0; var5 &lt; var4; ++var5) { // 遍历所有要扫描的包 String basePackage = var3[var5]; //寻找候选的组件 Set&lt;BeanDefinition&gt; candidates = this.findCandidateComponents(basePackage); Iterator var8 = candidates.iterator(); while(var8.hasNext()) { // 迭代这些候选组件 // 获取候选组件的BeanDefinition BeanDefinition candidate = (BeanDefinition)var8.next(); // 获取生命周期的元定义信息 ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate); candidate.setScope(scopeMetadata.getScopeName()); // 生成组件名称 String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry); // 根据类型不同做一些后处理，例如设定懒加载等等 if (candidate instanceof AbstractBeanDefinition abstractBeanDefinition) { this.postProcessBeanDefinition(abstractBeanDefinition, beanName); } if (candidate instanceof AnnotatedBeanDefinition annotatedBeanDefinition) { AnnotationConfigUtils.processCommonDefinitionAnnotations(annotatedBeanDefinition); } // 检测当前BeanDefinition是否已经存在Spring中，已存在是否兼容 if (this.checkCandidate(beanName, candidate)) { BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName); definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); beanDefinitions.add(definitionHolder); // 注册组件定义 this.registerBeanDefinition(definitionHolder, this.registry); } } } return beanDefinitions;} 3.refresh 是Spring核心方法，在这里完成容器的初始化，完成Bean对象的实例化，并初始化其他Spring组件。这里首先看refresh方法概况，然后在逐个简要分析这些方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public void refresh() throws BeansException, IllegalStateException { this.startupShutdownLock.lock(); try { this.startupShutdownThread = Thread.currentThread(); StartupStep contextRefresh = this.applicationStartup.start(\"spring.context.refresh\"); // 1. 刷新前的预处理 this.prepareRefresh(); // 2. 创建一个刷新的BeanFactory ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory(); // 3. BeanFactory的准备工作 this.prepareBeanFactory(beanFactory); try { // 4. BeanFactory准备完成后的后处理工作 this.postProcessBeanFactory(beanFactory); StartupStep beanPostProcess = this.applicationStartup.start(\"spring.context.beans.post-process\"); // 5. 执行执行 BeanFactoryPostProcessor 和 BeanFactory 方法的后置处理器。 this.invokeBeanFactoryPostProcessors(beanFactory); // 6. 注册BeanPostProcessor this.registerBeanPostProcessors(beanFactory); beanPostProcess.end(); // 7. 初始化MessageSource组件 this.initMessageSource(); // 8. 初始化ApplicationEventMulticaster （Spring的事件发布/订阅机制） this.initApplicationEventMulticaster(); // 9. 留给子容器，例如在springboot中，用来启动tomcat、jetty this.onRefresh(); // 10. 注册ApplicationListeners （Spring的事件发布/订阅机制） this.registerListeners(); // 11. 核心方法，根据扫描到的BeanDefinition构建对应Bean实例 this.finishBeanFactoryInitialization(beanFactory); // 12. 完成refresh，IOC容器创建完成，Spring实例启动完成 this.finishRefresh(); } catch (Error | RuntimeException var12) { Throwable ex = var12; if (this.logger.isWarnEnabled()) { this.logger.warn(\"Exception encountered during context initialization - cancelling refresh attempt: \" + ex); } this.destroyBeans(); this.cancelRefresh(ex); throw ex; } finally { contextRefresh.end(); } } finally { this.startupShutdownThread = null; this.startupShutdownLock.unlock(); }} prepareRefresh 刷新前的预处理，调用 initPropertySources() 方法初始化一些属性设置，调用 getEnvironment().validateRequiredProperties() 校验属性的合法性，设置 earlyApplicationEvents= new LinkedHashSet() 保存容器中较早期的事件。 obtainFreshBeanFactory 获取 BeanFactory，创建一个刷新的 Bean 工厂，refreshBeanFactory() 并设置容器 ID，然后将创建的 DefaultListableBeanFactory 的对象进行返回。这里将ApplicationContext的ID关联到BeanFactory。 prepareBeanFactory BeanFactory 的预准备工作，设置 BeanFactory 的类加载器和表达式解析器，并添加 BeanPostProcessor【ApplicationContextAwareProcessor】，设置自动装配的接口，添加 BeanPostProcessor。实例化几个基础单例，定义了环境信息以及环境启动必要的组件。 postProcessBeanFactory BeanFactory 准备工作完成后进行的后置处理工作，子类通过重写这个方法来做进一步的设置。 registerBeanPostProcessors 注册 BeanPostProcessor（Bean 的后置处理器）,不同接口类型的 BeanPostProcessor 在 Bean 创建前后的执行时机是不一样的。 initMessageSource 初始化 MessageSource 组件， 做国际化功能、消息绑定、消息解析等。 initApplicationEventMulticaster 初始化事件派发器，如果容器中没有事件派发器，那么就创建一个 SimpleApplicationEventMulticaster 并添加到容器中。 onRefresh 留给子容器(子类)，例如在 springboot 中，用来创建 tomcat、jetty 容器并启动。 registerListeners 给容器中将所有项目里面的 ApplicationListener 注册进来，并将监听器注册到事件派发器中。 finishBeanFactoryInitialization 初始化所有剩下的单实例 bean，这个方法是核心方法， 4.5 Bean生命周期 Spring之Bean的生命周期_checkcandidate方法-CSDN博客 参考 面向对象及其五大基本编程原则[简洁易懂]_面向对象编程-CSDN博客 面向过程编程和面向对象编程的区别_面向对象编程和面向过程编程的区别-CSDN博客 字节面试杂谈——JAVA基础_character 缓存的范围是-CSDN博客 Spring 学习3--AOP（面向切面编程）_aop通配符含义-CSDN博客 软件工程概论---内聚性和耦合性_软件工程内聚和耦合-CSDN博客 软件的内聚度和耦合度 - 知乎 (zhihu.com) 设计模式简谈-CSDN博客 代理模式和装饰器模式的区别-CSDN博客 深度解析Spring框架原理_spring框架原理及流程-CSDN博客 Spring的@ComponentScan注解用法介绍_java_脚本之家 (jb51.net) IoC &amp; AOP详解（快速搞懂） | JavaGuide Spring BeanFactory和ApplicationContext详解-CSDN博客 Spring之BeanFactory详解-CSDN博客 Spring系列 BeanDefinitionRegistry解读（超通俗易懂）-CSDN博客 Spring之Bean的生命周期_checkcandidate方法-CSDN博客 Spring中的refresh方法分析_java_脚本之家 (jb51.net)","categories":[{"name":"八股","slug":"八股","permalink":"http://kalzncc.github.io/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"八股","slug":"八股","permalink":"http://kalzncc.github.io/tags/%E5%85%AB%E8%82%A1/"}]},{"title":"关于我","slug":"about-me","date":"2024-11-26T04:30:11.000Z","updated":"2024-11-27T14:22:49.923Z","comments":true,"path":"2024/11/26/about-me/","link":"","permalink":"http://kalzncc.github.io/2024/11/26/about-me/","excerpt":"","text":"About Me 这里是Kalzn，打过ICPC但没拿过金，打过CCPC但也没拿过金，打过蓝桥但没拿过第一，上过大学但是双非，在中科院读研但不是计算(自动化、软件)所。 写博客主要是取乐自己，顺带给阁下带来点帮助。 有关ICPC的东西应该不会更了(找工作的时候可能会再更？)，读研之后就不怎么接触了，目前主要更机器学习、项目代码。 JAVA/Golang后端开发，曾于国内某红色图文APP实习，目前计划供职于国内某知名二游厂商。 Honors and Achievements 2021 CCPC 总决赛铜牌 2020 CCPC 长春站银牌 2020 ICPC 上海站、银川站银牌 2019 ICPC-ECFinal银牌、银川站铜牌 SHTree: A Structural Encrypted Traffic Fingerprint Generation Method for Multiple Classification Tasks (ISCC 2024 一作) 2021.12~2022.08 XX监控大数据平台-部委 后端开发 2022.12~2025.X XX系统XXXXXX行为表征技术-国重研 算法设计","categories":[],"tags":[{"name":"置顶","slug":"置顶","permalink":"http://kalzncc.github.io/tags/%E7%BD%AE%E9%A1%B6/"}]},{"title":"面试-数据库基础以及MySql、ClickHost、Redis简介","slug":"137570823","date":"2024-04-09T14:58:23.000Z","updated":"2024-11-27T03:53:38.322Z","comments":true,"path":"2024/04/09/137570823/","link":"","permalink":"http://kalzncc.github.io/2024/04/09/137570823/","excerpt":"","text":"0.数据完整性 确保数据准确和一致，主要有以下四类约束： 实体完整性 主键完整 域完整性 键值数据类型 参照完整性 外键完整 用户定义的完整性 例如计数器必须大于0等用户自定义的完整性条件# 面试-数据库基础、MySql、ClickHost、Redis简介 1.数据库并发控制 1.1事物 事物是提交给DBMS执行的一系列操作。DBMS需要确保事物的操作序列被完整执行。即要么全部执行，要么回滚至事物执行前的状态，不能执行一半。 四大特性（ACID）： 原子性（Atomicity） 事物的操作序列要么全部执行完毕，要么不执行。 一致性（Consistency） 不能破坏数据库数据的完整性和一致性。 隔离性（Isolation） 事物执行不能相互干扰。 持久性（Durability） 事物一旦被提交，即被永久记录。 1.2 并发读写错误 更新丢失 事物A，B同时读取V，并都进行修改。那么第一个修改会丢失。 读脏数据 事物A要对V值进行修改，但是事物B在此期间（事物A还没有来得及修改V之前）读取了V。然后在没有修改的V上进行计算，将错误结果存回。 在这里插入图片描述 不可重复读 事物A先后读取两次V值，但是再次期间V被另一事物B修改，导致两次读取的V值不同。 幻读 事物A在查询或统计某条或者数条记录，但再次期间事物B删除了该条或者删加了几条需要统计的记录，导致事物A再次读取时发生变化。（幻读强调数据的删除和增添，不可重读强调对数据内容的修改。） 1.3 锁 1.3.1 乐观锁与悲观锁 悲观锁 指的是在操作数据的时候比较悲观，悲观地认为别人一定会同时修改数据，因此悲观锁在操作数据时是直接把数据上锁，直到操作完成之后才会释放锁，在上锁期间其他人不能操作数据。 乐观锁 指的是在操作数据的时候非常乐观，乐观地认为别人不会同时修改数据，因此乐观锁默认是不会上锁的，只有在执行更新的时候才会去判断在此期间别人是否修改了数据，如果别人修改了数据则放弃操作，否则执行操作。 1.3.2 共享锁和排他锁 共享锁（Share Locks，简记为S）又被称为读锁，其他用户可以并发读取数据，但任何事务都不能获取数据上的排他锁，直到已释放所有共享锁。 排它锁（(Exclusive lock,简记为X锁)）又称为写锁，若事务T对数据对象A加上X锁，则只允许T读取和修改A，其它任何事务都不能再对A加任何类型的锁，直到T释放A上的锁。它防止任何其它事务获取资源上的锁，直到在事务的末尾将资源上的原始锁释放为止。在更新操作(INSERT、UPDATE 或 DELETE)过程中始终应用排它锁。 写锁所有等，写锁等所有，读锁可共入 1.3.3 行锁与表锁 见5.1.2 1.3.4 意向锁 见5.1.2 1.4 封锁协议与隔离级别 S锁（共享锁 读锁）X锁（排他锁 写锁） 一级封锁 对应 READ-UNCOMMITTED (读取未提交 ) 在修改数据A之前加X锁，事物结束释放。 二级封锁 对应 READ-COMMITTED(读取已提交) 在一级封锁的基础上，在读取A之前加S锁，读完释放。 （Oracle 默认隔离级别） 三级封锁 对应 REPEATABLE-READ(可重复读) 在一级封锁的基础上，在读取A之前加S锁，事物结束释放。（MySql 5.5 InnoDB 默认隔离级别） 最高封锁 对应 SERIALIZABLE(可串行化 ) 最高的隔离级别，完全服从 ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产⽣干扰 更新丢失 脏读 不可重复读 幻读 一级 √ 二级 √ √ 三级 √ √ √ 最高 √ √ √ √ 1.5 MVCC 1.5.1 概念 MVCC，全称Multi-Version Concurrency Control，即多版本并发控制。MVCC是一种并发控制的方法，是现代数据库（包括 MySQL、Oracle、PostgreSQL 等）引擎实现中常用的处理读写冲突的手段，目的在于提高数据库高并发场景下的吞吐性能。 MVCC用更好的方式去处理读—写请求，做到在发生读—写请求冲突时不用加锁。 这个读是指的快照读，而不是当前读，当前读是一种加锁操作，是悲观锁。 最早的数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞。引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度。 1.5.2 当前读与快照读 1.3提及的共享锁和排他锁都是当前锁。为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。 当前读的实现方式：next-key锁(行记录锁+Gap间隙锁) 见4.1.2详细解释 间隙锁：只有在Read Repeatable、Serializable隔离级别才有，就是锁定范围空间的数据，假设id有3,4,5，锁定id&gt;3的数据，是指的4，5及后面的数字都会被锁定，因为此时如果不锁定没有的数据，例如当加入了新的数据id=6，就会出现幻读，间隙锁避免了幻读。 快照读是数据库操作中的一种读取方式，它指的是从数据库中获取在某个时间点或事务开始之前的数据快照。与当前读不同，快照读不会看到其他事务已经提交的更改，而是提供了一个固定时间点的数据库状态。这种读取方式通常用于需要查看历史数据或生成报表的应用场景。 当前读/快照读与MVCC的关系 MVCC是设计理念：保存数据的多个版本，使得读写操作没有冲突。 快照读是MySql（InnoDB引擎）为了实现MVCC模型的一种具体的做法。 1.5.3 MVCC in InnoDB MVCC的目的就是多版本并发控制，在数据库中的实现，就是为了解决读写冲突，它的实现原理主要是依赖记录中的 3个隐式字段。undo日志 ，Read View 来实现MVCC。 Undolog：处理修改和回滚 Read View：处理读取时的快照生成 Undolog 事务会先使用“排他锁”锁定改行，将该行当前的值复制到undo log中，然后再真正地修改当前行的值，最后填写事务的DB_TRX_ID，使用回滚指针DB_ROLL_PTR指向undo log中修改前的行DB_ROW_ID。 在这里插入图片描述 DB_TRX_ID: 6字节DB_TRX_ID字段，表示最后更新的事务id(update,delete,insert)。此外，删除在内部被视为更新，其中行中的特殊位被设置为将其标记为已软删除。 DB_ROLL_PTR: 7字节回滚指针，指向前一个版本的undolog记录，组成undo链表。如果更新了行，则撤消日志记录包含在更新行之前重建行内容所需的信息。 DB_ROW_ID: 6字节的DB_ROW_ID字段，包含一个随着新行插入而单调递增的行ID, 当由innodb自动产生聚集索引时，聚集索引会包括这个行ID的值，否则这个行ID不会出现在任何索引中。如果表中没有主键或合适的唯一索引, 也就是无法生成聚簇索引的时候, InnoDB会帮我们自动生成聚集索引, 聚簇索引会使用DB_ROW_ID的值来作为主键; 如果表中有主键或者合适的唯一索引, 那么聚簇索引中也就不会包含 DB_ROW_ID了 。 Read View 说白了Read View就是事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID(当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以最新的事务，ID值越大)。 Read View遵循一个可见性算法，主要是将要被修改的数据的最新记录中的DB_TRX_ID（即当前事务ID）取出来，与系统当前其他活跃事务的ID去对比（由Read View维护），如果DB_TRX_ID跟Read View的属性做了某些比较，不符合可见性，那就通过DB_ROLL_PTR回滚指针去取出Undo Log中的DB_TRX_ID再比较，即遍历链表的DB_TRX_ID（从链首到链尾，即从最近的一次修改查起），直到找到满足特定条件的DB_TRX_ID, 那么这个DB_TRX_ID所在的旧记录就是当前事务能看见的最新老版本 2. 数据库范式 目的：消除冗余 第一范式（1NF） 属性不可分（关系数据库的基础） 第二范式（2NF） 在1NF的基础上，不存在部分依赖，非主键列要完全依赖于主键。 例如：为了记录学生成绩，有属性studentID，studnetName，courseID，courseName，score。其中studnetName仅依赖studentID；courseName仅依赖courseID，而主键为(studentID, courseID)。所以将上述记录存储在一张表里不符合2NF。正确做法是拆分3张表存储：学生表：（studentID，studentName），课程表：（courseID，courseName），分数表：（studentID，courseID，score）。 第三范式（3NF） 在2NF的基础上，不存在传递依赖。 例如：记录人员：有属性：name，sexCode，sexText 其中sexCode依赖name，而sexText依赖sexCode。所以将上述记录存储在一张表里不符合3NF。正确做法是拆分2张表存储：人员表：（name，sexCode），性别表：（sexCode，sexText）。 BC范式（BCNF） 在3NF的基础上，关系R中的每个非平凡函数依赖X → Y，X必须是R的超键。 例如仓库管理（仓库号，存储物品号，管理员号，数量）满足一个管理员只在一个仓库工作；一个仓库可以存储多种物品，则存在如下关系： (仓库号，存储物品号)——&gt;(管理员号，数量) (管理员号，存储物品号)——&gt;(仓库号，数量) 但是(仓库号)——&gt;(管理员号)且(管理员号)——&gt;(仓库号)。即存在关键字段决定关键字段的情况，因此其不符合BCNF。把仓库管理关系表分解为两个关系表仓库管理表(仓库号，管理员号)和仓库表(仓库号，存储物品号，数量)，这样这个数据库表是符合BCNF的，并消除了删除异常、插入异常和更新异常。 第四范式（4NF） 设R是一个关系模型，D是R上的多值依赖集合。如果D中存在凡多值依赖X-&gt;Y时，X必是R的超键，那么称R是第四范式的模式。 例如，职工表(职工编号，职工孩子姓名，职工选修课程)，在这个表中，同一个职工可能会有多个职工孩子姓名，同样，同一个职工也可能会有多个职工选修课程，即这里存在着多值事实，不符合第四范式。如果要符合第四范式，只需要将上表分为两个表，使它们只有一个多值事实，例如职工表一(职工编号，职工孩子姓名)，职工表二(职工编号，职工选修课程)，两个表都只有一个多值事实，所以符合第四范式。 数据库范式只是理论指导规范，遵不遵守要看工程的实际情况。工程上多有为了效率而牺牲空间的例子，这些情况下数据库甚至可能不符合1NF。 此外还有BCNF、4NF直至5NF。这些范式的强度依次增强，冗余越低。 3.分布式系统CAP定理 CAP定理是分布式系统中的一个基本定理，它指出任何分布式系统最多可以具有以下三个属性中的两个。 一致性（Consistency） 在一个一致性的系统中，客户端向任何服务器发起一个写请求，将一个值写入服务器并得到响应，那么之后向任何服务器发起读请求，都必须读取到这个值(或者更加新的值)。 可用性（Availability） 在一个可用的分布式系统中，客户端向其中一个服务器发起一个请求且该服务器未崩溃，那么这个服务器最终必须响应客户端的请求。 分区容错性（Partition tolerance） 能容忍网络分区，在网络断开的情况下，被分隔的节点仍能正常对外提供服务。 CA 保证一致性和可用性，所有服务器必须互相通信才可以。所以丧失P属性。 CP 在网络分区（服务器无法通信）的情况下，为了保证C属性，只等设定一组服务器上的副本为可用的，其他分区的服务器为不可用，所以丧失A属性。 AP 在网络分区（服务器无法通信）且所有服务器都保证可用的情况下，无法保证数据一致，丧失C属性。 4.灾备 RAID0 （不含校验码的条带存储） RAID 0 又称为Stripe（条带化），它在所有RAID级别中具有最高的存储性能，通过多块磁盘组合为RAID 0后，数据被分割并分别存储在每块硬盘中，所以能最大程度的提升存储性能与存储空间，把连续的数据分散到多个磁盘上存取，这样，系统有数据请求就可以被多个磁盘并行的执行，每个磁盘执行属于它自己的那部分数据请求，这种数据上的并行操作可以充分利用总线的带宽，显著提高磁盘整体存取性能，但是无法容错。 优：速度快、无冗余、读写并行、磁盘利用率100%。 缺：没有备份，没有灾备能力。 RAID 1 （不含校验码的镜像存储） RAID 1 又称为Mirror 或Mirrooring(镜像)，它的宗旨是最大限度的保证用户数据的可用性和可修复性，RAID 1 的操作方式是把用户写入硬盘的数据百分之百的自动复制到另外一个硬盘上，从而实现存储双份的数据。 优：保证了数据冗余，保证了数据安全，可靠性高，可以并发读取（相当于两块RAID 0）。 缺：写入效率低下，磁盘利用率低。 RAID 5 （数据块级别的分布式校验条带存储） RAID 5 是一种存储性能，数据安全和存储成本兼顾的存储解决方案。RAID5技术是把硬盘设备的数据奇偶校验信息保存到其他硬盘设备中。RAID5磁盘阵列组中数据的奇偶校验信息并不是单独保存到某一块磁盘设备中，而是存储到除自身以外的其他每一块对应的磁盘上，这样的好处是其中任何一个磁盘损坏后不至于出现致命缺陷，但只能允许一块磁盘损坏，否则无法利用剩下的数据和校验信息进行数据的恢复。 优：RAID0和RAID1的折中，兼顾存储性能、数据安全和存储成本。 缺：写入性能相对较差，而且只允许单磁盘故障，在有磁盘离线的情况下，RAID 5 的读写性能较差，在重建数据时，性能会受到较大的影响。 RAID 6 （两种存储的奇偶校验码的磁盘结构） RAID6技术是在RAID 5基础上，为了进一步加强数据保护而设计的一种RAID方式，实际上是一种扩展RAID 5等级。与RAID 5的不同之处于除了每个硬盘上都有同级数据XOR校验区外，还有一个针对每个数据块的XOR校验区。与RAID 5 相同的是当前磁盘数据块的校验数据不可能存在当前磁盘中，而是交错存储的。组建RAID 6 要求至少4块硬盘，而RAID 6可以允许坏掉两块硬盘。 优：RAID 6的数据冗余性能相当好，在使用大数据块时，随机读取性能好，允许两块硬盘的掉线，有更高的容错能力。 缺：由于增加了一个校验，所以写入的效率比RAID 5还差，而且RAID控制系统的设计也更为复杂，第二块的校验区也减少了硬盘有效存储空间。 RAID 10（镜像与条带存储） RAID 10 不是独创的一种RAID级别，它由RAID 1 和 RAID 0 两种阵列形式组合而成，RAID 10继承了RAID 0 的快速与高效，同时也继承了RAID 1 的数据安全，RAID 10 至少需要四块硬盘。RAID 1+0，先使用四块硬盘组合成两个独立的RAID 1 ，然后将两个RAID 1 组合成一个RAID 0。 优: RAID10兼备了RAID1和RAID0的优点，不仅实现了数据保障的作用，也保障数据读写的效率。 缺: 由于一半的磁盘空间都用于存储冗余数据，所以RAID 10的磁盘利用率很低，只有50%。 RAID 50 RAID50是RAID5与RAID0的结合。此配置在RAID5的子磁盘组的每个磁盘上进行包括奇偶信息在内的数据的剥离。每个RAID5子磁盘组要求至少三个硬盘。RAID50具备更高的容错能力，因为它允许某个组内有一个磁盘出现故障，而不会造成数据丢失。 优： 比RAID5有更好的读性能，比相同容量的RAID5重建时间更短，可以容许N个磁盘同时失效，更高的容错能力，具备更快数据读取速率的潜力。 缺： 设计复杂，比较难实现；同一个RAID5组内的两个磁盘失效会导致整个阵列失效；磁盘故障会影响吞吐量。故障后重建信息的时间比镜像配置情况下要长。 在这里插入图片描述 5.Mysql数据库框架与引擎 5.1 Mysql Framework 5.1.1 框架 在这里插入图片描述 MySQL 可以分为 Server 层和存储引擎两部分。 Server 层包括：连接器、查询缓存、分析器、优化器、执行器等，涵盖了 MySQL 的大多数核心服务功能，以及所有的内置函数（如：日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这⼀层实现，比如：存储过程、触发器、视图等等。 存储引擎层负责：数据的存储和提取。其架构是插件式的，⽀持 InnoDB 、 MyISAM 等多个存储引擎。从 MySQL5.5.5 版本开始默认的是 InnoDB ，但是在建表时可以通过 engine = MyISAM 来指定存储引擎。不同存储引 擎的表数据存取方式不同，支持的功能也不同。 5.1.2 InnoDB &amp; MyISAM MyISAM是 MySQL 的默认数据库引擎（ 5.5版之前）。虽然性能极佳，而且提供了大量的特性， 包括全文索引、压缩、空间函数等，但 MyISAM不支持事务和行级锁，而且最⼤的缺陷就是崩溃后无法安全恢复。不过， 5.5 版本之后， MySQL 引入了 InnoDB （事务性数据库引擎），MySQL5.5 版本后默认的存储引擎为 InnoDB 。 InnoDB vs MyISAM 是否支持行锁 MyISAM只有表锁，InnoDB支持行锁和表锁，默认为行锁。 是否支持事务 MyISAM不提供事物支持，InnoDB支持。同时，InnoDB具备rollback、crash recovery能力。 是否支持外键 MyISAM不支持，InnoDB支持。 是否支持MVCC 仅InnoDB支持。 总之一句话：MyISAM注重效率，而InnoDB更意图保证并行下的数据完整性 5.2 Lock in Mysql InnoDB中支持表锁和行锁，而MyISAM仅支持表锁。InnoDB中的表锁和行锁都分为S锁和X锁。 表锁 Mysql中锁定 粒度最大 的一种锁，对当前操作的整张表加锁，实现简单 ，资源消耗也比较少，加锁快，不会出现死锁 。此外表锁还存在意向锁： 而意向锁的作用就是当一个事务在需要获取资源锁定的时候，如果遇到自己需要的资源已经被排他锁占用的时候，该事务可以在需要锁定行的表上面添加一个合适的意向锁。如果自己需要一个共享锁，那么就在表上面添加一个意向共享锁。而如果自己需要的是某行（或者某些行）上面添加一个排他锁的话，则先在表上面添加一个意向排他锁。意向共享锁可以同时并存多个，但是意向排他锁同时只能有一个存在。 意向共享锁（IS）： 表示事务准备给数据行记入共享锁，事务在一个数据行加共享锁前必须先取得该表的IS锁。 意向排他锁（IX）： 表示事务准备给数据行加入排他锁，事务在一个数据行加排他锁前必须先取得该表的IX锁。 意向锁vs普通锁：意向锁是放置在资源层次结构的一个级别上的锁，如果想要下级资源（如表中的行）加锁，则需要先将上级资源加上意向锁。（把资源层级看作一棵树，要给某个节点加锁，则其祖先必须先加意向锁。）如果一个上级资源被加了意向锁，则证明某下级资源被加锁。 行锁 Mysql中锁定 粒度最小 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。 Record Lock 对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项 Gap Lock 对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁）。（即在两个索引之前加锁） Next-key Lock 锁定索引项本身和索引范围。即Record Lock和Gap Lock的结合。可解决幻读问题。 5.3 数据库索引 5.3.1 聚簇索引（InnoDB）和非聚簇索引（MyISAM） 聚簇索引 将数据存储与索引放到了一块，索引结构的叶子节点保存了行数据。表数据按照索引的顺序来存储的，也就是说索引项的顺序与表中记录的物理顺序一致。它默认的实现是这个主键索引。主键索引就是聚簇索引他实现之一，如果你这个表里没有这个主键索引，InnoDB就会选择一个唯一的非空索引代替。 如果连唯一的索引都没有的话，这个InnoDB就会在内部生成一个隐式的聚簇索引。 非聚簇索引 将数据与索引分开存储，索引结构的叶子节点指向了数据对应的位置。 InnnDB中，会在主键建立聚簇索引。当在其他键建立索引时，InnoDB是这么干的：建立一个二级索引，这个索引可以通过其他建值索引到主键，然后在使用主键再索引数据。 在MyISAM中，采用非聚簇索引，即索引的叶子节点是行指针，指向对应的行。 聚簇索引 vs 非聚簇索引 聚簇索引优点： 快速数据访问：由于数据物理存储顺序与索引顺序一致，相邻数据行通常存储在同一磁盘块中，减少了I/O操作次数，提高了查询速度。 高效存储：聚簇索引的叶子节点存储的是数据行本身，对于不需要查询全部列的查询语句，可以减少I/O操作，提高查询效率。 排序查找快速：对于主键的排序查找和范围查找，聚簇索引表现出色。 聚簇索引缺点： 插入和更新性能：插入和更新数据时需要移动其他数据行，这可能导致性能下降。 数据访问局限性：如果数据不是按照索引顺序存储的，某些数据访问可能会较慢。 主键更新代价高：更新主键时，需要移动被更新的行，这可能导致性能下降。 非聚簇索引优点： 插入和更新效率：插入和更新数据时不需要移动数据，因此不会影响性能。 维护简单：在表的数据发生变化时，不需要重新组织索引结构，减少维护索引的时间。 非聚簇索引缺点： 查询效率：查询时需要进行两次磁盘I/O操作：第一次查找索引条目，第二次查找实际数据行，这使得查询效率相对较低。 简而言之：聚簇索引查快改慢，非聚簇索引查慢改快 5.3.2 索引数据结构 MySQL索引使用的数据结构主要有 BTree 索引 和 哈希索引 。对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree 索引。 MySQL的 BTree 索引使用的是 B 树中的 B+Tree，但对于主要的两种存储引擎的实现方式是不同的。 BTree和B+Tree以及散列表详细介绍见数据结构章节 为什么MySql采用B+Tree而不是BTree 用 B+ 树不用 B 树考虑的是 IO 对性能的影响， B 树的每个节点都存储数据，而 B+ 树只有叶子节点才存储数据，所 以查找相同数据量的情况下， B 树所需要的内存更大， IO 更频繁。数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存了，只能逐⼀加载每⼀个磁盘页（对应索引树的节点）。 自适应哈希索引 哈希索引能以 O(1) 时间进行查找，但是失去了有序性。无法用于排序与分组、只⽀持精确查找，无法用于部分查找和范围查找。InnoDB 存储引擎有⼀个特殊的功能叫 “自适应哈希索引 ” ，当某个索引值被使用的非常频繁时，会在 B+ 树索引之上 再创建⼀个哈希索引，这样就让 B+Tree 索引具有哈希索引的⼀些优点，比如：快速的哈希查找。 InnoDB B+树 可以存放多少行数据 InnoDB的默认最小存储单位为16k。假设每条记录占用空间为1k。一个高度为2个B+Tree包括一个根节点（16k），在其中存储多项（主键+指针）的组合。由于InnoDB默认主键为bigint 8字节，指针为硬编码的6字节，所以每条记录为14字节。根节点共存储16384/14=1170个子节点指针。而叶子节点用于存储数据，前面假设每条记录为1k，所以一个节点可以存储16k/1k=16条数据。因此，高度为2的B+Tree共计存储1170 * 16 = 18720条记录。同理可知高度为3个B+Tree可存储1170* 1170 *16=21902400条记录。 InnoDB单表最多可以存储多少数据 自建主键的情况下取决于主键类型的最大值，例如主键为int(4)，那就是4字节int的最大值。如果超过则报错。 没有主键自动生成一个隐藏主键int(6)，如果超过则会覆盖之前的数据而不会报错。 B+Tree vs BTree（为什么MySql选择B+Tree而不是BTree？） B+树非叶子节点只存储key值，而B树存储key值和data值，这样B+树每次读取时可以读取到更多的key值。 mysql进行区间访问时，由于B+树叶子节点之间用指针相连，只需要遍历所有的叶子节点即可；而B树则需要中序遍历那样遍历 B+树非叶子节点只存储key值，而B树存储key值和data值，导致B+树的层级更少，查询效率更高 B+树所有关键词地址都存在叶子节点上，所以每次查询次数都相同，比B树稳定 B+Tree vs Hash （Hash明明更快O(1)，MySql为什么选择B+Tree而不是Hash？） 磁盘IO特性：从内存角度上说，数据库中的索引一般时在磁盘上，数据量大的情况可能无法一次性装入内存，B+树的设计可以允许数据分批加载。 Hash不适应多条范围查询：从业务场景上说，如果只选择一个数据那确实是hash更快，但是数据库中经常会选中多条这时候由于B+树索引有序，并且又有链表相连，它的查询效率比hash就快很多了。 MySql也支持Hash索引（默认是B+Tree），如前文所述，它仅在单条查询占比较大的情况下比较快。 B+Tree vs 红黑树 （内存中，红黑树优于B+Tree。为什么Mysql选择B+Tree？） 操作系统IO特性：操作系统所组织的文件系统最小单位为页，即使只需要该页内的部分数据，也需要整页读取。而红黑树是二叉树，仅有两个孩子节点，无法充分利用单页的存储空间。而B+Tree是多叉树，单节点可以挂载很多孩子，在充分利用单页存储空间的同时减少树的高度，减少了IO次数。 ps.有关hash、BTree、红黑树的详细介绍移步数据结构.md 5.3.3 索引分类总结 从数据结构角度：1）B+Tree索引O(logn) 2) Hash索引 O(1) 从物理存储角度：1）聚簇索引 2）非聚簇索引 5.3.4 索引可用性 最左前缀原则 最左前缀原则（Leftmost Prefix Rule）是索引在数据库查询中的一种使用规则。它指的是在使用复合索引时，查询条件需要遵循索引中列的顺序，从左到右进行匹配。只有当查询条件满足最左前缀原则时，才能充分利用联合索引的优势，提高查询性能。 例如索引组(a,b,c)。当查询(a,c)时，仅有a索引可以被利用，而由于b被跳过了，所以c索引无法被利用。 再例如，查询(b,c)时，所有索引均不会被利用，这是由于a被跳过了。形式来讲当存在索引组： 而对于查询： 如果,则仅有前个索引可以被利用。 此外最左前缀碰到范围查询时也会停止！后面的索引都不会用到。 如何知道创建的索引有没有被用到？或是说怎么排除语句运行慢的原因？ 使用 Explain 命令来查看语句的执行计划，MySQL 在执行某个语句之前，会将该语句过⼀遍查询优化器，之后会拿到对语句的分析，也就是执行计划，其中包含了许多信息。可以通过其中和索引有关的信息来分析是否命中了索引，例如： possilbe_key 、 key 、 key_len 等字段，分别说明了此语句可能会使用的索引、实际使用的索引以及使用的索引长度。 会导致索引失效的情况？ 索引参与表达式或函数计算 通配符 字符串和数字比较无法利用索引 or语句中如果有一项没有索引，则另一项索引失效 正则 优化器判定全表扫描更快时不用索引 查询优化方案？ 减少请求量：仅返回必要的列和行 内存侧缓存：讲频繁查询的记录存储在内存中 使用链接（join）而不是子查询 使用union而不是or 避免范围查询：甚少在where子句中使用!=, &lt;, &gt; 避免null值判断：这会迫使引擎采用全表扫描而不是索引 索引优缺点（何时应该怎样应该建立索引？） 需要查询、排序、分组和联合操作的字段适合建立索引。 使用字段值不重复比例大的字段建立索引，联合索引比独立索引的效率高。 索引越多，维护成本越高，数据修改的效率越低。 唯一性索引可以确保数据唯一性。 索引可以加快表的链接效率，在实现参照完整性的方面具有特别意义。 5.4 主从复制 5.4.1 概念 主从复制，是用来建立一个和主数据库完全一样的数据库环境，称为从数据库，主数据库一般是准实时的业务数据库。 5.4.2 Binlog 从比较宽泛的角度来探讨复制的原理，MySQL的Server之间通过二进制日志来实现实时数据变化的传输复制，这里的二进制日志是属于MySQL服务器的日志，记录了所有对MySQL所做的更改。这种复制模式也可以根据具体数据的特性分为三种： Statement：基于语句格式 Statement模式下，复制过程中向获取数据的从库发送的就是在主库上执行的SQL原句，主库会将执行的SQL原有发送到从库中。 Row：基于行格式 Row模式下，主库会将每次DML操作引发的数据具体行变化记录在Binlog中并复制到从库上，从库根据行的变更记录来对应地修改数据，但DDL类型的操作依然是以Statement的格式记录。 Mixed：基于混合语句和行格式 MySQL 会根据执行的每一条具体的 SQL 语句来区分对待记录的日志形式，也就是在 statement 和 row 之间选择一种。 目前互联网业务的在线MySQL集群全部都是基于Row行格式的Binlog。虽然这种模式下对资源的开销会偏大，但数据变化的准确性以及可靠性是要强于Statement格式的，同时这种模式下的Binlog提供了完整的数据变更信息，可以使其应用不被局限在MySQL集群系统内。（泛用性强） 5.4.3 主从复制的流程 在这里插入图片描述 首先从库启动I/O线程，跟主库建立客户端连接。 主库启动binlog dump线程，读取主库上的binlog event发送给从库的I/O线程，I/O线程获取到binlog event之后将其写入到自己的Relay Log中。 从库启动SQL线程，将等待Relay中的数据进行重放，完成从库的数据更新。 为什么存在Relay Log而不是直接commit？ 在MySQL 4.0 之前是没有Relay Log这部分的，整个过程中只有两个线程。但是这样也带来一个问题，那就是复制的过程需要同步的进行，很容易被影响，而且效率不高。例如主库必须要等待从库读取完了才能发送下一个binlog事件。这就有点类似于一个阻塞的信道和非阻塞的信道。 主从复制的好处？ 实现复杂均衡 实现异地备份 提高数据库可用性（？不就是均衡负载） 主库宕机后，数据可能丢失，从库只有一个sql Thread，主库写压力大，复制可能延迟。 解决方法： 半同步复制 解决数据丢失问题 并行复制 解决从库复制延迟的问题（多个SQL程序并行执行） 异步复制（Asynchronous replication） MySQL默认的复制即是异步的，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主如果crash掉了，此时主上已经提交的事务可能并没有传到从上，如果此时，强行将从提升为主，可能导致新主上的数据不完整。 全同步复制（Fully synchronous replication） 指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。 半同步复制（Semisynchronous replication） 介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log中才返回给客户端。相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用。 5.4.4 数据库读写分离 读写分离常用代理放式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。主服务器处 理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。 为什么进行读写分离？ 各自读写，极大程度缓解锁争用。 从服务器可以使用MyISAM引擎，提高查询效率。 增加冗余，增强可用性。 5.4.5 主从同步延迟 原因： 假如⼀个服务器开放 Ｎ 个连接给客户端，这样有会有大量并发的更新操作, 但是从服务器的里面读取 binlog 的线程仅有⼀个， 当某个 SQL 在从服务器上执行的时间稍长或者由于某个 SQL要 进行锁表就会导致主服务器的 SQL 大量积压，未被同步到从服务器里。这就导致了主从不⼀致， 也就是主从延迟。 解决方法： 在对数据安全要求不是很高的情况下关闭从服务器的sync_binlog。 增加服务器。（？神经） 5.5 MySQL执行分析 5.5.1 MySql基本执行框架 先简单介绍一下下图涉及的一些组件的基本作用帮助大家理解这幅图，在 1.2 节中会详细介绍到这些组件的作用。 连接器： 身份认证和权限相关(登录 MySQL 的时候)。 查询缓存: 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。 分析器: 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。 优化器： 按照 MySQL 认为最优的方案去执行。 执行器: 执行语句，然后从存储引擎返回数据。 在这里插入图片描述 5.5.2 Server层 连接器 连接器主要和身份认证和权限相关的功能相关，主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作，如果用户账户密码已通过，连接器会到权限表中查询该用户的所有权限，之后在这个连接里的权限逻辑判断都是会依赖此时读取到的权限数据，也就是说，后续只要这个连接不断开，即时管理员修改了该用户的权限，该用户也是不受影响的。 查询缓存（MySql 8.0后移除） 查询缓存主要用来缓存我所执行的 SELECT 语句以及该语句的结果集。 连接建立后，执行查询语句的时候，会先查询缓存，MySQL 会先校验这个 sql 是否执行过，以 Key-Value 的形式缓存在内存中，Key 是查询预计，Value 是结果集。如果缓存 key 被命中，就会直接返回给客户端，如果没有命中，就会执行后续的操作，完成后也会把结果缓存起来，方便下一次调用。当然在真正执行缓存查询的时候还是会校验用户的权限，是否有该表的查询条件。 移除原因：不常用，表更新后缓存会清空。 分析器（相当于编译前端） 对sql语句进行解释，分为两个步骤： 词法分析，提取关键字，比如 select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。 语法分析，讲词法分析得出的词串串联分析语义信息，检查语法是否正确。 优化器（相当于编译后端） 优化器的作用就是它认为的最优的执行方案去执行。 执行器 执行器会首先校验用户权限，如果鉴权通过则调用引擎接口。 5.5.3 Log系统 进行更新操作时需要同时记录日志，MySql（InnoDB引擎）有两个日志系统Binlog（Server层执行器的）和Redolog（InnoDB引擎的）。 更新流程如下： 引擎查询到要修改的数据。 修改目标数据 引擎记录Redolog，Redolog进入prepare状态，并告诉执行器执行完成。 执行器收到通知后记录Binlog，随后调用引擎，提交Redolog为提交状态。 为何要有两个日志系统？ 令InnoDB具有crash-safe能力。这里分析两种情况： 先写Redolog直接提交，然后写Binlog，假设写完 redo log 后，机器挂了，binlog 日志没有被写入，那么机器重启后，这台机器会通过 redo log 恢复数据，但是这个时候 bingog 并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。 先写 Binlog，然后写 Redolog，假设写完了 binlog，机器异常重启了，由于没有 redo log，本机是无法恢复这一条记录的，但是 binlog 又有记录，那么和上面同样的道理，就会产生数据不一致的情况。 6. 数据库设计规范 6.1 数据库命名规范 所有数据库对象名称必须使用小写字母并用下划线分割 所有数据库对象名称禁止使用 MySQL 保留关键字（如果表名中包含关键字查询时，需要将其用单引号括起来） 数据库对象的命名要能做到见名识意，并且最好不要超过 32 个字符 临时库表必须以 tmp_为前缀并以日期为后缀，备份表必须以 bak_为前缀并以日期 (时间戳) 为后缀 所有存储相同数据的列名和列类型必须一致（一般作为关联列，如果查询时关联列类型不一致会自动进行数据类型隐式转换，会造成列上的索引失效，导致查询效率降低） 6.2 数据库设计规范 使用InnoDB存储引擎 数据库和表的字符集统一使用 UTF8 所有表和字段加注释 尽量控制单表数据量大小，控制在500万以内。 可以使用历史数据归档、分库分表等手段控制数据量 谨慎使用分区表 分离冷热数据，减小表宽度 不要预留字段 不能存储图片、文件等大二进制数据 禁止在线上做压力测试 禁止从开发环境、测试环境链接生成环境数据库 7. ClickHouse 7.1 概念 ClickHouse是高性能、MPP架构、列式存储、完备DBMS功能的OLAP数据库 特点 高性能 分布式框架 支持SQL 支持多种数据类型 支持多种压缩算法 免费开源 其中几个名词的解释： MPP架构 MPP架构（Massively Parallel Processing）是一种设计用于处理大规模数据集的计算架构，其核心思想是将数据处理任务分布在多个处理器上以实现并行计算，从而获得高性能和可扩展性。这种架构的主要优势包括 高性能。通过在多个处理器上同时执行任务，MPP架构能够实现高吞吐量和低延迟，显著加速计算过程。 可扩展性。通过增加更多处理器，MPP架构可以扩展系统的计算能力，满足不断增长的数据处理需求。 容错能力。MPP架构通过在多个处理器上冗余数据和计算任务，提高系统的容错性，确保在部分处理器故障时系统的稳定性。 MPP架构可以分为不同的类别，包括共享存储和分布式存储两类。共享存储MPP架构中，所有处理器都连接到同一个共享存储系统，使用高速互联网络进行通信，优点是能够实现高速数据访问，但可能存在存储系统性能瓶颈。分布式存储MPP架构中，每个处理器都有其自己的本地存储系统，也通过高速互联网络进行通信，优点是避免了存储系统成为性能瓶颈，但可能需要更复杂的数据分布和通信机制。 MPP架构广泛应用于多个领域，如大数据处理、机器学习、金融风险管理等，在大数据处理方面，它能够有效地处理大量数据，特别是在需要实时分析和处理的场景下；在机器学习和人工智能方面，它能够加速训练和推理过程；在金融风险管理方面，它帮助金融机构快速处理交易数据以实现高效风险管理。 缺点：存储不透明、单节点瓶颈 在设计上，MPP架构优先考虑一致性（Consistency），其次考虑可用性（Availability），同时尽量做到分区容错性（Partition Tolerance）。即保证CA属性。MPP架构常用于数据仓库、数据集市、大数据分析等场景，其分布式设计能够有效应对数据规模的不断增长和复杂度的提高，但也会面临一些挑战。 分布式架构 分布式架构是一种将计算任务并发分散到多个计算节点上的计算架构，主要用于处理大规模数据和复杂计算问题。这种架构也常称为大数据架构或分布式批处理架构，并且包含多个具体实现，如Hadoop、Spark等。在设计上，分布式系统通常会优先考虑分区容错性（Partition Tolerance），其次考虑可用性（Availability），尽量做到一致性（Consistency）。即保证AP属性 DBMS 即Database Management System。 数据库管理系统(Database Management System)是一种操纵和管理数据库的大型软件，用于建立、使用和维护数据库。 OLAP &amp; OLTP OLAP（联机分析处理）和OLTP（联机事物处理） OLTP旨在高效地处理日常的事务，如银行交易、订单处理等，它强调的是事务的处理速度和实时性，主要用于事务数据的录入和实时处理（注重实时处理） OLAP则用于处理大规模数据，支持复杂的数据分析和决策支持，强调从历史数据中提取洞察力，主要用于查询、报表生成和数据分析（注重历史分析） 在这里插入图片描述 其中，OLAP还可分为ROLAP（关系型OLAP）和MOLAP。MOLAP是指带预先结果统计和存储的OLAP，是一种以空间换时间的做法。此外还有HOLAP（细节数据存储在ROLAP，聚合数据存储在MOLAP）。 列式存储 在传统的行式存储中，数据按照行的方式存储，即将每个记录的各个字段按顺序存储在一起，每行数据占用的存储空间相对较大。而列式存储是将每列的数据存储在一起，优：可以单独进行压缩与解码，占用的存储空间更少，查询效率更高。 7.2 ClickHouse的优缺点 优：查询速度快，可以在存储数据超过20万亿行的情况下，做到了90%的查询能够在1秒内返回。支持高级数据类型，支持自定义函数和聚合函数，支持多种存储引擎。 缺点：针对OLTP业务场景的支持有限： 不支持事物 不擅长根据主键按行粒度进行查询（但支持） 不擅长按行删除数据（但支持）（？内部数据结构和线段树差不多） 7.3 ClickHouse高效查询的原因 列式存储与数据压缩 减少数据扫描范围和数据传输时的大小，列式存储和数据压缩就可以做到这两点。 向量化执行 消除程序中循环的优化，是基于底层硬件实现的优化。 多样化引擎 与MySQL类似，ClickHouse也将存储部分进行了抽象，把存储引擎作为一层独立的接口。目前ClickHouse共拥有合并树、内存、文件、接口和其他6大类20多种表引擎。每一种表引擎都有着各自的特点，用户可以根据实际业务场景的要求，选择合适的表引擎使用。 多线程与分布式 多线程处理就是通过线程级并行的方式实现了性能的提升，ClickHouse将数据划分为多个partition，每个partition再进一步划分为多个index granularity，然后通过多个CPU核心分别处理其中的一部分来实现并行数据处理。这种设计下，可以使得ClickHouse单条Query就能利用整机所有CPU，极致的并行处理能力，极大的降低了查询延时。 7.4 ClickHouse执行过程 在这里插入图片描述 简单来说，就是一条sql,会经由Parser与Interpreter，解析和执行，通过调用Column、DataType、Block、Functions、Storage等模块，最终返回数据，下面是各个模块具体的介绍。 Columns 表示内存中的列（实际上是列块），需使用 IColumn 接口。该接口提供了用于实现各种关系操作符的辅助方法。几乎所有的操作都是不可变的：这些操作不会更改原始列，但是会创建一个新的修改后的列。 Field 表示单个值，有时候也可能需要处理单个值，可以使用Field。Field 是 UInt64、Int64、Float64、String 和 Array 组成的联合。与Column对象的泛化设计思路不同，Field对象使用了聚合的设计模式。在Field对象内部聚合了Null、UInt64、String和Array等13种数据类型及相应的处理逻辑。 DataType IDataType 负责序列化和反序列化：读写二进制或文本形式的列或单个值构成的块。IDataType直接与表的数据类型相对应。比如，有 DataTypeUInt32、DataTypeDateTime、DataTypeString等数据类型。 Storage IStorage接口表示一张表。该接口的不同实现对应不同的表引擎。比如StorageMergeTree、StorageMemory等。这些类的实例就是表。 Parser与Interpreter Parser和Interpreter是非常重要的两组接口：Parser分析器负责创建AST对象；而Interpreter解释器则负责解释AST，并进一步创建查询的执行管道。它们与IStorage一起，串联起了整个数据查询的过程。Parser分析器可以将一条SQL语句以递归下降的方法解析成AST语法树的形式。不同的SQL语句，会经由不同的Parser实现类解析。例如，有负责解析DDL查询语句的ParserRenameQuery、ParserDropQuery和ParserAlterQuery解析器，也有负责解析INSERT语句的ParserInsertQuery解析器，还有负责SELECT语句的ParserSelectQuery等。 7.5 ClickHouse表引擎 7.5.1 合并树引擎 Clickhouse中最强大的表引擎当属MergeTree（合并树）引擎及该系列（MergeTree）中的其他引擎。 MergeTree系列的引擎被设计用于插入极大量的数据到一张表当中。数据可以以数据片段的形式一个接着一个的快速写入，数据片段在后台按照一定的规则进行合并。相比在插入时不断修改（重写）已存储的数据，这种策略会高效很多。 特点 存储的数据按主键排序。这使得您能够创建一个小型的稀疏索引来加快数据检索。 如果指定了分区键的话，可以使用分区。在相同数据集和相同结果集的情况下ClickHouse中某些带分区的操作会比普通操作更快。查询中指定了分区键时ClickHouse会自动截取分区数据。这也有效增加了查询性能。 支持数据副本。ReplicatedMergeTree系列的表提供了数据副本功能。 支持数据采样。需要的话，您可以给表设置一个采样方法。 引擎名称 说明 MergeTree 适用于查询性能要求较高的数据表，如：时间序列数据。它有一个优化排序和合并的技术，从而提高数据查询速度。 CollapsingMergeTree 与 MergeTree 相似，但是在累加数据值方面更有优势。它可以在查询中合并多个数据值。 SummingMergeTree 与 CollapsingMergeTree 相似，但它专门用于对数值累加。 ReplacingMergeTree 适用于在数据表中替换某些数据值。如果数据表中存在与新数据重复的键，则它将替换该数据。 GraphiteMergeTree 适用于操作时间序列数据，如：Graphite 应用。它对时间序列数据查询具有较高的性能。 VersionedCollapsingMergeTree 适用于数据版本控制，并且可以在多个版本之间查询数据。 Memory 将数据存储在 RAM 中，因此数据查询速度比磁盘存储快得多。不过，由于它是在内存中存储数据，因此它通常不适用于大数据量的数据表。 Buffer 缓存引擎，用于存储缓存表。适用于中间结果，可以在内存和磁盘之间快速切换 相对于内存引擎的读写速度较慢，数据不能永久保存。 7.5.2 日志引擎 用于日志存储的存储引擎，这些引擎是为了需要写入许多小数据量（少于一百万行）的表的场景而开发的。 这系列的引擎有： StripeLog Log TinyLog 特点 数据存储在磁盘上。 写入时将数据追加在文件末尾。 不支持突变操作,也就是更新。 不支持索引。 这意味着 SELECT 在范围查询时效率不高。 非原子地写入数据。 如果某些事情破坏了写操作，例如服务器的异常关闭，你将会得到一张包含了损坏数据的表。 7.6 高级数据结构 ClickHouse支持多种数据类型，包括基本数据类型、复合数据类型和几何数据类型。 在这里插入图片描述 7.7 CilckHouse vs 传统关系型数据库 ClickHouse的数据模型是基于表的，与创建表时指定的数据存储类型和存储引擎有关，支持多种高级数据类型。 ClickHouse的数据模型是列式存储的（传统关系型数据库为行式存储），每个列可以单独进行压缩与解码，存储空间更少，查询效率高。 ClickHouse是OLAP数据库，用于处理大规模数据，支持复杂的数据分析和决策支持，强调从历史数据中提取洞察力，主要用于查询、报表生成和数据分析（注重历史分析，查统增改快，删慢） OLTP能力有限，不支持事物。 7.8 DDL &amp; DML ClickHouse的DDL和DML是ClickHouse SQL，它与传统的SQL具有很高的兼容性，但也有一些专门为ClickHouse设计的特殊语法和函数，以便更好地支持列式存储和分布式计算。 特点 支持多种查询 优化查询性能 支持高级数据结构 支持自定义函数和聚合函数 支持多种存储引擎 一个建表的例子 1234567CREATE TABLE encoded_data ( eventdate Date CODEC(Delta, LZ4), event_type String CODEC(ZSTD), value UInt32) ENGINE = MergeTree()ORDER BY event_datePARTITION BY(event_type); 大部分与SQL标准一致，其中CODEC指定改列的数据压缩和数据编码方法。ENGINE=MergeTree()用于指定数据存储引擎。 ORDER BY event_date是指将会按照event_date这一字段排序。 PARTITION BY(event_type) 是指数据会通过event_type这一字段进行分区。 7.9 数据压缩与编码 7.9.1 数据压缩 数据压缩是通过消除数据中的冗余信息来减少数据大小的过程。在ClickHouse中，数据压缩主要通过两种压缩算法实现：LZ4和ZSTD。 LZ4（默认压缩算法） LZ4是一种无损压缩算法，它提供了较高的压缩速度和较低的解压缩速度。LZ4适用于大多数场景，因为它可以在不影响查询性能的情况下显著减少存储空间。 ZSTD ZSTD（Zstandard）是一种无损压缩算法，它提供了较高的压缩比和较低的解压缩速度。相比LZ4，ZSTD可以进一步减少存储空间，但解压缩速度较慢。ZSTD适用于对存储空间有严格要求的场景。 压缩率：LZ4 &lt; ZSTD 解压速度：LZ4 &gt; ZSTD 7.9.2 数据编码 数据编码是通过对数据进行转换来减少数据大小的过程。在ClickHouse中，数据编码主要通过两种技术实现：Delta和Gorilla。 Delta Delta编码是一种差分编码技术，它通过存储相邻数据之间的差值来减少数据大小。Delta编码适用于具有连续值或递增值的数据，如时间序列数据。在ClickHouse中，Delta编码可以与LZ4或ZSTD压缩算法结合使用，以进一步减少存储空间。 Gorilla Gorilla编码是一种专为时间序列数据设计的编码技术，它通过存储相邻数据之间的XOR值来减少数据大小。与Delta编码相比，Gorilla编码可以实现更高的压缩比，但仅适用于时间序列数据。在ClickHouse中，Gorilla编码可以与LZ4或ZSTD压缩算法结合使用，以进一步减少存储空间。 7.10 分布式结构 7.10.1 角色 ClickHose是一个分布式系统，内含多种角色的服务器。 在这里插入图片描述 7.10.2 本地表和分布式表 本地表 当使用一般的CREATE语句进行建表时，所建立的表只会存在在一台ClickHouse Server上，这种表称为本地表 分布式表 一个逻辑上的表, 可以理解为数据库中的视图, 一般查询都查询分布式表. 分布式表引擎会将我们的查询请求路由本地表进行查询, 然后进行汇总最终返回给用户。 为什么不在分布式表进行写入？ 分布式表接收到数据后会将数据拆分成多个parts，并转发数据到其他服务器，会引起服务器间网络流量增加、服务器merge的工作量增加，导致写入速度变慢，并且增加了Too many parts的可能性 数据的一致性问题，现在分布式表所在的机器进行落盘，然后异步的发送到本地表所在的机器上进行存储，中间没有一致性的校验，而且在分布式表所在机器如果集群出现down机，会存在数据丢失风险。 对zookeeper的压力比较大。 在实际生成环境中通常只读分布式表，写入本地表。 7.10.3 数据同步与查询（数据切片和冗余） Replication &amp; Sharding ClickHouse依靠ReplicatedMergeTree引擎族与ZooKeeper实现了复制表机制, 成为其高可用的基础。ClickHouse像ElasticSearch一样具有数据分片(shard)的概念, 这也是分布式存储的特点之一, 即通过并行读写提高效率。 ClickHouse依靠Distributed引擎实现了分布式表机制, 在所有分片（本地表）上建立视图进行分布式查询。 在这里插入图片描述 Shard（切片）：表内数据的一段 Replicated（冗余）：表内数据的一段副本。 Replicated Table &amp; ReplicatedMergeTree Engine ReplicatedMergeTree是支持实现高可用的Replicated Table（复制表）的引擎，ReplicatedMergeTree引擎族非常依赖于zookeeper, 它在zookeeper中存储了大量的数据。 Distributed Table &amp; Distributed Engine ClickHouse分布式表的本质并不是一张表,，而是一些本地物理表(分片)的分布式视图，本身并不存储数据.。分布式表建表的引擎为Distributed。 数据同步流程 在这里插入图片描述 写入到一个节点 通过interserver HTTP port端口同步到其他实例上 更新zookeeper集群记录的信息 数据查询流程 在这里插入图片描述 各个实例之间会交换自己持有的分片的表数据 汇总到同一个实例上返回给用户 写入去重 可复制表写入去重：注意，只有对于复制表系列才有写入去重机制，并不是所有的表都有写入去重机制的。可复制表的写入去重依赖于zookeeper。 clickhouse在zookeeper上的默认路径为 /clickhouse。对于可复制表的写入，每次写入，将所有写入的数据按照规则划分为一个个block，对每一个block计算一个校验和，将校验和存储在zookeeper的 /clickhouse/tables/分片号/数据库名/表名/blocks路径下（这个路径和 可复制表的参数也有关）的一个节点上。每次写入的时候，比较数据块的校验和已有的数据块校验和关系，用以判断写入数据是否重复。 ClickHouse支持哪些分布式部署方案，如何进行分布式查询？ ClickHouse支持以下几种分布式部署方案： 分片复制部署：将数据划分为多个分片，每个分片都有多个副本，每个副本都可以读写数据。在这种部署方案中，每个节点都可以执行查询，但只有主副本可以执行写操作。当主副本出现故障时，会自动切换到备副本。 分片无复制部署：将数据划分为多个分片，每个分片只有一个副本。在这种部署方案中，每个节点都可以执行查询和写操作。 复制无分片部署：所有数据都复制到每个节点上，每个节点都可以执行查询和写操作。这种部署方案适合小型集群和低并发查询。 分布式查询可以通过以下两种方式进行： 基于分布式查询引擎：ClickHouse提供了分布式查询引擎，允许用户在多个节点上并行执行查询，并将结果汇总到一个节点上。分布式查询引擎可以处理大量数据，并且可以根据查询的特点自动调整查询计划，提高查询性能。 基于分布式存储引擎：ClickHouse支持分布式存储引擎，可以将数据分布到多个节点上，实现数据的并行读取和写入。在这种情况下，查询可以在多个节点上执行，并通过网络传输数据进行计算。这种方法适用于需要在多个节点上分析大量数据的场景。 7.11 数据组织与索引 7.11.1 分区（Partition） 1234567CREATE TABLE encoded_data ( eventdate Date CODEC(Delta, LZ4), event_type String CODEC(ZSTD), value UInt32) ENGINE = MergeTree()ORDER BY event_datePARTITION BY(event_type); PARTITION BY(event_type) 是指数据会通过event_type这一字段进行分区。在ClickHouse进行数据组织存储时，会按照某个字段分组存储，这被称为分区。在上述例子中，encoded_data中的所有数据将会按照event_type分成数个组，分别进行存储。 在这里插入图片描述 为什么要分区？（分区优点） 提高查询速度，减少不必要额数据读取。where子句中查询某一类别只需要到该类别对应的分区查询即可。 7.11.2 列式存储 在传统的行式存储中，数据按照行的方式存储，即将每个记录的各个字段按顺序存储在一起，每行数据占用的存储空间相对较大。而列式存储是将每列的数据存储在一起。 为什么要用列式存储？（行式存储 vs 列式存储） 在进行OLAP业务有优势，在进行统计和查询时只取其中的几个列。而行式存储需要读取每一行的整个条目，然后在选择列。但是于此同时，对于记录的删除，修改则需要耗费更高的成本，这也是为什么Clickhouse不擅长删除的原因。 此外，列式存储更容易去做数据编码和压缩。 总而言之：列存储适合OLAP业务，行存储适合OLTP业务 7.11.3 MergeTree的数据组织和索引 数据组织 在这里插入图片描述 稀疏索引 稀疏索引是一套在设定的有序列上建立的索引。它是一个粗粒度索引，被记录在primay.idx。它每隔固定的行数建立一个索引指针指向当前行数。例如在下图中通过有序列age建立索引，其中每隔5列建立一个索引指针。适用稀疏索引可以快速确定所要查询的记录在表中的位置区域。在进行查询时先通过primay.idx获取要查询的区域序号，在通过各列的column.mrk2文件找到该区域的偏移量，随后到各列文件中的对应位置检索数据。 在这里插入图片描述 在这里插入图片描述 数据插入方法 当有新的一批数据插入分区时，并不会直接插入到原分区的各个列内，（Why？因为那样需要对分区重新排序，重新构建索引。）而是针对这新的一批数据建立一套独立的稀疏索引，然后挂载到MergeTree中。 在这里插入图片描述 此时要进行快速查询需要在每个part内部分别进行查询，然后将结果合并。 异步合并 为了不使part过多，ClickHouse会对同一个partition下的part进行异步合并。 ClickHouse的索引类型是什么，如何使用索引来提高查询性能？ ClickHouse支持以下三种索引类型： 稠密索引(Dense Index)：稠密索引是一种基于跳跃表的索引结构，用于在有序列上进行范围查询。在ClickHouse中，稠密索引使用较少的空间来存储数据，并且可以加快查询速度。 稀疏索引(Sparse Index)：稀疏索引是一种基于哈希表的索引结构，用于在无序列上进行查询。稀疏索引只在查询时创建，因此可以减少索引的空间占用。 索引光标(Index Cursor)：索引光标是一种用于加速聚合查询的技术。它允许ClickHouse在数据分片和节点之间进行快速分布式聚合查询。 ClickHouse的数据写入和数据删除是如何实现的？ 在往 ClickHouse 中写入数据时，它会先将数据写入的内存表中，当内存表达到一定的大小后，将内存表中的数据写入新的数据块中，根据数据的时间戳确定数据块的位置。当数据块达到一定大小后，会进行归并排序，存储到更大的数据块中，形成一个更大的分区，最终进行长期的存储。 ClickHouse 使用 alter table 关键字进行数据删除，它是一种逻辑删除。通过添加一个标记字段来区分数据是否被删除，并不会删除真正的数据，只有在分片时才会真正的清理。 ClickHouse的内存管理和垃圾回收机制是怎样的？ ClickHouse 采用自己实现的内存池来管理内存，这样可以快速地进行内存分配和回收。ClickHouse 也可以设置内存限制，以确保查询过程中不会耗尽系统内存，一旦达到内存限制，ClickHouse 将会自动开始垃圾回收，以释放一些内存。 ClickHouse 使用的是一种自适应的垃圾回收机制，当内存使用达到限制时会自动进行回收，选择尽可能少的数据进行回收，同时避免产生大量的垃圾数据。 ClickHouse如何处理时序数据和实时数据？ ClickHouse 支持专门的时序数据库引擎 —— MergeTree 引擎，该引擎是针对时间序列数据设计的，能够快速地处理基于时间的查询和聚合操作。 ClickHouse 提供了 Kafka 引擎，能够直接消费 Kafka 消息队列中的数据，并将其存储到 ClickHouse 中。还支持对实时数据进行预处理和聚合操作，从而实现实时数据分析和监控。 ClickHouse支持哪些数据导入和导出方式？ 支持csv、json、orc、parquet、MySQL等关系型数据库、NoSQL，还支持从消息队列和存储系统中导入和导出数据，例如：Kafka、Redis等。 7.11.4 向量化计算 向量化计算是一种特殊的并行计算方式。相比于一般程序在同一时间只执行一个操作的方式，它可以一次计算一组数据（向量）。SIMD(Single Instruction Multiple Data): 即单指令流多数据流。 7.12 物化视图 物化视图是包括一个查询结果的数据库对象，利用空间换时间。可以避免多基础表的频繁查询，尤其是固定查询。可以显著提高查询的性能。 一致性保证 物化视图保证了数据一致性，即原表数据发生改变，物化视图内的数据也会跟着改变。能够完成该特性的存储引擎是AggregatingMergeTree。 8. Redis 8.1 Redis简介与适用场景 Redis是一个key-value存储系统，它支持存储的value类型相对更多，包括string、list、set、zset（sorted set --有序集合）和hash。这些数据结构都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，Redis支持各种不同方式的排序。为了保证效率，数据都是缓存在内存中，Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave（主从）同步。 使用场景 Redis是基于内存的nosql数据库，可以通过新建线程的形式进行持久化，不影响Redis单线程的读写操作。 通过list取最新的N条数据。 模拟类似于token这种需要设置过期时间的场景。 发布订阅消息系统。 定时器、计数器。 功能 本机内存缓存 当调用api访问数据库时，假如此过程需要2秒，如果每次请求都要访问数据库，那将对服务器造成巨大的压力，如果将此sql的查询结果存到Redis中，再次请求时，直接从Redis中取得，而不是访问数据库，效率将得到巨大的提升，Redis可以定时去更新数据（比如1分钟）。 持久化存储 哨兵和复制 Sentinel可以管理多个Redis服务器，它提供了监控、提醒以及自动的故障转移功能； 复制则是让Redis服务器可以配备备份的服务器；Redis也是通过这两个功能保证Redis的高可用； 集群 支持的数据类型 字符串 hash list set zset （有序set） 8.2 Redis IO多路复用 8.2.1 概念 在Redis中，IO多路复用是一种技术，允许单个线程处理多个网络连接。它利用了select、poll、epoll等机制，能够同时监视多个描述符（fd），一旦某个描述符就绪（读/写/异常），就能通知程序进行相应的读写操作。 这种技术可以避免大量的无用操作，因为在空闲的时候，会将当前线程阻塞掉。当有一个或多个流有I/O事件时，就从阻塞态中唤醒，程序会轮询一遍所有的流（epoll是只轮询那些真正发出了事件的流），依次顺序的处理就绪的流。 IO多路复用可以高效的处理多个连接请求（尽量减少网络IO的时间消耗），让单个线程能同时处理多个客户端的连接。在Redis中，由于内存内的操作不会成为性能瓶颈，所以IO多路复用可以让Redis具有很高的吞吐量。 8.2.2 原理 IO多路复用（IO Multiplexing）的工作原理是利用一种机制同时监视多个文件描述符，以查看它们是否就绪，然后进行读写操作。这种技术允许多个连接同时被处理，而不需要为每个连接创建一个新的线程或进程。它是一种非阻塞的IO模型，通过在单个线程中处理多个连接来提高效率和减少资源消耗。 注册：将要监视的文件描述符（sockets）注册到IO多路复用函数中（例如，select、poll或epoll）。 监视：IO多路复用函数开始监视所有注册的文件描述符。 检查：IO多路复用函数定期检查每个文件描述符的状态，查看它们是否准备好进行读或写操作。 处理：当某个文件描述符就绪时，IO多路复用函数会通知应用程序，应用程序可以执行相应的读或写操作。 轮询：应用程序可以在一个循环中轮询所有文件描述符，检查它们的状态并执行相应的操作。 8.3 Redis vs Memcached Memcached是高性能的分布式内存缓存服务器。使用目的一般是从缓存中读取数据，减少数据库访问次数，提高动态web应用速度。 Redis相比memecache，拥有更多的数据结构和支持更丰富的数据操作。 内存使用率对比，Redis采用hash结构来做key-value存储，由于其组合式的压缩，其内存利用率会高于memecache。 性能对比：Redis只使用单核，memecache使用多核。 Redis支持磁盘持久化，memecache不支持。 Redis支持分布式集群，memecache不支持。 8.4 消息队列 8.4.1 概念 消息队列（Message Queue）的主要能力应该是解耦和削峰。 在有了 mq 后，producer 不需要过分关心 consumer 的身份信息，只需要把消息按照指定的协议投递到对应的 topic 即可。 producer 在处理请求时，只需要把消息投递到 mq 即可认为流程处理结束，相比于同步请求下游，整个流程会更加轻便灵活，拥有更高的吞吐量。 因为有 mq 作为缓冲层. 下游 consumer 可以设定好合适的消费限流参数，按照指定的速率进行消费，能够在很大程度上对 consumer 起到保护作用。 流程类型 push型：mq主动将消息推送到consumer。 优：实时性强，契合发布/订阅模型 缺：对下游consumer保护力度不够。（削峰不太好） pull型：consumer主动从mq拉取消息 优：consumer有主动权，选择在合适时机消费。 缺：实时性弱。 8.4.2 Redis Channel Redis Channel 是一种消息传递机制，允许发布者向特定频道发布消息，而订阅者则通过订阅频道实时接收消息。 Redis Channel 的消息传输是通过 Redis PUB/SUB 模型实现的。发布者使用 PUBLISH 命令将消息发送到指定的频道，订阅者使用 SUBSCRIBE 命令订阅指定频道。值得注意的是，频道的主要作用是实现实时消息传递，频道信息并不存储在数据库中，而是在内存中动态生成，所以在 Redis 重启后信息将消失，如果要存储频道信息，需要引入另外的方案。 8.4.3 Redis Stream Redis Stream 是 Redis 5.0 版本新增加的数据结构。 Redis Stream 主要用于消息队列（MQ，Message Queue），Redis 本身是有一个 Redis 发布订阅 (pub/sub) 来实现消息队列的功能，但它有个缺点就是消息无法持久化，如果出现网络断开、Redis 宕机等，消息就会被丢弃。简单来说发布订阅 (pub/sub) 可以分发消息，但无法记录历史消息。 而 Redis Stream 提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。 Redis Channel vs Redis Stream 两者均可以完成消息队列的实现，而Redis Stream相比Channel，可以进行消息的持久化存储，提供主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。 8.5 Redis机制 8.5.1 Redis过期删除策略 Redis所有的数据结构都可以设置过期时间，时间一到，这些数据就会变成过期数据，这个时候就需要进行删除。在redis中有3种过期数据删除策略：惰性删除和定期删除及定时删除 定时删除 定时删除对每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即对key进行清除。 优点：立即删除能保证内存中数据的最大新鲜度，因为它保证过期键值会在过期后马上被删除，其所占用的内存也会随之释放。对内存来说是非常友好的。 缺点： 立即删除对cpu是最不友好的。因为删除操作会占用cpu的时间，如果刚好碰上了cpu很忙的时候，比如正在做交集或排序等计算的时候，就会给cpu造成额外的压力。 定期删除 定期删除策略每隔一段时间执行一次删除过期键操作并通过限制删除操作执行时长和频率来减少删除操作对CPU时间的影响。定时任务的发起的频率由redis.conf配置文件中的hz来进行配置，Redis 默认每 1 秒运行 10 次，也就是每 100 ms 执行一次，每次随机抽取一些设置了过期时间的 key（这边注意不是检查所有设置过期时间的key，而是随机抽取部分），检查是否过期，如果发现过期了就直接删除。建议不要将这个值（hz）设置超过 100，否则会对CPU造成比较大的压力。 定期清理的两种模式： SLOW模式是定时任务，执行频率默认为10hz，每次不超过25ms，以通过修改配置文件redis.conf 的 hz 选项来调整这个次数 FAST模式执行频率不固定，每次事件循环会尝试执行，但两次间隔不低于2ms，每次耗时不超过1ms 定期删除注意事项： 如果删除操作执行次数过多、执行时间太长，就会导致占用大量cpu资源去进行删除操作。 如果删除操作次数太少、执行时间短，就会导致内存资源被持续占用，得不到释放。 优点：可以通过限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响。另外定期删除，也能有效释放过期键占用的内存。 缺点：难以确定删除操作执行的时长和频率。 惰性删除 惰性删除不会去主动删除数据，而是在访问数据的时候，再检查当前键值是否过期，如果过期则执行删除并返回 null 给客户端，如果没有过期则返回正常信息给客户端。 优点：对 CPU友好，我们只会在使用该键时才会进行过期检查，对于很多用不到的key不用浪费时间进行过期检查。 缺点：内存泄漏，就是一个键已经过期，如果我们一直不去访问它，然后的话让这个键仍然保留在redis中，也就是意味着这个过期键不被删除，它所占用的内存就不会释放。因此对于内存是很不友好的， 除非我们手动执行FLUSHDB（用于清空当前数据库中的所有 key）。 删除策略 特点 对CPU资源的利用 总结 定时删除 节约内存，无占用 不分时段占用CPU资源，频度高。 时间换空间 定期删除 折中，定期清理内存。 延时进行，CPU利用率高。 随机抽查，重点抽查。 惰性删除 内存占用严重 每次查询耗费CPU资源。 拿空间换时间 8.5.2 内存淘汰机制 当内存被占满（到达所配置的最大内存占用空间后），需要进行数据的淘汰。Redis提供8种内存淘汰策略。 noeviction（默认） 不删除任何数据，拒绝写入操作并返回Out of Memory错误。 alllkeys-lru 从所有key中使用LRU算法（最近最少使用） allkeys-lfu 从所有key中使用LFU算法（最不常用算法 4.0新增） volatile-lru 从设置了过期时间中key中使用LRU算法 volatile-lfu 从设置了过期时间中key中使用LFU算法 allkey-random 从所有key中随机淘汰 volatile-random 从设置了过期时间中key中随机淘汰 volatile-ttl 淘汰距离过期时间最近的 注意： 当使用 volatile-lru、volatile-lfu、volatile-random、volatile-ttl 这四种淘汰策略时，如果没有 key 可以淘汰，则和 neoviction 一样返回错误。 何时应该选择何种淘汰策略？ 根据应用程序的访问模式，选择正确的淘汰策略很重要，但是你可以在程序运行时重新配置策略，并使用 Redis 的 info 命令 输出来监控缓存未命中和命中的数量，以调整设置。 经验上来讲： 使用 allkeys-lru 策略场景： 当你期望元素的子集将比其他元素更频繁地被访问时，比如幂律分布，20%的数据占有80%的使用次数； 当你不确定使用哪种策略时。 使用 allkeys-random 策略场景： 当你有一个循环访问，其中所有 key 进行会被连续地访问； 当你希望所有 key 的分布比较均匀。 使用 volatile-ttl 策略场景： 当你大部分缓存都设有不同的 ttl 值，向 Redis 提供过期候选的提示时。 8.5.3 Redis持久化机制 Redis 的持久化指的是将内存中的数据持久化，Redis 服务器重启或宕机时能够恢复数据。Redis 支持两种持久化方式：RDB 和 AOF。 RDB持久化 RDB 持久化方式会将内存中的数据以快照的形式写入到磁盘上，保证了 Redis 服务器重启后数据不丢失。在执行 RDB 持久化时，Redis 会触发保存操作，并创建一个子进程来进行数据快照的写入操作。当快照写入完成后，Redis 会将生成 RDB 文件的时间戳、版本信息等元数据信息保存到服务器状态中，表示 RDB 持久化操作已经完成。 RDB 持久化方式分为两个部分：Snapshot 和 Save。其中 Snapshot 是指 Redis 的内存数据集，而 Save 则是将 Snapshot 持久化到硬盘上（即将内存数据快照写到 RDB 文件中）。以下是 RDB 持久化的流程： 触发保存操作； Redis 提供了多种触发保存操作的方式，如调用 SAVE 或 BGSAVE 命令、设置 SAVE 配置选项等。当触发保存操作时，Redis 会开始执行 RDB 持久化操作。 创建子进程； 由于 Redis 是单线程的，所以在执行持久化操作时需要fork一个子进程来进行操作，防止主进程被阻塞。 将数据写入临时文件 子进程会遍历整个内存数据集快照，并将快照写入到一个临时文件中，这个过程中内存数据集可以继续处理命令请求。 移动临时文件到目标文件 当子进程完成快照写入操作后，会将临时文件移动到目标文件，这个过程中 Redis 会使用原子操作来保证数据的完整性和一致性。 完成持久化操作 当目标文件生成之后，Redis 会将生成 RDB 文件的时间戳、版本信息等元数据信息保存到服务器状态中，表示 RDB 持久化操作已经完成。 SAVE &amp; BGSAVE Redis 的 SAVE 和 BGSAVE 命令都是用来进行 RDB 持久化的命令，它们的作用和用法不太一样。 1）SAVE 命令 SAVE 命令会在当前 Redis 进程执行期间阻塞所有客户端请求，直到 RDB 持久化完成为止。这个命令适合用于小规模数据集的保存操作，因为它会占用 Redis 主进程，可能会造成服务暂停的情况。 2）BGSAVE 命令 BGSAVE 命令会创建一个子进程，用于执行 RDB 持久化操作，然后主进程可以继续响应客户端请求。这个命令适合用于大规模数据集的保存操作，因为它不会阻塞 Redis 主进程，不会影响服务的正常运行。 需要注意的是，在执行 BGSAVE 命令时，由于子进程需要遍历整个内存数据集进行快照写入操作，可能会占用大量 CPU 和内存资源，导致 Redis 服务器的性能下降。因此，建议在系统空闲时执行 BGSAVE 命令，并设置适当的 RDB 文件大小和保存规则，以保证数据的安全性和服务的稳定性。 另外，如果 BGSAVE 命令执行失败（如磁盘空间不足等情况），Redis 会记录错误日志，并停止执行 RDB 持久化操作。如果需要强制执行 RDB 持久化操作，可以使用 SAVE 命令或手动删除旧的 RDB 文件来释放磁盘空间。 在这里插入图片描述 AOF持久化 快照功能并不是非常耐久（durable）： 如果 Redis 因为某些原因而造成故障停机， 那么服务器将丢失最近写入、且仍未保存到快照中的那些数据。从 1.1 版本开始， Redis 增加了一种完全耐久的持久化方式： AOF 持久化，将修改的每一条指令记录进文件appendonly.aof中(先写入os cache，每隔一段时间fsync到磁盘) AOF打开时，redis执行的每个写操作都被记录下来，并追加到AOF文件中。AOF文件是一个日志文件，包含了在服务器上执行写操作的所有指令。当redis服务器需要恢复时，它能够通过读取AOF文件来还原出命令历史，重建完整的数据状态。这种技术称为命令回放，命令回放交换和被还原在AOF文件中的操作的属于服务器的已知落后的输出。期间，服务器不再接收任何输入，而是尝试重新执行它之前已经执行过的适量输出的效果。 AOF存在三种不同的策略： always（每个命令立刻输入） 对于每个redis对服务器执行的命令都立即将其内容同步到aof文件中。这种方法能够保证非常高的数据安全性，因为aof文件总是包含最新的数据，但性能相对较低，可能会对性能造成一定的影响。 everysec（每秒钟同步一次） 这种方式每隔一秒钟将所有未同步的命令同步到磁盘上的aof文件中，这样可以减少硬盘io，提高性能和安全性的平衡。 no （让操作系统来决定何时进行同步） 当使用no方式时，redis会把aof缓冲区中的每条消息都直接交给系统内核来处理。内核再根据运行状态（包括机器负载、各进程等待时间等）来进行下一步操作。相对于其他两种，no方式在性能上有很大优势，但也存在最小程度的数据不可恢复风险。 RBD vs AOF 在这里插入图片描述 Redis 4.0 混合持久化 重启 Redis 时，我们很少使用 RDB来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 RDB来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。 Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。 AOF在重写时，不再是单纯将内存数据转换为RESP命令写入AOF文件，而是将重写这一刻之前的内存做RDB快照处理，并且将RDB快照内容和增量的AOF修改内存数据的命令存在一起，都写入新的AOF文件，新的文件一开始不叫appendonly.aof，等到重写完新的AOF文件才会进行改名，覆盖原有的AOF文件，完成新旧两个AOF文件的替换。 于是在 Redis 重启的时候，可以先加载 RDB 的内容，然后再重放增量 AOF 日志就可以完全替代之前的AOF 全量文件重放，因此重启效率大幅得到提升。 简而言之：检查点重构+日志重放。每次AOF重写时将已经写入的日志重构成RDB快照，然后续写日志。从上次重写的地方开始可以直接利用RDB快照重构，然后余下的部分利用日志回放。 8.5.4 缓存穿透 查询一个不存在的数据，因为mysql查询不到数据，所以不会直接写入缓存，就会导致每次请求都去查数据库。（恶意攻击者常用此手段DoS服务器IO资源） 解决方法-缓存空数据 查询返回的数据为空，仍把这个空结果进行缓存； 优点：实现简单。 缺点：①如果有大量查询的数据都不存在，则redis中会缓存大量空数据，这会消耗内存（这里可以给缓存添加一个TTL,减少内存消耗）；②如果原先查的数据不存在，但是后来数据库中又添加上了，可能存在数据不一致的问题。 解决方法-布隆过滤器 在这里插入图片描述 优点：内存占用较少，没有多余key。 缺点：①实现复杂；②存在误判。 布隆过滤器主要是用于检索一个元素是否在一个集合中，可以使用redisson实现布隆过滤器。 它的底层主要是先去初始化一个比较大数组，里面存放的二进制0或1。在一开始都是0，当一个key来了之后经过3次hash计算，根据计算结果找到对应数组下标，然后把数组中原来的0改为1，这样的话，三个数组的位置就能表明一个key的存在。查找的过程也是一样的。 由于hash过程没有冲突处理，所以有一定的的误判率，但是，只可能是不存在被误判为存在，而不可能是存在被误判为不存在。 原因显而易见，由hash性质决定。 8.5.5 缓存雪崩 Redis缓存雪崩是指在某个特定时间段，缓存中的大部分数据都过期失效，导致大量的请求直接访问数据库，造成数据库压力过大，甚至引起数据库崩溃的情况。 原因 缓存数据同时过期； 大量的缓存数据在同一时间段过期，例如由于误配置或由于某些缓存服务器的故障，缓存数据无法及时更新，那么当有大量请求访问这些数据时，它们将直接落到数据库上，导致数据库请求量骤增，产生压力。 缓存服务器宕机； 缓存服务器遇到故障或宕机，所有请求将无法从缓存中获取数据，强迫它们直接访问数据库。由于缓存未能发挥作用，数据库将面临大量请求，导致性能下降，并可能导致数据库崩溃。 解决方案 设置合理的缓存过期时间 缓存过期时间的设置需要根据业务需求和数据的变化频率来确定。对于不经常变化的数据，可以设置较长的过期时间，以减少对数据库的频繁访问。对于经常变化的数据，可以设置较短的过期时间，确保缓存数据的实时性。 注意的是，缓存过期时间设置过长可能导致数据的实时性降低，而设置过短可能增加缓存失效和数据库压力。因此，需要根据具体应用场景和需求来综合考虑，进行合理的设置。 使用热点数据预加载 预先将热点数据加载到缓存中，并设置较长的过期时间，可以避免在同一时间点大量请求直接访问数据库。可以根据业务需求，在系统启动或低峰期进行预热操作，将热点数据提前加载到缓存中。 热点数据预加载可以提升系统的性能和响应速度，减轻数据库的负载。要注意的是，预加载操作可能会占用系统资源，因此需要合理安排预加载执行的时间和频率，避免对系统正常业务的影响。另外，需要根据实际情况监控和调整预加载策略，以保持缓存数据的实时性和准确性。 缓存数据分布均衡 将缓存数据进行分散存储，可以使用一致性哈希算法或数据分片来将缓存数据分散存储在多个缓存服务器上，避免将所有数据集中存储在同一台缓存服务器上。这样可以提高系统的容错性，避免某个缓存服务器故障导致大量的缓存失效。通过合理的数据分布策略和动态的节点管理，可以确保缓存数据在不同节点之间均衡分布，提高系统的性能和可扩展性。 使用多级缓存架构 使用多级缓存架构可以提高系统的性能和容错性。内存缓存（如Redis）可以提供快速的数据访问能力，而分布式缓存（如Memcached）可以通过多台服务器组成集群，提高系统的可用性。可以根据数据的访问频率和重要程度，将数据存储在不同级别的缓存中。 使用多级缓存架构可以根据数据的访问频率和重要性，将数据存储在不同级别的缓存中，以提高数据访问的速度和稳定性。同时，通过合理的缓存策略和同步机制，保证多级缓存中的数据的实时性和一致性。综合考虑业务需求和技术条件，可以选择适合的多级缓存架构来提升系统的性能和用户体验。 缓存故障转移和降级策略 当缓存服务器发生故障或宕机时，需要有相应的故障转移和降级策略。可以通过监控系统来及时发现缓存故障，并进行自动切换到备份缓存服务器。同时，可以实现降级策略，当缓存失效时，系统可以直接访问数据库，保证系统的可用性。 通过缓存故障转移和降级策略，可以保证系统在缓存不可用或故障的情况下仍然可以正常运行，提高系统的稳定性和容错性。 8.5.4 缓存击穿 缓存击穿就是大量请求同时查询一个key（或一批）时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去，也就是热点key突然都失效了，MySQL承受高并发量 简单说就是：热点key突然失效，导致MySQL被暴打 解决方案 设置热点数据的永不过期策略：对于一些非常热门的数据，可以将其缓存时间设置为永不过期，这样可以避免缓存失效导致的击穿问题。但需要注意，这种方式可能会导致缓存数据不及时更新的问题。 互斥更新，采用双检加锁机制。即设置key值为独占资源，串行执行所有请求。（由于第一个请求查回key值后会缓存至Redis，此时其他请求直接缓存命中走人，无需在请求数据库。） 8.5.5 缓存预热 缓存预热是指在系统启动或者高峰期之前，提前将数据加载到缓存中，避免在用户请求的时候，先查询数据库（这样第一个查询的人就会比较慢），再把查询结果回写到redis当中去。 ps. 8.5.4缓存穿透中的布隆过滤器在此时被构建。 在这里插入图片描述 8.5.6 缓存降级 缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。降级一般是有损的操作，所以尽量减少降级对于业务的影响程度。 在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案： 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级； 警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警； 错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级； 严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。 8.6 Redis缓存和数据库的一致性 8.6.1 问题 如何保证 Redis 缓存和数据库一致性？ 到底是更新缓存还是删除缓存？ 到底选择先更新数据库，再删除缓存，还是先删除缓存，再更新数据库？ 8.6.2 缓存的引入 前期业务正处在开始阶段，流量非常小，当客户端请求过来，无论是读请求还是写请求，直接操作数据库就可以，前期架构框架如下图。 在这里插入图片描述 但是随着业务量的增长，项目请求量越来越大，这时如果每次都从数据库中读数据，就会出现大问题了。这个时候我们项目通常都会引入缓存来提高读性能，架构框架如下图。 在这里插入图片描述 这个实现方式如果有请求过来，所有读请求都可以直接从缓存中读取到数据，不需要再查数据库，性能非常高。 但是会存在以下2点问题： 不设置过期时间，不经常访问的数据还存在缓存中 因为是定时执行同步数据，会导致缓存和数据库的数据不一致的问题（看任务执行的频率） 这种方式适合数据量小，对数据一致性要求不高的业务场景。 想要缓存利用率最大化，我们很容易想到的方案是，缓存中只保留最近访问的热数据。具体要怎么做呢？如下几点： 写请求只写数据库 读请求首先读缓存，如果缓存中不存在，再从数据库中读取，并更新到缓存 写入缓存中的数据，都设置失效时间 在这里插入图片描述 8.6.3 缓存一致性问题 当数据发生更新时，我们不仅要操作数据库，还要一并操作缓存。具体操作就是，修改一条数据时，不仅要更新数据库，也要连带缓存一起更新。 如果缓存和数据库都更新的话，就会存在以下两个问题： 是先更新数据库还是后更新缓存 是先更新缓存还是后更新数据库 异常导致的一致性问题 先更新数据库，后更新缓存 首先执行数据库更新的操作并且成功了，这时再去更新缓存并且失败了，那么此时数据库中是最新的值，而缓存中还是旧的数据值。如果一个读请求过来，首先读取缓存中的数据，这时都是旧值，只有当缓存过期失效后，才能重新在数据库中得到新的值。 先更新缓存，后更新数据库 首先执行缓存更新的操作并且成功了，这时再去更新数据库并且失败了，那么此时缓存中是最新的值，而数据库中还是旧的数据值。虽然此时读请求可以命中缓存，拿到正确的值，但是缓存过期失效以后就会从数据库中读取到旧值，重新同步缓存也是这个旧值。 并发导致的一致性问题 线程 A 更新数据库（X = 1） 线程 B 更新数据库（X = 2） 线程 B 更新缓存（X = 2） 线程 A 更新缓存（X = 1） 8.6.4 解决方案 缓存单删 即业界俗称的缓存删除模式。在更新数据前先删除缓存；然后再更新库，每次查询的时候发现缓存无数据，再从库里加载数据放入缓存。 优点 此种实现方案简单 无需依赖三方中间件 缓存中的数据基本能和库里的数据保持一致 缺点 缓存逻辑和正常业务逻辑耦合在一起 在高并发的读流量下，还是会存在缓存和库里的数据不一致。见下图 在这里插入图片描述 延时双删 延迟双删其实是为了解决缓存单删，在高并发读情况下，数据不一致的问题。具体过程为： 操作数据前，先删除缓存；接着更新DB；然后延迟一段时间，再删除缓存。 优点 1、技术架构上简单 2、不依赖三方中间件 3、操作速度上挺快的，直接操作DB和缓存 缺点 1、落地难度有点大，主要是延迟时间太不好确认了 2、缓存操作逻辑和业务逻辑进行了耦合 极端情况仍有问题： 在这里插入图片描述 定时+增量更新 定时更新+增量查询：主要是利用库里行数据的更新时间字段+定时增量查询。 具体为：每次更新库里的行数据，记录当前行的更新时间；然后把更新时间做为一个索引字段。定时任务：会每隔5秒钟（间隔时间可自定义）；把库里最近更新5秒钟的数据查询出来；然后放入缓存，并记录本次查询结束时间。 优点 1、实现方案，和架构很简单 2、也能把缓存逻辑和业务逻辑进行解耦 缺点 1、数据库里的数据和缓存中数据，会在极短时间内，存在不一致，但最终会是一致的。这个极短的时间，取决于定时调度间隔时间，一般在秒级。 2、如果是分库分表的业务，编写这个查询逻辑，估计会稍显复杂。 监听binlog+MQ 通过监听数据库(比如mysql binlog)；通过binlog把数据库数据的更新操作日志（比如insert,update,delete），采集到后，通过MQ的方式，把数据同步给下游对应的消费者；下游消费者拿到数据的操作日志并拿到对应的业务数据后，再放入缓存。 优点 1、把操作缓存的代码逻辑，从正常的业务逻辑里解耦出来；业务代码更加清爽和简洁，两者互不干扰和影响，独立发展。用非人类的话说，减少对业务代码的侵入性。 2、曾经有幸在大厂里实践过此种方案，速度还贼快，虽然从库到缓存经过了类canal和mq中间件，但基本上耗时都是在毫秒级，99.9%都是10毫秒内能完成库里的数据和缓存数据同步（大厂的优势出来了） 缺点 1、技术方案和架构，非常复杂 2、中间件的运维和维护，是个不小的工作量 3、由于引入了MQ需要解决引入MQ后带来的问题。比如数据乱序问题：同一条数据先发后至，后发先至的到达消费者后，从而引起的MQ乱序消费问题，但一般都能解决。 总结 在这里插入图片描述 8.7 主从复制 8.7.1 概念 Redis 的主从复制是指将一个 Redis 实例（称为主节点）的数据复制到其他 Redis 实例（称为从节点）的过程。主从复制可以实现数据备份、读写分离、负载均衡等功能。 主机数据更新后根据配置和策略，自动同步到从机的 master/slave 机制，Master 以写为主，Slave 以读为主。主少从多、主写从读、读写分离、主写同步复制到从。 作用（为什么要主从复制？） 1.数据的热备份 2.故障恢复：在主服务器挂掉的时候，从服务器可以顶替过来 3.负载均衡：读写分离，写数据可以主服务器来做，读操作从服务器来操作 备注：主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。 8.7.2 主从复制方式 在 Redis 主从复制中，主节点负责接收客户端的写操作，并将其同步到从节点。从节点只能接收读操作请求，不能进行写操作。主节点将数据同步到从节点的方式有两种： 全量复制 主节点将所有数据发送给从节点进行复制，适用于从节点第一次复制数据或者从节点数据丢失需要重新复制的情况。 在这里插入图片描述 全量复制是非常重型的操作的具体表现在下面几点： （1）主节点通过bgsave命令fork子进程进行RDB持久化，该过程是非常消耗CPU、内存(页表复制)、硬盘IO的 （2）主节点通过网络将RDB文件发送给从节点，对主从节点的带宽都会带来很大的消耗 （3）从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgrewriteaof，也会带来额外的消耗 ps.全量复制走的是AOF持久化流程 增量复制 主节点只发送最新的修改数据给从节点进行复制，适用于从节点已经复制过数据，只需要同步最新数据的情况。 过程如下： 首先，从节点根据当前状态，决定如何调用psync命令： 121.如果从节点之前未执行过slveof或最近执行了slaveof no one，则从节点发送命令为psync ? -1，向主节点请求全量复制；2.如果从节点之前执行了slaveof，则发送命令为psync &lt;runid&gt; &lt;offset&gt;，其中runid为上次复制的主节点的runid，offset为上次复制截止时从节点保存的复制偏移量。 复制 其次，主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制： 123456789101.如果主节点版本低于Redis2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制；2.如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可；3.如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已不在复制积压缓冲区中(在队列中被挤出了)，则回复+FULLRESYNC &lt;runid&gt; &lt;offset&gt;，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两个值，以备使用。 Redis主从复制 vs Redis集群 Redis 的主从复制和 Redis 集群都是实现高可用性的方式，但它们的实现方式和应用场景有所不同。 主从复制是将一个 Redis 实例（主节点）的数据复制到多个 Redis 实例（从节点）中，可以实现数据的备份和读写分离。主节点负责写操作，从节点负责读操作，可以提高读写性能。但是主从复制不能扩展写性能，因为所有的写操作都需要在主节点上执行。 Redis 集群是将多个 Redis 实例组成一个集群，每个实例负责部分数据，可以实现数据的分片存储和负载均衡。不同的实例负责不同的数据，可以提高写操作的性能。同时， Redis 集群还可以实现自动故障转移，当某个实例出现故障时，集群会自动将该实例的数据迁移到其他实例上，保证数据的可用性。 因此，主从复制适用于读多写少的场景，而 Redis 集群适用于读写都比较频繁的场景。如果需要提高读写性能和数据的可用性，可以采用主从复制和 Redis 集群的组合方式。 参考文献 Redis持久化机制看这一篇就够了！-CSDN博客 字节面试杂谈——MySQL、Redis_redis数据库使用的memery数据引擎嘛-CSDN博客 Redis知识详解（超详细）-CSDN博客 redis面试题总结（附答案）-CSDN博客 万字长文解析如何基于Redis实现消息队列 - 知乎 (zhihu.com) Redis Stream | 菜鸟教程 (runoob.com) 深入了解下 「Redis 发布/订阅机制」的原理与实战运用_redis订阅发布的实际应用-CSDN博客 Redis实战（5）——Redis实现消息队列_redis消息队列实现-CSDN博客 【Redis】IO多路复用机制_redis io多路复用-CSDN博客 「Clickhouse系列」分布式表&amp;本地表详解_51CTO博客_clickhouse 分布式表 ClickHouse之存储格式揭秘_哔哩哔哩_bilibili 数据库的三大设计范式和BCNF_bcnf范式-CSDN博客 BCNF 范式详解-CSDN博客 聚簇索引和非聚簇索引-CSDN博客 当前读和快照读-CSDN博客 悲观锁和乐观锁的区别_乐观锁和悲欢锁的区别-CSDN博客 CAP原则_百度百科 (baidu.com) 数据库并发控制、事物的四大特性、原子性、一致性、隔离性、持久性，简称ACID、事物的概念、数据概念（脏读，不可重复读，幻读)、封锁协议、一级封锁协议、二级封锁协议、三级封锁协议、最强封锁协议_数据库 原子性 隔离性-CSDN博客 【Redis篇】Redis缓存之缓存穿透-CSDN博客 Redis--缓存雪崩及解决方案_redis缓存雪崩-CSDN博客 Redis 之 缓存预热 &amp; 缓存雪崩 &amp; 缓存击穿 &amp; 缓存穿透-CSDN博客 面试必问：缓存预热、降级？-腾讯云开发者社区-腾讯云 (tencent.com) RAID0、RAID1、RAID5、RAID6、RAID10、RAID50的异同与应用-腾讯云开发者社区-腾讯云 (tencent.com) 如何保证 Redis 缓存与数据库双写一致性？看这篇就够了_redis如何保证缓存和数据库一致性-CSDN博客 redis 如何保证缓存和数据库一致性_reidis如何保证数据和缓存一致性-CSDN博客","categories":[{"name":"八股","slug":"八股","permalink":"http://kalzncc.github.io/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"八股","slug":"八股","permalink":"http://kalzncc.github.io/tags/%E5%85%AB%E8%82%A1/"}]},{"title":"2022最终回！","slug":"2022-final-blog","date":"2023-01-02T15:44:28.000Z","updated":"2023-01-02T16:02:21.924Z","comments":true,"path":"2023/01/02/2022-final-blog/","link":"","permalink":"http://kalzncc.github.io/2023/01/02/2022-final-blog/","excerpt":"","text":"2022最终回 0 引言 2022是特殊的一年，至少从2018年算起是这样的。应该是因为毕业的缘故吧，而且不同于四年前的那次，这次毕业后也算是半只脚踏入社会了。虽然是读研了，但是在中科院体系里面，算是所里的半个职工了，打螺丝改bug一样少不了。 1 青岛和毕业 疫情还是生活中的主旋律。怎么说呢，我是放开派，主要是这疫情真的实实在在的严重影响到了我的生活。也感觉放开是必然，没办法（扯远了）。我刚刚复盘了一下今年的行程，拖着疫情和学校、研究所的各种封闭政策，我一共在家、青岛、北京三地之间辗转了8次。想想也挺扯的，我为了回学校毕业，看看同学，走完大学的最后时光，揣着带着星的行程码冒死回到了青岛，然后因为没法入校，就在学校周边的一个阴暗的破宾馆住下了。甚至我的毕业答辩都是在那间阴暗的小屋里面完成的。不过因为这带星的行程码，我终还是没能入校，终还是没有拍上毕业照。（甚至最后班长忘记统计没来的同学，我都没有被p进去。笑死）不过我回青岛的目的主要还是见见同学，这个目的已经达成了。 青岛滨海大道 我的宿舍 答辩后，我们和之前的朋友一起烧个烤、吃个饭、去崂山租了个民宿看日出，和老师见个面，道个别。然后和室友一起去崂山景区转了转。大学的最后这几天的时间还是过的不错的。 崂山的日出是真的好看！我们跟老师吃了道别饭后，就打车上山，到山上已是晚上。这民宿在一片茶园内，晚上漆黑一片看不清，我们只能打着手电慢慢往里磨。我的一位同学已经提前到这儿了，因为我们来的实在是太迟了，我的那位同学也是等得心烦气躁，这里也说声抱歉。（也许就不该跟老师吃那一次饭，笑） 首先是晚上的烧烤，随便吃吃，又半夜去海边赶海，（因为海边石摊太滑了，我没敢下去。）不过印象很深的就是看到了海边远处的一处灯塔。之前也只在电影中见过，只能说在夜里面，这灯塔照出的光穿刺海雾，还是有点震撼。 第二天就是看日出了，4点起床，天微亮，到海边上发现 云很多，也就没报什么希望能看到了。但是我们低估了阳光的穿透力啊。太阳照得云彩丁达尔现象都出来了，笑死。 从民宿回来后，我和我室友（不是一批人）去吃了一次海底捞。当时我打算吃完最后一次饭后，后天返回北京。但是心中还是有些意犹未尽，于是我决定，在我离开的最后一天，一起在和室友们去一次崂山。 好在青岛那时在疫情恢复期，崂山景区门票全免。于是上午直接打车来到了崂山，开始向山进发。 我这是第二次（刚刚民宿那次不算，那次没有到景区内部）来崂山景区了，第一次是在大一，和高中同学。崂山是真的漂亮啊，全国为数不多的，可以让你在山上看海的地方。这里推荐一波，是来青岛旅游必须去的地方。 不过这次因为我们来的时间太晚了，所以到山顶的时候，山顶那座道观的道士都已经准备下班了，不过见我们来，还是让我们进去了。这也弥补了我第一次去崂山时没有进这个道观的遗憾（只是因为没看的上风景，我不信教，笑）。只能说，这道观的视野是真的好啊，纵览全山，在没被开发成景区之前，也绝对是个与世隔绝的净地。 随后也就是下山了，在崂山下山不用按照原路返回，而是有另一条下山道路，所以风景还都是新的。只不过因为时间太晚，我们也有些匆忙，景区也没什么人了，路边的摊贩 也都打样了。最后在山脚上了景区大巴，离开了。 青岛崂山日出 青岛崂山山脚 从景区回来的那天晚上，我和室友们在烧烤摊吃饭。我本计划是明天就出发返回北京，我给我的北京导师发微信说明天就回北京。结果导师说：”你可以不用马上回来，先处理好学校的事情吧。“ 笑死，我当时喝了酒，既然你都这么说了，就算你是跟我客气客气，那我也不跟你客气了。我当即跟他说：那我就毕完业在走咯。后来就马上退了北京的车票，买了回家的车票。第二天遂坐上了回家的火车。 这两年加起来，我在家就带来不到1个半月的时间，我在家还是去看了看家人们，但在家里终究还是不太自由。在家5天后，我就又回到了青岛。此时我行程码的星号还在，于是也只能在住两天宾馆了。 当我再次回到青岛的宿舍中，也快是毕业典礼的时间了。青岛大学的毕业典礼（好像是个网红的什么云云）不过，班长的失误，我们宿舍又没弄到入场券。（对，青大的毕业典礼，毕业生参加也是需要入场券的。）于是也只能在宿舍咯。在离校的最后一夜，我们宿舍用买书的钱一起吃了顿海底捞，也算是散伙饭了。饭后回到宿舍已经12点了，然后我们又被大一的同学拉了出去，0点又出去吃了个烧烤。 总之虽然不完美，也算是给大学生活画了个句号了。然后拿着毕业证卷铺盖走人了。 室友们 青大正门 2 北京和实习 我四月就去北京实习了，其实我年初就想来北京的（导师催得紧啊），结果前脚刚买好高铁票，后脚青岛疫情了，只得退票。然后就被封在了宿舍里面，封了近3个月的时间。初到北京心里真的切切实实地体会到了北漂的心理感受——身心俱疲、居无定所（虽然马上就有了）、举目无亲（指认识的人）。先是住了一天的宾馆，然后提着被褥来到了所里安排的宿舍。 宿舍就是社会上的单身公寓，我和一位比我大一级的职工老兄住在一个房间。刚到这里心理还是有些落差的，三个人挤在一个单身公寓内，桌子只有一个，我吃饭也只能趴到窗台上吃。 忘了是怎么了，刚到这的第一周。我趴在窗台上吃饭的时候，差点哭了出来。可能是即将毕业的悲伤么，还是对前途感到迷茫。不过随着时间的推移，我也渐渐适应了这种打工人生活，好在我还算是客座学生，项目上给我的压力也不是太大，所里的老师职工和同学们也都很友善。随着和大家混熟后，心中的不安感也都消失了。在遇到什么感觉条件太差，那就一句：这都是临时的，等搬了园区，开了学，一切都会好起来的。给自己搪塞过去。 邻近回青岛毕业的时候，北京疫情突然严重，全市居家办公。因为室友职工老兄是地道北京人，所以他就回家了。我就开始独享单身公寓。本来我觉得这段时间应该会很快乐。但是事实上，比上班更可怕的是——工作时间和生活时间的混淆。我从起床到闭眼（有时加班到1点多）都是在改bug、写接口、和前端对接。不可不谓之可怕。 或许是我来的不是时候。我到这儿的时候，这个项目正在收尾和验收期，所以异常的忙。不过无论怎样，居家办公快一个月后，我绷不住了，于是联系导师，回青岛毕业去了。 北京实习宿舍 所里 回青岛毕了业后，我返回了北京，这时我也彻底安分下来了，到北京就好好搞搞研究生改搞的事情吧。此时录取通知书也下来了，心中也是有点兴奋。不过回到北京到开学这段时间里（6月到8月）也没发生什么值得铭记的事情，这里是领略到了打工人生活之枯燥。唯一值得说的还是和室友老兄一起把《独行月球》看了。 时间进入8月后，我的事情就少了很多，项目貌似已经交付了。我作为学生他们也尽量不会派活给我。这段时间也也就在搞搞一些小玩意，学学新东西啥的，好适应开学的生活。这段时间用java搞了个通用代码生成工具，但是也是个半成品，勉强能用的水平。 录取通知书 北京路边修猫一只 8月中，要开学了，这里计划和室友们吃了个饭，毕竟也是认识了几个月的，下次见面最快也等到半年后，第一学期结束了。于是和他们一起吃了个烤串。 由于我也不知道具体该称呼他们什么，他们有和我一样的客座学生，也有所里的职工。但是都是同龄人，有的还是和我一届的，这里就称呼同学啦。他们人都挺不错的，这几个月来相处的也都很融洽，熟络起来也天天在一起吹牛逼的。当然也有上司，或者年龄比较大的职工们（在所里一般称老师或者哥、姐。这里也都称老师吧~），也都很好说话，总体感觉也还不错。 我翻相册时才发现，我在北京所里客座这段时间基本没拍什么照片啊，卧槽。有点可惜了，毕竟再次回所就是新园区了。可惜了可惜了。555~ 新园区还是很好的！之前的那个旧园区让我严重怀疑中科院的经费都被用在哪里了。笑死，我们和一堆公司企业挤在一个产业园里面，每天吵吵嚷嚷的，产业园的公共食堂人也巨多。 北京烤串 所新园区 3 雁栖湖和入学 比起在所里客座，当然还是希望感觉入学了。8月中开学时，学校需要连续上报七天的体温。结果中间我有一天忘记了，遂只能延迟几天入学。不过好在最后还是顺利来到了学校（抬着被褥挤小高铁，有点难受） 初到雁栖湖的学校，怎么说呢，这地方说好听点叫科研与休养的僻静之地，说难听点就是鸟不拉屎的地方。不过现在这种入校即封校的状态，这学校在哪里也都无所谓了。 然后就是枯燥乏味的研究生校园生活。怎么说呢，感觉在上大五。笑死，因为没法回所里，在学校也只是在上课。而且由于中科院的体制是尽量在第一年修完所有学分（研二就要回所里了）所有课也贼多。因为没有工位，所以去图书馆占座也是必须的。好家伙，总体下来，感觉又上了半年本科。 国科大正门 国科大桥风景 校园生活没有什么波澜，尤其是在封校的状态。最后因为疫情的缘故，我也是早早被遣返了（确实是自愿的）不过，看着疫情形势，下学期应该是可以正常开学的，所以问题也不大了。 4 总结与将来 今年对我而已是及其特殊的一年。标志着我纯粹校园生活的结束，开始逐步向社会和工作过渡。从通常意义上来讲，今年的最后的放开，也意味着2年的疫情封控政策的结束。 今年发生了很多事，也应该是目前人生中事务最繁杂的一年。至于之后的研究生和工作，估计也应该是如同前几年的校园生活一样，应是平淡且稳定的。这也好，毕竟今年这样也真的很累。 话说在写这篇博客一开始，我是想对我4年的本科做一个总结的。但是吧，之前已经总结过一次了。那次只是对前三年的总结，正好大四的事情在这篇博客中做了补充（上学期一直在搞毕设，拿了个优秀毕业论文；下学期就是在宿舍里窝着打游戏+实习了） 至于我对未来有什么打算。我是个得过且过的人，没啥梦想，没啥愿景。我想这种东西留在面试的时候跟考官现场编吧。不过可以确定的是，我大体应该是不会太过深入的搞安全领域，好在老师给的课题本质还是数据挖掘和人工智能（披一层安全的皮嘛，懂得都懂） 本来以为我又会输出一篇负能量堆砌成的屎山，结果总体看下来，还算乐观。 先这样吧！最后祝你我未来无限光明，陌生人！","categories":[{"name":"杂文","slug":"杂文","permalink":"http://kalzncc.github.io/categories/%E6%9D%82%E6%96%87/"}],"tags":[{"name":"总结","slug":"总结","permalink":"http://kalzncc.github.io/tags/%E6%80%BB%E7%BB%93/"}]},{"title":"机器学习算法实现","slug":"ML-impl","date":"2022-12-10T09:45:10.000Z","updated":"2022-12-11T08:50:19.367Z","comments":true,"path":"2022/12/10/ML-impl/","link":"","permalink":"http://kalzncc.github.io/2022/12/10/ML-impl/","excerpt":"","text":"仓库地址 MachineLearningImpl 这里是一些经典机器学习算法的实现。实现基于C++或者python基本库（python使用numpy和pandas，不使用任何机器学习框架），初学学习之用。 当前更新： ANN 朴素bayes CART决策树 ID3决策树 随机森林 kNN Kmeans SVM ANN（基于C++） https://github.com/Kalzncc/SimpleANNModel 朴素bayes（基于C++） https://github.com/Kalzncc/SimpleBayesClassifier ID3决策树和kNN算法 https://github.com/Kalzncc/ID3AndKNNImpl CART决策树 1234567891011121314from random_forest.model.decision_tree import Decision_Treemodel = Decision_Tree(gini_threshold=0.01, rf_atr_num=-1)# gini_threshold 基尼指数阈值，小于此阈值终止划分# rf_atr_num 默认是-1，每次随机选取的属性数目，（用于随机森林）model.train(data, label, dtype)# data, label 分别是numpy数组格式的数据和对应的label，# 而dtype是一个列表，其对应了每一维属性是离散值还是连续值# 例如数据的数据为：(年龄，分数，性别)。其中年龄，分数为连续值，性别为离散值，则传入的dtype则为:[1,1,0]out_label = model.query(sample)# 输入一个样例，输出预测标签 随机森林 1234567891011121314from random_forest.model.random_forest import Random_Forestmodel = Random_Forest(tree_num=10, random_atr_num=3, batch=100, gini_threshold=0.3)# tree_num 决策树数量# random_atr_num 每次随机选取的属性个数# batch 每次训练随机选取的样例个数model.train(data=data, label=label, dtype=dtype)# data, label 分别是numpy数组格式的数据和对应的label，# 而dtype是一个列表，其对应了每一维属性是离散值还是连续值# 例如数据的数据为：(年龄，分数，性别)。其中年龄，分数为连续值，性别为离散值，则传入的dtype则为:[1,1,0]out_label = model.query(sample)# 输入一个样例，输出预测标签 Kmeans算法 1234567891011121314from model.kmeans import Kmeansfrom utils.draw import draw_scatterfrom model.kmeans import get_data_divmodel = Kmeans(k=4)# K为分簇个数bel, means = model.train(data)# bel为每个数据的所属类# means为每个簇的中心draw_scatter(get_data_div(bel, data, 4), means)#画散点图示例 这里演示聚簇示例 SVM 基于SMO算法 公式推定：https://kalzncc.github.io/2022/11/19/smo/ 这里吐槽一下，这个东西是真的难啊。一度想要放弃，不过最后还是推出来并实现出来了。 123456789101112131415161718192021from model.support_vector_machine import Support_Vector_Machinefrom utils.utils import read_dataimport model.kernel_func as kffrom utils.draw import draw_div_linesvm = Support_Vector_Machine(max_round, delta_alpha_threshold, c, kkt_tolerance, kernel_func)# max_round 最大优化轮次# delta_alpha_threshold 优化alpha时的最小变化阈值（变化小于此阈值时视为优化失败）# c 软间隔松弛参数，默认极大值# kkt_tolerance kkt条件容忍程度阈值（辨别时依据此阈值判定一变量是否满足kkt）# kernel_func 核函数， 在model.kernel_func.py中定义了一些核函数示例，可以参考。默认为线性核svm.train(data, label)# data, label 分别是numpy数组格式的数据和对应的label，应为二分类，label只有0，1两种标签out_f = svm.query(sample)# 询问样例标签，输出为一个数值，为原f函数输出，如果值小于0应划分至-1，如果值大于0应划分至1label = np.array([-1 if i == 0 else 1 for i in label])draw_div_line(data, label, min_x=-5, max_x=15, min_y=-5, max_y=15, query=svm.query, sv=svm.sv)# 画分割线图表 有关核函数，在model.kernel_func.py有示例，核函数需要定义run方法，传入两个等维度numpy向量，输出一个标量值。这里示例创建一个sigma为1.0的高斯核函数。 1234567891011# main.pyfrom svm.model.kernel_func import Gauss_Kernelsvm = Support_Vector_Machine(max_round=10, kernel_func=Gauss_Kernel(sigma=1.0))# svm.model.kernel_func.pyclass Gauss_Kernel: def __init__(self, sigma): self.sigma = sigma def run(self, x, y): return math.exp(-sum((x - y) * (x - y)) / (2 * self.sigma * self.sigma)) 下面是示例，这里带有红色x的样本是支持向量","categories":[{"name":"AI","slug":"AI","permalink":"http://kalzncc.github.io/categories/AI/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://kalzncc.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"python","slug":"python","permalink":"http://kalzncc.github.io/tags/python/"}]},{"title":"博客改造计划","slug":"blog-reform-plan","date":"2022-11-22T03:19:06.000Z","updated":"2024-11-27T14:10:15.924Z","comments":true,"path":"2022/11/22/blog-reform-plan/","link":"","permalink":"http://kalzncc.github.io/2022/11/22/blog-reform-plan/","excerpt":"","text":"现在前面 首先感谢Nexmoe主题的开发大佬们。 本篇blog主要记录了我在构建这个博客时的一些踩坑经历和一些小改造。以供他人借鉴之。 对LaTex的支持 写机器学习比较多，难免要用到LaTex，但是我从CSDN搬运过来后发现LaTex不能渲染。遂上网查询解决方案。发现时hexo预制的渲染器不支持LaTex公式。 解决方案很多，但是很多都没有效果，不清楚为什么，这里通过多次尝试，找到了一种适用于本主题的解决方案。 这里应该先卸载原本的渲染器，安装pandoc渲染器。 12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save 在主题的config.yml文件中添加配置。 1234# MathJaxmathjax: enable: true per_page: true 在hexo的_config.yml文件中添加配置。 123456789101112131415# mathjax:# tags: none # or &#x27;ams&#x27; or &#x27;all&#x27;# single_dollars: true # enable single dollar signs as in-line math delimiters# cjk_width: 0.9 # relative CJK char width# normal_width: 0.6 # relative normal (monospace) width# append_css: true # add CSS to pages rendered by MathJax# every_page: false # if true, every page will be rendered by MathJax regardless the `mathjax` setting in Front-mattermarkdown: plugins: - markdown-it-footnote - markdown-it-sup - markdown-it-sub - markdown-it-abbr - markdown-it-emoji - hexo-math 在每篇博客的头部添加mathjax标签。 1234---title: 示例mathjax: true--- 随后博客可以正常渲染LaTex公式。 代码高亮问题 发现代码的显示出现了问题，代码块的样式很正常，但是代码无法根据不同语言高亮。这个问题折腾了我很长时间，上网几经周折也没找出问题。网上给出的方案挨个尝试也没什么效果。最后通过以下手段解决了一半，代码可以高亮了，但是风格有些奇怪。 变更_config.yml文件配置。 123456789101112highlight: enable: true line_number: true auto_detect: false tab_replace: &#x27;&#x27; wrap: true hljs: trueprismjs: enable: false preprocess: true line_number: true tab_replace: &#x27;&#x27; 在网站头进入highlist.js脚本，一种具体做法是在主题的config.yml文件中更改配置, 在网页head标签中嵌入js。 1slotHead: &#x27;&lt;script src=&quot;//cdn.bootcss.com/highlight.js/9.2.0/highlight.min.js&quot;&gt;&lt;/script&gt;&#x27; 博客置顶 我想把一篇blog进行置顶操作，百度后，发现有个方法，就是在文章头部中添加top参数，top值越高，越靠前。但是尝试后发现没有效果。这里发现_config.yml文件中有下面属性： 遂尝试改成： 但是发现没有任何效果，在hexo文档中也没有找到有关这个参数的说明。这里在百度的指导下，找到hexo有关主页博客排序的源码位置node_mudules/hexo-generator-index/lib/generator.js，观察源码，但是忽然意识到自己不怎么会js。总之，既然无法理解，就改一下源码，手动进行排序吧。 其实，通过分析源码可以发现，hexo的order_by属性不能是一个数组，而只能是一个-开头的属性，以供sort进行排序，所以hexo仅支持对单一属性进行排序。这不符合我的需求（先按top排序，然后再按日期排序）。 123456789101112131415// posts.data.sort((a, b) =&gt; (b.sticky || 0) - (a.sticky || 0)); // 将源代码中的该语句注释，改成下面这样。console.warn(&quot;Kalzn:: Hexo 源码已经被修改！ hexo-generator-index/lib/generator.js 首页排序被自定义！&quot;);posts.data = posts.data.sort(function(a, b) &#123; if(a.top &amp;&amp; b.top) &#123; / if(a.top == b.top) return b.date - a.date; else return b.top - a.top; &#125; else if(a.top &amp;&amp; !b.top) &#123; return -1; &#125; else if(!a.top &amp;&amp; b.top) &#123; return 1; &#125; else return b.date - a.date;&#125;); 此时我们在将文章头部引入top属性，文章将以top排序，之后按照date排序。 12345---title: 示例top: 10date: 2022-11:14: 11:45:14--- 此时发现，想要置顶的blog已经出现在文章首页啦！但是有个问题，我得让别人直到这是个置顶blog呀。此时我想到了标签系统，如果这是我给文章打个置顶标签，就能看到了。但是，Nexmoe主题默认是无法在主页显示标签的（只会显示分类），所以这里对源码进行一些改写。 在主题的layout/_partial/_post/meta.ejs中添加tags的显示。 12345678910111213141516&lt;div class=&quot;nexmoe-rainbow&quot;&gt; &lt;a class=&quot;nexmoefont icon-calendar-fill&quot;&gt;&lt;%- date(page.date, &quot;YYYY年MM月DD日&quot;) %&gt;&lt;/a&gt; &lt;% if (page.categories &amp;&amp; page.categories.length)&#123; %&gt; &lt;%- list_categories(page.categories, &#123; show_count: false, class: &#x27;nexmoefont icon-appstore-fill &#x27;, style: &#x27;none&#x27;, separator: &#x27;&#x27; &#125;) %&gt; &lt;% &#125; %&gt; &lt;%- partial(&#x27;_partial/_post/word-count&#x27;, &#123;post: page&#125;) %&gt; &lt;!-- 添加label列举 --&gt; &lt;%- partial(&#x27;_partial/_post/tag&#x27;, &#123;post: page&#125;) %&gt;&lt;/div&gt; 此时，在引入置顶标签后，就可以看到了。 但是，此时我发现，在进入blog后，会在文章的上下显示两边标签（文章末的标签是原本自带的）。这里索性将文章末的标签注释，改在文章头显示标签。 在主题的layout/post.ejs中注释代码。 1234567891011&lt;% if (!page.reprint)&#123; %&gt; &lt;%- partial(&#x27;_partial/copyright&#x27;) %&gt;&lt;% &#125; %&gt;&lt;!-- &lt;%- partial(&#x27;_partial/_post/tag&#x27;) %&gt; --&gt;&lt;% if (page.comments)&#123; %&gt; &lt;div class=&quot;nexmoe-post-footer&quot;&gt; &lt;%- theme.slotComment %&gt; &lt;/div&gt;&lt;% &#125; %&gt; 大功告成。 文章图片随机显示 网上有随机显示的教程，但好像是指定一个随机显示图片的连接。我们需求是想从我自己选取的一组图片中随机选取一个。应该有解决方案，但是我懒得找了，自己动手吧！ 在主题的config.yml中添加自定的参数。 1234567background: # 既是博客的背景，又是文章默认头图 randomImage: true #开启随机图片 randomFolder: /static/pic/random_background/ #随机图片存放的文件夹 randomNumber: 9 # 随机图片的数量 path: /static/pic/back.jpg width: 1280 height: 726 在主题的layout/index.ejs中添加对改参数的支持，这里在目录下随机选取一个图片，随机的数值与位置题目对应，以保证每次生成时，同一篇文章始终对应一张图片（也可以完全随机，但是不想每次生成都把整个网站的样子完全改变一下。笑） 123456789101112131415161718192021222324&lt;a href=&quot;&lt;%- url_for(page.path) %&gt;&quot;&gt; &lt;% if (page.cover)&#123; %&gt; &lt;div class=&quot;nexmoe-post-cover mdui-ripple absolute&quot; style=&quot;padding-top: &lt;%- page.coverHeight/page.coverWidth*100 %&gt;%;&quot;&gt; &lt;img src=&quot;&lt;%- page.cover %&gt;&quot; alt=&quot;&lt;%= page.title %&gt;&quot; loading=&quot;lazy&quot;&gt; &lt;h1&gt;&lt;%= page.title %&gt;&lt;/h1&gt; &lt;/div&gt; &lt;% &#125; else if(theme.background.randomImage) &#123; randomNo = 0; for (var i =0; i &lt;page.title.length; i++) &#123; randomNo = (randomNo * 2053 % 1000000007 + page.title.charCodeAt(i)) % 1000000007; &#125; randomNo %= theme.background.randomNumber; randomPath = theme.background.randomFolder + randomNo + &quot;.jpg&quot;; %&gt; &lt;div class=&quot;nexmoe-post-cover absolute&quot; style=&quot;padding-top: &lt;%- page.coverHeight/page.coverWidth*100 %&gt;%;&quot;&gt; &lt;img src=&quot;&lt;%- randomPath %&gt;&quot; alt=&quot;&lt;%= page.title %&gt;&quot; loading=&quot;lazy&quot;&gt; &lt;h1&gt;&lt;%= page.title %&gt;&lt;/h1&gt; &lt;/div&gt; &lt;%&#125; else&#123; %&gt; &lt;div class=&quot;nexmoe-post-cover mdui-ripple&quot;&gt; &lt;img src=&quot;&lt;%- theme.background.path %&gt;&quot; alt=&quot;&lt;%= page.title %&gt;&quot; loading=&quot;lazy&quot;&gt; &lt;h1&gt;&lt;%= page.title %&gt;&lt;/h1&gt; &lt;/div&gt; &lt;% &#125; %&gt; 同样在layout/post.ejs进行改变。 1234567891011121314151617181920212223&lt;% if (page.cover)&#123; %&gt; &lt;div class=&quot;nexmoe-post-cover absolute&quot; style=&quot;padding-top: &lt;%- page.coverHeight/page.coverWidth*100 %&gt;%;&quot;&gt; &lt;img src=&quot;&lt;%- page.cover %&gt;&quot; alt=&quot;&lt;%= page.title %&gt;&quot; loading=&quot;lazy&quot;&gt; &lt;h1&gt;&lt;%= page.title %&gt;&lt;/h1&gt; &lt;/div&gt; &lt;% &#125; else if(theme.background.randomImage) &#123; randomNo = 0; for (var i =0; i &lt;page.title.length; i++) &#123; randomNo = (randomNo * 2053 % 1000000007 + page.title.charCodeAt(i)) % 1000000007; &#125; randomNo %= theme.background.randomNumber; randomPath = theme.background.randomFolder + randomNo + &quot;.jpg&quot;; %&gt; &lt;div class=&quot;nexmoe-post-cover absolute&quot; style=&quot;padding-top: &lt;%- page.coverHeight/page.coverWidth*100 %&gt;%;&quot;&gt; &lt;img src=&quot;&lt;%- randomPath %&gt;&quot; alt=&quot;&lt;%= page.title %&gt;&quot; loading=&quot;lazy&quot;&gt; &lt;h1&gt;&lt;%= page.title %&gt;&lt;/h1&gt; &lt;/div&gt; &lt;%&#125; else&#123; %&gt; &lt;div class=&quot;nexmoe-post-cover&quot;&gt; &lt;img src=&quot;&lt;%- theme.background.path %&gt;&quot; alt=&quot;&lt;%= page.title %&gt;&quot; loading=&quot;lazy&quot;&gt; &lt;h1&gt;&lt;%= page.title %&gt;&lt;/h1&gt; &lt;/div&gt; &lt;% &#125; %&gt; 然后创建存储随机文件的文件夹，放入对应数量的图片。图片命名从0开始，后缀是jpg。 然后开始欣赏美如画的荧妹妹吧！ 哦，看了官方的归档页面指导，也顺带把归档页面的标签也设置为随机把！在layout/archives.ejs中进行更改。 12345678910111213141516171819202122232425&lt;div class=&quot;categories nexmoe-rainbow-fill&quot;&gt; &lt;% site.categories.sort(&#x27;name&#x27;).map(function(category)&#123; %&gt; &lt;% let randomNo = 0; for (var i = 0; i &lt; category.name.length; i++) &#123; randomNo = (randomNo * 2053 % 1000000007 + category.name.charCodeAt(i)) % 1000000007; &#125; randomNo %= theme.background.randomNumber; randomPath = theme.background.randomFolder + randomNo + &quot;.jpg&quot;; let coverx = randomPath %&gt; &lt;% category.posts.sort(&#x27;-date&#x27;).map(function(post)&#123; %&gt; &lt;% if(post.cover!==undefined)&#123; %&gt; &lt;% coverx = post.cover %&gt; &lt;% &#125; %&gt; &lt;% &#125;) %&gt; &lt;a class=&quot;mdui-ripple&quot; href=&quot;&lt;%- url_for(category.path) %&gt;&quot;&gt; &lt;div class=&quot;bg&quot; style=&quot;background-image:url(&lt;%= coverx %&gt;)&quot;&gt;&lt;/div&gt; &lt;h1&gt;&lt;%= category.name %&gt;&lt;/h1&gt; &lt;/a&gt; &lt;% &#125;) %&gt;&lt;/div&gt; 归档页统计图 在归档页做两个统计图，这里使用了echarts.js绘制，具体教程官网非常详细。将代码插入到arhive页面中即可。 荧妹页 此页专门用来欣赏荧妹！","categories":[{"name":"博客改造","slug":"博客改造","permalink":"http://kalzncc.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%94%B9%E9%80%A0/"}],"tags":[{"name":"置顶","slug":"置顶","permalink":"http://kalzncc.github.io/tags/%E7%BD%AE%E9%A1%B6/"},{"name":"博客","slug":"博客","permalink":"http://kalzncc.github.io/tags/%E5%8D%9A%E5%AE%A2/"}]},{"title":"2021年-蓝桥c/c++ b组国赛回忆题解","slug":"lanqiao-2021-recall","date":"2022-11-20T07:08:10.000Z","updated":"2022-11-22T02:28:11.880Z","comments":true,"path":"2022/11/20/lanqiao-2021-recall/","link":"","permalink":"http://kalzncc.github.io/2022/11/20/lanqiao-2021-recall/","excerpt":"","text":"更新一下。成绩出来了，第18名。估计是H题没能拿全分，最后一个题又没有写出一个比较好的算法。 A 这个题有点坑人，因为他不是一个算法题，而是一个计算机知识题，不知道出题人出这个题的意图。。 刚拿到蒙了，但是回忆了一下，有次我手机限速，百度了一下1Mbps是多少。隐隐约约记得公式是1Mbps=0.125MB/s， 所以。。 B 利用素数筛打表，打到20210605，然后依次判定数字，以及每个数位是不是质数即可。注意这里不认为1是质数。 C 日期题，从2001.1.1枚举到2021.12.31，依次判断即可。 D dp可解。为有个节点的二叉数的最小权值。则： E 大小写转换不解释。 F 等差序列前缀和+二分，对于x，先二分出之前有多少轮。然后求和，然后加上最后不足的一轮的前缀和。 G 数位dp，令为考虑前i位二进制，已经包含j个1，且已经到达上限flag=1，或没有到达上限flag=0的个数。 H 有循环节，我认为一个长度位n的01串会在最多迭代n次后陷入一个长度不长于n的循环节中，但赛后与别人讨论，也有说这个串在最开始就会陷入一个循环节中。都没有证明。不过我写的常数很大。估计没法拿到全分。 I 线段树+区间合并。我们视左括号为+1，右括号为-1，线段树要维护。1、区间和。2、从区间左端点开始求和的区间前缀和最小值和最大值。当进行区间反转时，进行以下操作：1、打标记。2、区间和乘-1。3、区间前缀和最小值和最大值交换，并乘-1。当进行查询时，从L节点开始，二分一个最长的，前缀和全是正数的区间。一般情况下，这个区间的右段端即位所求，因为如果这个区间是最长的，那么这个区间右段端的下一个位置的前缀和一定为负，则到这个右端点的前缀和一定是0。但是有例外，就是这个区间到序列的结束，如果没有前缀和==0的，即位不可能，否则再寻找区间的最后一个0。可以二分寻找。由于是二分套线段树，所以复杂度是m是2e5，应该可以过吧。。 J 没时间了，因为要检查，直接上了，但是出考场一讨论，傻b了，因为所以第三个数直接可以出来的，于是少了10%的样例。。。","categories":[{"name":"算法竞赛","slug":"算法竞赛","permalink":"http://kalzncc.github.io/categories/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B/"}],"tags":[{"name":"蓝桥","slug":"蓝桥","permalink":"http://kalzncc.github.io/tags/%E8%93%9D%E6%A1%A5/"}]},{"title":"线段树合并(四道例题)","slug":"segment-tree-merge-4-example","date":"2022-11-20T06:19:11.000Z","updated":"2022-11-22T02:28:20.919Z","comments":true,"path":"2022/11/20/segment-tree-merge-4-example/","link":"","permalink":"http://kalzncc.github.io/2022/11/20/segment-tree-merge-4-example/","excerpt":"","text":"顾名思义,就是合并两个同构(就是维护的区间长度一样)线段树,其实也没啥比较nb的算法,就是一个一个节点的合并,但是如果在n个要合并的线段树里,如果一共有m个元素,则配合动态开点,复杂度会均摊成一个惊人的所以,在多次合并的均摊复杂度是非常优秀的.另外线段树合并还可以和线段树分裂一起构成维护一组线段树森林的方法 我们每次合并一个点,就是综合两个线段树表示相同区间的两个节点的信息,然后整合成一个,删去另一个,这时,我们可以有一个垃圾回收处理,如下: 123//bac数组就是垃圾桶数组,如果里面有节点,就优先取出用掉,要是没有就另起新点inline int newnod() {return (cnt?bac[cnt--]:++tot);}inline void del(int p) {bac[++cnt] = p; tr[p].l = tr[p].r = tr[p].val = 0;} 合并函数可以点点进行直接合并,如果这样不方便,也可以只针对叶子节点进行直接合并,其他节点通过pushup操作得出.(总之是两个线段树所有节点都遍历一边) 例一: P4556 Vani有约会 雨天的尾巴 线段树合并模板 如题是模板题,我们讲z种不同的物资针对每个节点维护一个权值线段树(即每个节点一个).然后按照树上差分的思想,对于路径(x,y)加上z物资一件,就让x和y的权值线段树z位置加一,,lca(x,y)和fa(lca(x,y))的权值z位置减一,最后dfs一边执行线段树合并,就行啦. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;queue&gt;#include &lt;algorithm&gt;#include &lt;cstdio&gt;#include &lt;cmath&gt;#define ll long longusing namespace std;const int N = 2e5 + 5;const int Z = 1e5 + 2;int n, m;int he[N], ver[N], ne[N], tot;int d[N];queue&lt;int&gt; q;int f[N][30];inline void add(int x, int y){ ver[++tot] = y; ne[tot] = he[x]; he[x] = tot;}void bfs(){ d[1] = 1; q.push(1); while (q.size()) { int te = q.front(); q.pop(); for (int i = he[te]; i; i = ne[i]) { int v = ver[i]; if (d[v]) continue; d[v] = d[te] + 1; f[v][0] = te; for (int j = 1; j &lt; 30; j++) f[v][j] = f[f[v][j - 1]][j - 1]; q.push(v); } }}int lca(int x, int y){ if (d[x] &gt; d[y]) swap(x, y); for (int i = 29; i &gt;= 0; i--) { if (d[f[y][i]] &lt; d[x]) continue; y = f[y][i]; } if (x == y) return x; for (int i = 29; i &gt;= 0; i--) if (f[x][i] != f[y][i]) x = f[x][i], y = f[y][i]; return f[x][0];}struct Node{ int l, r; int val; int id;}tr[N * 40];int cnt, top;int rt[N], bac[N*40], ans[N];inline int newnod() { return cnt ? bac[cnt--] : ++tot; }inline void del(int p) { bac[++cnt] = p; tr[p].l = tr[p].r = tr[p].val = 0; }inline void pushup(int p){ if (tr[tr[p].l].val &gt;= tr[tr[p].r].val) { tr[p].val = tr[tr[p].l].val; tr[p].id = tr[tr[p].l].id; } else { tr[p].val = tr[tr[p].r].val; tr[p].id = tr[tr[p].r].id; }}void insert(int &amp;p, int pos, int v, int l = 1, int r = Z){ if (!p) p = newnod(); if (l == r) { tr[p].val += v; tr[p].id = l; return; } int mid = (l + r) &gt;&gt; 1; if (pos &lt;= mid) insert(tr[p].l, pos, v, l, mid); else insert(tr[p].r, pos, v, mid + 1, r); pushup(p);}int merge(int x, int y, int l = 1, int r = Z){ if (!x || !y) return x + y; int mid = (l + r) &gt;&gt; 1; if (l == r) tr[x].val += tr[y].val, tr[x].id = l; else { tr[x].l = merge(tr[x].l, tr[y].l, l, mid); tr[x].r = merge(tr[x].r, tr[y].r, mid + 1, r); pushup(x); } del(y); return x;}void print(int p, int l = 1, int r = Z){ cout &lt;&lt; l &lt;&lt; \" \" &lt;&lt; r &lt;&lt; \" \" &lt;&lt; tr[p].val &lt;&lt; \" \" &lt;&lt; tr[p].id &lt;&lt; endl; if (l == r) return; int mid = (l + r) &gt;&gt; 1; print(tr[p].l, l, mid); print(tr[p].r, mid + 1, r);}void dfs_mg(int cur, int fa){ for (int i = he[cur]; i; i = ne[i]) { int y = ver[i]; if (y == fa) continue; dfs_mg(y, cur); rt[cur] = merge(rt[cur], rt[y]); } if (tr[rt[cur]].val) ans[cur] = tr[rt[cur]].id; return;}int main(){ cin &gt;&gt; n &gt;&gt; m; for (int i = 1; i &lt; n; i++) { int x, y; scanf(\"%d%d\", &amp;x, &amp;y); add(x, y); add(y, x); } bfs(); while (m--) { int x, y, t; scanf(\"%d%d%d\", &amp;x, &amp;y, &amp;t); insert(rt[x], t, 1); insert(rt[y], t, 1); int _lca = lca(x, y); insert(rt[_lca], t, -1); insert(rt[f[_lca][0]], t, -1); } dfs_mg(1, 0); for (int i = 1; i &lt;= n; i++) printf(\"%d\\n\", ans[i]); return 0;} 例二: P1600 天天爱跑步 这个题写了很长时间,想了半天,才从之前做的一个题里收到启发,观察这个题,如果我们对每一个点都针对n秒维护一个权值线段树,那么,针对一个路路径,线段树向父节点合并就有两种情况: &gt;1.路径是从子节点到父节点,这时,我们必须要让子节点线段树的所有元素都\"整体向前移一位\",即1秒的数量变成2秒的数量,2秒的数量变成3秒的数量....依次类推 &gt;2.路径是从父节点到子节点,这时,我们必须要让子节点线段树的所有元素都\"整体向后移一位\",即2秒的数量变成1秒的数量,3秒的数量变成2秒的数量....依次类推 但是这种操作很难在极短时间内进行,这时我们不如建立一个整体值,针对1情况,我们每上一层值都加一,我们往线段树中压入的是形式值,而实际值为+形式值,比如,在一层某个节点的值为6,这时我们在这里压入一个0秒,我们修改该点的权值线段树,但是不是让0位置+1,而是让位置加一,因为-6是这一层0的形式值.这时我们往上走两层,这时值等于8,此时我们查询2秒的个数,这时我们其实是查2秒在这一层的形式值的个数,即,这时我们在前插入的0秒,在这产生了影响,总而言之,我们在一个点插入形式值后,这个形式值,会依据整体值的不同在各层产生不同影响.然后我们必须让这课树的每一层的值统一,我们发现树的深度是一个比较好的天然值.于是乎,针对每个路径我们拆成两部分和分别依据差分思想插入树中,然后按照不同的值规则合并两边就ok啦! 123456insert(rt[x], idn(0-dep2(x)), 1);insert(rt[f[_lca][0]], idn(0-dep2(x)), -1);//第一部分tt = dep1[x] - dep1[_lca]) + (dep1[y] - dep1[_lca];//路径长度insert(rt[y], idn(tt-dep1[y]), 1);insert(rt[_lca], idn(tt-dep1[y]), -1);//第二部分 ps.这可能是迄今为止自己琢磨出的最震撼的算法了QAQ 下面是ac代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;queue&gt;#include &lt;algorithm&gt;#include &lt;cstdio&gt;#include &lt;cmath&gt;#define ll long long#define max(x, y) ((x)&gt;(y)?(x):(y))using namespace std;const int N = 6e5 + 5;const int Z = 6e5 + 5;int n, m;int he[N], ver[N], ne[N], tot;int dep1[N], deep;int d[N];int q[N], qh, ql;int f[N][30];inline void add(int x, int y){ ver[++tot] = y; ne[tot] = he[x]; he[x] = tot;}inline int idn(int n) {return n + 3e5+5;}inline int dep2(int n) {return deep - dep1[n];}void bfs(){ d[1] = 1; q[++qh] = 1; while (qh &gt; ql) { int te = q[++ql]; for (int i = he[te]; i; i = ne[i]) { int v = ver[i]; if (d[v]) continue; d[v] = d[te] + 1; f[v][0] = te; for (int j = 1; j &lt; 30; j++) f[v][j] = f[f[v][j - 1]][j - 1]; dep1[v] = dep1[te] + 1; deep = max(dep1[v], deep); q[++qh] = v; } }}int lca(int x, int y){ if (d[x] &gt; d[y]) swap(x, y); for (int i = 29; i &gt;= 0; i--) { if (d[f[y][i]] &lt; d[x]) continue; y = f[y][i]; } if (x == y) return x; for (int i = 29; i &gt;= 0; i--) if (f[x][i] != f[y][i]) x = f[x][i], y = f[y][i]; return f[x][0];}struct Node{ int l, r; int val;}tr[N * 40];int cnt, top;int rt[N], bac[N*40];inline int newnod() { return cnt ? bac[cnt--] : ++top; }inline void del(int p) { bac[++cnt] = p; tr[p].l = tr[p].r = tr[p].val = 0; }void insert(int &amp;p, int pos, int v, int l = 1, int r = Z){ if (!p) p = newnod(); tr[p].val += v; if (l == r) return; int mid = (l + r) &gt;&gt; 1; if (pos &lt;= mid) insert(tr[p].l, pos, v, l, mid); else insert(tr[p].r, pos, v, mid + 1, r);}int merge(int x, int y, int l = 1, int r = Z){ if (!x || !y) return x + y; tr[x].val += tr[y].val; int mid = (l + r) &gt;&gt; 1; tr[x].l = merge(tr[x].l, tr[y].l, l, mid); tr[x].r = merge(tr[x].r, tr[y].r, mid + 1, r); del(y); return x;}int qt[N], ans[N];bool flag = 0;int ask(int p, int k, int l = 1, int r = Z){ if (l == r) return tr[p].val; int mid = (l + r) &gt;&gt; 1; if (k &lt;= mid) return ask(tr[p].l, k, l, mid); else return ask(tr[p].r, k, mid+1, r);}void dfs_mg(int cur, int fa){ for (int i = he[cur]; i; i = ne[i]) { int y = ver[i]; if (y == fa) continue; dfs_mg(y, cur); rt[cur] = merge(rt[cur], rt[y]); } int tt = qt[cur]; ans[cur] += ask(rt[cur], idn(tt - (flag ? dep1[cur] : dep2(cur)))); return;}struct qy{ int lca, y; int lca_m, y_m;}qr[N];int main(){ cin &gt;&gt; n &gt;&gt; m; for (int i = 1; i &lt; n; i++) { int x, y; scanf(\"%d%d\", &amp;x, &amp;y); add(x, y); add(y, x); } bfs(); for (int i = 1; i &lt;= n; i++) scanf(\"%d\", &amp;qt[i]); for (int i = 1; i &lt;= m; i++) { int x, y; scanf(\"%d%d\", &amp;x, &amp;y); int _lca = lca(x, y); insert(rt[x], idn(0-dep2(x)), 1); insert(rt[f[_lca][0]], idn(0-dep2(x)), -1); qr[i].lca = _lca; qr[i].y = y; qr[i].y_m = (dep1[x] - dep1[_lca]) + (dep1[y] - dep1[_lca]); } dfs_mg(1, 0); cnt = top = 0; for (int i = 0; i &lt; N * 40; i++) tr[i].l = tr[i].r = tr[i].val = 0; memset(rt, 0, sizeof(rt)); for (int i = 1; i &lt;= m; i++) { int y = qr[i].y, _lca = qr[i].lca; int tt = qr[i].y_m; insert(rt[y], idn(tt-dep1[y]), 1); insert(rt[_lca], idn(tt-dep1[y]), -1); } flag = 1; dfs_mg(1, 0); for (int i = 1; i &lt;= n; i++) printf(\"%d \", ans[i]); puts(\"\"); return 0;} 例三:P3224 [HNOI2012]永无乡 一个模板中的模板了.结合并查集找根即可. 下面是ac代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;queue&gt;#include &lt;algorithm&gt;#include &lt;cstdio&gt;#include &lt;cmath&gt;#define ll long longusing namespace std;const int N = 2e5 + 5;int fa[N];int fi(int x){ if (x == fa[x]) return x; return fa[x] = fi(fa[x]);}struct Node{ int l, r; int val;}tr[N * 40];int cnt, top;int rt[N], bac[N*40];inline int newnod() { return cnt ? bac[cnt--] : ++top; }inline void del(int p) { bac[++cnt] = p; tr[p].l = tr[p].r = tr[p].val = 0; }int n, m;void insert(int &amp;p, int pos, int v, int l = 1, int r = n){ if (!p) p = newnod(); tr[p].val += v; if (l == r) return; int mid = (l + r) &gt;&gt; 1; if (pos &lt;= mid) insert(tr[p].l, pos, v, l, mid); else insert(tr[p].r, pos, v, mid + 1, r);}int merge(int x, int y, int l = 1, int r = n){ if (!x || !y) return x + y; int mid = (l + r) &gt;&gt; 1; tr[x].val += tr[y].val; tr[x].l = merge(tr[x].l, tr[y].l, l, mid); tr[x].r = merge(tr[x].r, tr[y].r, mid + 1, r); del(y); return x;}void mmerge(int x, int y){ fa[y] = x; rt[x] = merge(rt[x], rt[y]);}int ask(int p, int k, int l = 1, int r = n){ if (l == r) return l; int mid = (l + r) &gt;&gt; 1; if (tr[tr[p].l].val &gt;= k) return ask(tr[p].l, k, l, mid); else return ask(tr[p].r, k - tr[tr[p].l].val, mid+1, r);}void Debug_print(int p, int l = 1, int r = n){ cout &lt;&lt; l &lt;&lt; \" \" &lt;&lt; r &lt;&lt; \" \" &lt;&lt; tr[p].val &lt;&lt; endl; if (l == r) { return;} int mid = (l + r) &gt;&gt; 1; Debug_print(tr[p].l, l, mid); Debug_print(tr[p].r, mid + 1, r);}void De(){ for (int i = 1; i &lt;= n; i++) cout &lt;&lt; fa[i] &lt;&lt; \" \"; cout &lt;&lt; endl; for (int i = 1; i &lt;= n; i++) { cout &lt;&lt; \"--------------\" &lt;&lt; endl; cout &lt;&lt; i &lt;&lt; endl; for (int j = 1; j &lt;= n; j++) Debug_print(rt[i], j); cout &lt;&lt; \"\\n--------------\" &lt;&lt; endl; }}int _rank[N];int main(){ cin &gt;&gt; n &gt;&gt; m; for (int i = 1; i &lt;= n; i++) { fa[i] = i; int te; scanf(\"%d\", &amp;te); insert(rt[i], te, 1); _rank[te] = i; } while(m--) { int x, y; scanf(\"%d%d\", &amp;x, &amp;y); x = fi(x); y = fi(y); if (x != y) mmerge(x, y); } int q; cin &gt;&gt; q; while(q--) { char op[5]; int x, y; scanf(\"%s%d%d\", op, &amp;x, &amp;y); if (op[0] == 'Q') { x = fi(x); if (tr[rt[x]].val &lt; y) {puts(\"-1\"); continue;} int te = ask(rt[x], y); printf(\"%d\\n\", _rank[te]); } else { x = fi(x); y = fi(y); if (x != y) mmerge(x, y); } } return 0;} 补充一例:CF600E Lomsat gelral 这个题可以用dsu来做,但是今天发现可以用线段树合并也可以!啊啊啊,这些神奇的算法还是这么的神奇,个人觉得线段树合并比dsu还要好理解一点. 下面是ac代码: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cmath&gt;#define ll long long #define int llusing namespace std;const int N = 1e5+5;int top, cnt, tot;int bac[N*40], ver[N&lt;&lt;1], he[N], ne[N&lt;&lt;1], rt[N];int su[N];int n;struct Node{ int l, r; ll val, ans;}tr[N*40];inline int neww() { return cnt ? bac[cnt--] : ++top; }inline void del(int p) { bac[++cnt]; tr[p].l = tr[p].r = tr[p].val = 0; } void add(int x, int y){ ver[++tot] = y; ne[tot] = he[x]; he[x] = tot;}inline void pushup(int p){ if (tr[tr[p].l].val &gt; tr[tr[p].r].val) { tr[p].val = tr[tr[p].l].val; tr[p].ans = tr[tr[p].l].ans; } else if (tr[tr[p].l].val &lt; tr[tr[p].r].val) { tr[p].val = tr[tr[p].r].val; tr[p].ans = tr[tr[p].r].ans; } else { tr[p].val = tr[tr[p].l].val; tr[p].ans = tr[tr[p].l].ans + tr[tr[p].r].ans; } }void ins(int &amp;p, int k, int val, int l = 1, int r = n){ if (!p) p = neww(); if (l == r){tr[p].val += val; tr[p].ans = l; return;} int mid = (l + r) &gt;&gt; 1; if (k &lt;= mid) ins(tr[p].l, k, val, l, mid); else ins(tr[p].r, k, val, mid+1, r); pushup(p);}int merge(int x, int y, int l = 1, int r = n){ if (!x || !y) return x + y; if (l == r) {tr[x].val += tr[y].val; tr[x].ans = l;} else { int mid = (l + r) &gt;&gt; 1; tr[x].l = merge(tr[x].l, tr[y].l, l, mid); tr[x].r = merge(tr[x].r, tr[y].r, mid+1, r); pushup(x); } del(y); return x;}int ans[N];void dfs_mg(int cur, int fa){ for (int i = he[cur]; i; i = ne[i]) { int y = ver[i]; if (y == fa) continue; dfs_mg(y, cur); rt[cur] = merge(rt[cur], rt[y]); } ans[cur] = tr[rt[cur]].ans; return;}signed main(){ cin &gt;&gt; n; for (int i = 1; i &lt;= n; i++) { scanf(\"%lld\", &amp;su[i]); ins(rt[i], su[i], 1); } for (int i = 1; i &lt; n; i++) { int x, y; scanf(\"%lld%lld\", &amp;x, &amp;y); add(x, y); add(y, x); } dfs_mg(1, 0); for (int i = 1; i &lt;= n; i++) printf(\"%lld \", ans[i]); puts(\"\"); return 0;}","categories":[{"name":"算法竞赛","slug":"算法竞赛","permalink":"http://kalzncc.github.io/categories/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B/"}],"tags":[{"name":"ICPC","slug":"ICPC","permalink":"http://kalzncc.github.io/tags/ICPC/"},{"name":"数据结构","slug":"数据结构","permalink":"http://kalzncc.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"SMO算法流程","slug":"smo","date":"2022-11-19T12:42:37.000Z","updated":"2024-11-26T05:20:26.566Z","comments":true,"path":"2022/11/19/smo/","link":"","permalink":"http://kalzncc.github.io/2022/11/19/smo/","excerpt":"","text":"SMO 算法流程 python代码见github 问题简介 SMO(Sequential Minimal Optimization)用于解决支持向量机中的对偶问题的最优化求解过程，该问题为： 而此问题也满足KKT条件要求 流程 该问题是一种凸二次规划问题，但是如果当作一般情况处理，计算过于繁琐。好在我们可以利用该问题特殊情况，得以特殊处理以简化流程。 SMO算法的核心思想是利用这一条件，进行特殊处理。由于一次性确定所有的最优化取值是十分困难，所谓我们不妨每次只考虑变更两个变量，然后唯一确定剩下的变量为。这里为什么选择两个变量，每次只选择一个不应该更容易吗？这里我们要注意，我们是通过迭代的方式每次选取一组的值进行更改。鉴于条件，我们是无法对单一进行修改的，换句话说，如果我们更改了一个变量，则必须有另一个变量跟随发生改变以满足。 以下，为了表述方便，我们每次选择的变量定为，此时目标函数可以写成： 这里我们把与无关的常数项都简写为，因为这部分在接下来的求导过程中无用。 这里引入我们之前的条件,并设定 带入消去得 其中 我们需要对其最大化，这里进行求导,赋值0求极值 至此，问题似乎得以解决，我们似乎只需要通过该等式解出即可。但是，请再次注意，我们是通过迭代的方式每次选取一组进行优化的。而注意到变量，它的取值为：，其中其他的变量我们无法获悉。我们只知道在之前的迭代中确定的旧值。 所以，这里我们考虑如何调整的数值。即，如何通过旧值推定出新值。我们假定，在之前的迭代中已经确定了一个拟定分隔超平面 这里为上一次迭代中的旧的值。这里我们明确，在此轮迭代中，改变的只有，所以有 所以我们将带入 将其带入得 其中为误差函数 但此时，我们还没有考虑到条件： 由于,故，上式无非就四种情况 其中(2)(3)可以归为一种情况 其中可以归结为。 满足线性规划 在这里插入图片描述 在这种情况下，应满足 。定义 此外，(1)(4)可以归为另一种情况 在这里插入图片描述 在这种情况下，应满足。定义 所以最后更新 至此我们确定了得更新值，然后的值也随之推出。这里我们设 则有 这里我们需要明确一件事情，到目前为止，我们所作的事情就是求这个目标函数得极值，通过分析可以发现是一个二次多项式函数，而二次项的系数为。所以目前来说，上述结论仅在时成立，因为此时是个开口向下的二次函数，存在极值为最小值。这种情况实际上可以应对大部分情况。但是在一部分情况，此时函数极小值在定义域边界出现。当然，在算法的实际实现中，我们可以直接求出定义域的两端值和极值，然后取三者中的最小值即可。 接下来，我们将讨论偏置的值如何求出。根据KKT条件可得，即有 带入误差函数得 其中为旧的偏置值，将该式子代入替换上式的前两项 同理可以得出 而最终的要取两者的中间值，即 最后，我们来讨论，如何进行变量的选取。首先我们应该确定第一个变量，此时，我们变量样本集，选取第一个不满足KKT条件的样本。这里写作KKT条件为： 然后依照规则选取第二个变量，执行优化。当完成后，我们开始遍历非边界样例集（即满足的样例），同样选择第一个不满足KKT条件的变量，然后依照一定规则选择出第二个变量进行优化。完成后，我们再次选择整个样本集进行以上操作。总得来说，我们交替选择整个样本集和非边界样本集进行优化，直至整个样本集全部满足KKT条件。 关于选取第二个变量的规则，我们的原则是让尽可能大的发生变化，由于依赖所以当为正，则要尽量小，否则要尽量大。 有时按照上述的启发式选择第二个变量，不能够使得函数值有足够的下降，这时按下述步骤: &gt; 首先在非边界集上选择能够使函数值足够下降的样本作为第二个变量， 如果非边界集上没有，则在整个样本集上选择第二个变量， 如果整个样本集依然不存在，则重新选择第一个变量。 参考 1.https://blog.csdn.net/luoshixian099/article/details/51227754 2.https://www.cnblogs.com/jerrylead/archive/2011/03/18/1988419.html 3.https://www.jianshu.com/p/0c433f6f4141 4.https://zhuanlan.zhihu.com/p/257866920 5.John Platt.Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines (https://www.microsoft.com/en-us/research/publication/sequential-minimal-optimization-a-fast-algorithm-for-training-support-vector-machines/)","categories":[{"name":"AI","slug":"AI","permalink":"http://kalzncc.github.io/categories/AI/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://kalzncc.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"基于C++的朴素贝叶斯分类器","slug":"simple-bayes","date":"2022-11-19T12:41:26.000Z","updated":"2022-11-22T02:28:50.392Z","comments":true,"path":"2022/11/19/simple-bayes/","link":"","permalink":"http://kalzncc.github.io/2022/11/19/simple-bayes/","excerpt":"","text":"基于C++的朴素贝叶斯分类器 github链接 使用c++编写的朴素贝叶斯分类器，其中似然中的离散分量，以及先验概率使用拉普拉斯平滑，连续分量为正态分布。 警告，此代码仅为初学学习之用，请勿用作任何工程项目！ 一、跑起来 方式一 使用vscode+cmake插件或者Clion打开目录。然后直接编译运行。 方式二 1、确保安装cmake环境，没有请先装cmake。 2、在工程目录下键入： 1234mkdir buildcd buildcmake ..make 3、运行build目录下的程序Bayers_classifier程序 二、用起来 1、建立模型 123456789101112131415161718Simple_Bayes_Classifier::Info info;/** struct Info { int sample_num; // 样例数量 std::vector&lt;int&gt; header; // 样例格式， // 如当前分量为离散值则为样例可能取值的数量， // 如为连续值则填0， // 例如，现有样例格式为这样 : // x0 属于 {\"东\",\"南\",\"西\",\"北\"} // x1 属于 {\"左\",\"右\"} // x2 属于 {x|0&lt;x&lt;100} 为连续值 // 则 header={4, 2, 0} int class_num; // 分类数量 int sample_size; // 样例分量维度大小 } */Simple_Bayes_Classifier model(info); 2、读取文件，训练模型 1model.train(\"data/1.txt\"); // 文件格式为：每行一个样例，每个样例n个分量用空格隔开，最后为该样例所属分类 示例文件格式： 3、开始分类, 构造出一个待分类的样例，然后分类结果赋值到样例的belong_to字段 1234Sample s;s.add_parameter(x); s.add_parameter(y);model.classify(s);std::cout &lt;&lt; s.belong_to &lt;&lt; std::endl; 三、学起来 贝叶斯分类器的基石为Bayes公式： 若现在存在样例的向量为，而其所属分类为的概率为： 其中，我们把称为先验概率（prior），而则为似然（likelihood）而称为证据（evidence）。当分类器工作时，遵循，我们需要比较种分类，选择概率最大的分类。 而 所以我们可以忽略证据，针对每个待分类的样例，对每种分类计算先验概率和似然即可。 先验概率一般直接进行数量统计，即: 其中为训练集中。所属类别的样例集，而为全体训练集。 而计算较为困难的是似然，在朴素贝叶斯中，我们认为向量的所有分量的取值是独立的,此时有: 此时即可进行运算，这里如果为离散值，则可以直接进行统计： 其中是训练集中满足：所属类别为且分量为的集合。 而如果为连续值，则这里可以将其看成正态分布: 其中分别为所属类别为的训练集的分量的方差和均值。 至此我们解决了朴素贝叶斯分类器。 在有些时候，向量的分量不是独立的，一种常见的情况是所有分量满足多维正态分布。为了清晰设置 其中 这里我们将结果取对数 此时有决策函数： 为决策界，当归为类，否则归为。至此，我们讨论了贝叶斯分类器中，样例各分量满足多维正态分布的情况。","categories":[{"name":"AI","slug":"AI","permalink":"http://kalzncc.github.io/categories/AI/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://kalzncc.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"使用C++实现的简单ANN（人工神经网络）","slug":"ml-ann","date":"2022-11-19T12:01:22.000Z","updated":"2022-11-22T02:28:40.209Z","comments":true,"path":"2022/11/19/ml-ann/","link":"","permalink":"http://kalzncc.github.io/2022/11/19/ml-ann/","excerpt":"","text":"使用C++实现的简单ANN（人工神经网络） github地址 使用C++实现的最简单的人工神经网络，包含梯度下降的反向传播算法（BP）。内有部分注释，适合初学学习。至于为什么不用python？还是觉得从最底层（矩阵运算）写比较能加深印象和对算法的理解。（绝对不是因为我不会写python） 警告，此代码仅为初学学习之用，请勿用作任何工程项目！ 一、跑起来 方式一 使用vscode+cmake插件或者Clion打开目录。然后直接编译运行。 方式二 1、确保安装cmake环境，没有请先装cmake。 2、在工程目录下键入： 1234mkdir buildcd buildcmake ..make 3、运行build目录下的ANN程序 然后在data目录下生成文件output.csv,这是一个回归函数的拟合。 拟合情况如下： 二、用起来 1、使用十分简便，首先新建ANN模型，设置误差函数cost及其对于输出层每一项的偏导，这里使用默认的平方差函数 123ANNModel model;model.cost = Sqrt_Cost_Func::sqrt_cost;model.d_cost = Sqrt_Cost_Func::d_sqrt_cost; 1、设置学习率（一般0.0001~0.1） 1model.learning_rate = 0.01; 2、开始添加层级，从输入层开始，直到输出层，这里请保证输入层的神经元个数与输入向量的维度相同。并设置这些层级的激活函数和其导数。 123456789101112131415161718// 输入层 1个神经元ANNLayer layer0(1);layer0.activition = Linear_Func::linear; // 设置本层激活函数为线性函数f(x)=x // 根据ANN结构，输入层的激活函数应设置为线性layer0.d_activition = Linear_Func::linear;// 设置本层激活函数的导数model.add_layer(layer0);// 隐藏层 20个神经元ANNLayer layer1(20);layer1.activition = Signmod_Func::signmod; // 设置本层激活函数为sigmodlayer1.d_activition = Signmod_Func::d_signmod;model.add_layer(layer1);// 输出层1个神经院ANNLayer layer2(1);layer2.activition = Linear_Func::linear;layer2.d_activition = Linear_Func::d_linear;model.add_layer(layer2); 3、编译模型 1Compiled_ANNModel compiled_model = model.compile(); 4、训练模型，查看输出 12Vector data, expectation;Vector output = compiled_model.feed(data, expectation); 5、只输出，不训练 1Vector output = compiled_model.get_output(data); 三、学起来 这里给出最终公式，公式的推导请见其他教程、参考书。 1、获得神经元的激活值，这里使用表示第层的第个神经元的激活值大小 其中 其中为第层的激活函数，为从层第个神经元链接到第层第个神经元的边权（注意下标的顺序！），另外是第层第个神经元的偏置阈值。为第层的神经元个数。 2、反向传播公式（以平方差误差函数为例） 其中 最终有 最后对、进行更新如下 其中，为第层激活函数的导数。为误差函数，为预期输出向量的分量。为学习率。 具体实现的解释请，见代码注释。","categories":[{"name":"AI","slug":"AI","permalink":"http://kalzncc.github.io/categories/AI/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://kalzncc.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"博客迁移说明，我是Kalzn","slug":"hello-world","date":"2022-11-19T03:19:06.000Z","updated":"2024-11-26T06:52:29.229Z","comments":true,"path":"2022/11/19/hello-world/","link":"","permalink":"http://kalzncc.github.io/2022/11/19/hello-world/","excerpt":"","text":"我懒，所以一直不想迁移博客，所以对CSDN广告的容忍还是很高的。 但是由于最近CSDN的广告真的是让我忍无可忍（开屏一个网页的超大广告是搞什么？）所以还是花点时间迁过来吧。之后CSDN还会更新，但是说不定那天就完全转移过来了捏。之前的博客我会慢慢搬（github找了一圈，也没找见有博客搬迁的脚本，有无大佬搞一搞。） CSDN链接","categories":[],"tags":[]},{"title":"AOP（面向切面编程）的简单理解笔记","slug":"121226944","date":"2021-11-09T06:47:23.000Z","updated":"2024-11-27T03:40:27.578Z","comments":true,"path":"2021/11/09/121226944/","link":"","permalink":"http://kalzncc.github.io/2021/11/09/121226944/","excerpt":"","text":"AOP（Aspect Oriented Programming 面向切面编程）是从OOP（面向对象编程）衍生出来的，我查阅了各种书籍、网课，上面的都比较说法晦涩难懂，有甚者连基本概念都没讲就直接领着啃源码，个人太笨了，不太适应这种学习方式。还是没能正确的理解AOP的本质，最后终于在知乎的这篇提问下找到了相对简单的引例。 回忆一下，OOP的三个要素，“封装”、“继承”、“多态”。其中封装要求我们将各种方法封装到一个类里面，这样做分散了代码和功能，无疑提高了代码的可维护性和可重用性，但是也产生了一些弊端。如果有功能是公用的，那么我们必须将这个功能在所有类里面重写一遍，例如记录日志功能，我们要求在某些方法执行的时候，进行日志记录，那么按照传统OOP，我们需要在这些方法里面都加入日志记录相关的代码，大大增加了代码量，你当然也可以选择将日志记录功能封装成类，然后在这些方法执行的时候调用即可，但是这样作则无疑令这些方法所属的类与日志记录类耦合，所以诞生了AOP思想，将我们需要运行的代码（切面 Aspect）动态的插入（切入）到指定的地方。 继续刚刚的例子，我们在需要进行日志记录的类方法开始运行前建立一个插入点（切入点 Point cut），当运行到这些切入点时，我们对程序进行拦截，然后通过通知（Advice） 来执行 切面，在例子中，日志记录相关的代码就是切面，而被通知的对象（被关注的对象、被注入切面的对象）就是目标对象（Target）。最后我们还要了解切面的织入（Weaving） 方式，即何时将切面注入到相应位置：编译时期织入、类加载时期织入、执行时期织入。","categories":[{"name":"八股","slug":"八股","permalink":"http://kalzncc.github.io/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"八股","slug":"八股","permalink":"http://kalzncc.github.io/tags/%E5%85%AB%E8%82%A1/"}]},{"title":"我仍为一届平凡人(以此纪念我这差不多的本科三年、算竞生涯、失败的感情经历以及作为保研边缘人的历程）","slug":"120526796","date":"2021-09-28T06:57:57.000Z","updated":"2024-11-27T03:46:14.514Z","comments":true,"path":"2021/09/28/120526796/","link":"","permalink":"http://kalzncc.github.io/2021/09/28/120526796/","excerpt":"","text":"在这里插入图片描述 也许还是我想多了，从大学入学一开始直至被国科大录取，我还是没能跳脱出自己的小圈子，我的大学三年至此，已经告一段落了。在此我记录一下我的大学三年。 ### This is over, my university life. 记录一些重要的时间节点 时间 事件 2015年9月 进入菏泽一中开始我的高中生活 2016年4月 和她在一起了 2016年8月 高二分班，我差一点去优等班，而她去了优等班 2017年8月 高三开始，我终于被分到了优等班，但是和她不是一班 2018年6月-8月 高考，以一个不差也不好的成绩录取到青岛大学，而他去了西安某985，非常非常伤心，浑浑噩噩了一个暑假，然后溜去青岛上学了。 2018年10月 大学第一次翘课，去听了团队宣讲。决定走向算法竞赛这条不归路 2019年5月 我和她到郑州会合，但是心里有种怪怪的感觉。 2019年5月 第一次参加大型比赛——ICPC山东省省赛，和学长获得了银牌一块。特别开心。 2019年7月 决定暑假不回家了，留校参加ICPC集训。 2019年9月 通过ICPC集训队的选拨。，开始打ICPC网络赛 2019年9月-12月 和她的矛盾不断，是我的错。 2019年11月 和学长一起去ICPC银川站，参赛题验很糟糕，但是拿到了第一块ICPC牌子。 2019年12月 AC钙奶队伍正式成立！首战ICPC EC-Final，在西安拿到了一块银牌。 2019年12月 在西安比赛时候，她来找我了，一起吃饭，但是她明天有课就当晚赶回去了，睡了一夜机场。 2020年1月 去秦皇岛参加算法集训营 2020年1月 疫情开始了，幸好在此之前回到家了，没有被困到秦皇岛 2020年3月 开始了疫情在家的一学期。 2020年4月 和他分手了。2020.04-2016.04==4年 2020年7月 张老师突然私聊我，安排一些事情，可能让我的大学轨迹改写了。（得知自己可能保研） 2020年9月 返校了，开启了最忙碌的一个学期。 2020年下半年忘记了几月 蓝桥国二，当场自闭。 2020年11月 AC钙奶队伍，CCPC长春站 银奖，成为我校第一个进入CCPC总决赛的队伍 2020年12月 天梯赛个人国家一等奖，出了口恶气 2020年12月 AC钙奶，ICPC上海站银，38名差一点就金，非常遗憾 2021年3月 开学了，得知我的成绩赶到了第3名，只要六级过了就保研。开始没日没夜的卷六级。（只有最后一次机会了） 2021年4月 蓝桥省赛，c++B组山东省第一名 2021年5月 ICPC银川银，CCPC总决赛铜，ICPC省赛金 2021年6月 蓝桥国赛，第18名 2021年6月 六级炸了，准备考研了。 2021年7月 第二次留校，只不过这次是为了考研。 2021年8月 独自一个人在小麦岛，面朝着大海，查六级分数，459。当场哭了。很大声，直接社死了。 2021年9月 开始准备预推免，真的已经太晚了，没有夏令营，感觉什么都比别人慢一步。 今天（2021年9月28日） 确认被中科院信工所录取。 还是从中考讲起吧。15年，我的中考超常发挥，以690+的成绩进入了我们市仅有的一所重点高中，开始了我的高中生活。在一个小城市里的高中，并没有那么丰富多彩的高中生活，没有竞赛，没有各种活动，做题成为了我唯一的目标。直到她的出现，从我注意到他，到确认关系，似乎仅仅2星期的时间，甚至我们之前都没怎么说过话，但是，哈哈，我感觉真的不错。第一次送她回宿舍的那天，我依然记得非常清楚。路上，我紧张地一句话都说不出了，直到我回到男宿，迎接我的是男生们的起哄和嬉笑，我羞涩地笑了笑，遂第二天就确认了关系。 说实话，如果我高一的时候能够懂事点，我也不会变成现在这中模样。高一的时候，可能我初中的中二病还没有消退，我一直想引起他人的注意，于是做出了不限于在课上故意叫喊，故意在课下使用一些诸如penbeat的小伎俩博取他人的目光。乃至现在想起，我都恨不得给那时的我一巴掌。我还记得我的室友lhy，记得他在高一宿舍阳台上与我谈论未来和理想，以及当下要做的事情，我非常地感动。至今，我都把他当作我的救命恩人，因为是他把我从一条歪路上拉了回来。我开始变好，变得老实，认识到了学习的重要性，而她一直比我学习好，所以我决定努力学习，然后考入一个大学。 高一结束，高二开学。班群上突然传出消息，说高二要分班，我有些懵。因为按照我们学校的惯例，只有当高三才会重新分班。本来我觉得没什么，即使和她不在一个班里，我也离她很近。但是返校后，我才得知，她由于成绩优秀，被分到了一个优等班里，而我，被分到了普通班里，当时我整个人直接麻掉。这件事也成为了我人生的重要转折。我开始特别努力的学习，每天5点40第一个到教室，晚上10点15最后一个从教室离开。因为我知道，一切都是值得的。为了和她去同一个学校，我豁出去了。 我的努力初见成效，高二一年，每次大考我几乎都是全班第一名，wyk同学给我留下了很深的印象，我们真的是一直互相学习，互相进步。也可能是我高二的最好的朋友。高二也可能是我人生中最高光的一年，异常融洽的班级和异常nice的班主任也让我感觉非常的有归属感。现在回想起来，也是觉得特别的怀念。 高三，我终于进入了优等班，虽然没有和她在一个班里，但是起码树立了能和她考到一个大学的信心。我继续这高二的那种生活，但是很遗憾，我的成绩止步不前，慢慢地被别人超过。高三几乎是我截至目前的人生中最黑暗的一年，我学的很努力（至少我自己是这么觉得），但是依旧没有成效，当时我以我们班的第一名lgq作为榜样，但是成绩差距让我感到窒息。没办法，我慢慢的熬着，期盼着高考后的生活，希望一切都能好起来。就这样，我拖着行将崩溃的精神状态，渡过了我的高三。直到最后高考，我依旧没能赶上她，我高考592，她603，虽然差的不多，但是这点差距，让我往东去了青岛大学，而她往西去了西农。拿到高考成绩的那天，我心中最后一点妄想也破灭了，我瘫坐在椅子上，我爸爸在旁边不停的鼓励我，但是我着实没有听进去，满脑子都是我失败了，我失败了。。。。。最后还是没能到一起。 给出上面提到的一些高中同学的去向：lhy：社科院大学本科；wyk：西北大学本科；国科大硕士；lgq：复旦大学本科； 高考给我留下了很深的阴影，直至影响到了我大学的各种作为。在刚刚进入大学时，我觉得我很nb，我一定要干出一番大事业。大学新生嘛，心中刚刚燃起的烈火还是很耀眼。随后便是开学考试30+分导员的责骂和学生会复试被刷。这着实给了我很大的打击——怎么会？？这tm和我想得不一样啊。然后在一天下午，我在新生群中看到一则消息，内容是软件梦工厂创新实验室的新生宣讲。当时我在上思修课，我想既然学生会被刷，哪我一定要参加个什么东西来证明我的价值啊（笑）。在经过一系列思想斗争后，我做出了一个决定——翘掉我大学的第一节课，去听宣讲。 我写过2篇回忆录，在其中我都提到过这次宣讲，很难想象，如果我进了学生会，或者那天我决定不翘课，那么现在的我会是什么样呢？我一直都强调，希望我不会为当初翘课的这个决定而感到后悔。现在看来，那是一个正确的选择。在宣讲中，张老师让我们了解了关于竞赛的各种知识，但是我更感兴趣的是那些保研和进大厂的学长学姐，我自以为很nb，应该不比他们差，于是走向了算法竞赛的这条不归了。 不知道是不是竞赛的原因，上了大学后，我便对她越来越冷清，我确实没有办法，这是我内心的感觉，我也没法控制。在这一年间，我们之间的矛盾越积越多，并最终爆发。但是后来想想，之所以会变成现在这样，恐怕是因为，高考的打击让我心已死吧，之后无论在怎么样，一颗死掉的心，是很难复活的。 19年3月还是4月份，lz学长突然私聊我说，想不想打ICPC省赛，我那个激动的，当然想啊。lz学长说张老师已经安排我和他组队了。然后就开始了省赛被带飞的阶段。也就是在此时，我认识了我的另一个队友鑫爷——我院18级最强的男人。省赛训练在另一个校区，所以我和鑫爷每天17点坐地铁去另一个校区，然后打完训练赛，22点多，在打车回来（已经没有地铁了）。最后我们队也是成功出线，并在省赛中拿到一块银牌。 鑫爷是神仙。这是我们全院的师生共识，一个课程均分高第二名整整3分的男人，一个大一就带飞学长拿ICPC区域赛银牌的的男人，一个蓝桥国赛全国第8的男人。又是一个lgq呢，当时我想。能和他组队真是我万生有幸啊。 大一暑假要开始了，我决定还是留校参加ICPC集训了，集训期间，我真的非常希望能够在当年出线，但是我发现我的训练赛成绩一直很差，只能到第10左右，我非常的焦虑，因为按照我们学校往年的经验，能拿到ICPC区域赛银牌的人数不会超过2个队，但是，我一直非常的努力，每天除了吃饭睡觉，就是在训练，而那时鑫爷并不和我们一起训练，他已经提前进入集训队，参加HDU和牛客的组队多校了。但是吧，毕竟都选择留下了，我还是要继续了。我似乎还应该表扬一下那时的我，顶住了压力，没有出现高三那样的情况——我只尽力做到最好！事实证明我是正确的，在最后的集训队选拨中，我以第二名的成绩进入了集训队。事后我才知道——在平时训练赛的时候，有很多人作弊了。而在最后的集训队选拨中，使用的是原创题，没法作弊（那些平时在 训 练 赛 上作弊的人，，图啥啊？）。 然后我被分配到了数软院5队，正式开始了竞赛生涯，但是由于学长成功保研，临时凑出了实力强劲的数软0队，所以我被依次递补到数软4队。和两名学长：xr，qsh组队。在之后的网络赛中，我们队伍成功拿到了一个名额，选择参加了当年的银川赛站，并获铜牌一枚，这是我拿到的第一枚ICPC区域赛的铜牌，我非常地开心，因为我的努力终于有了回报。就当我准备暂时结束训练，开始复习期末时，张老师私聊我，问我愿不愿意去打EC-Final，我迟疑了一下，还是决定去。于是我便与鑫爷和yh一起组成了一支队伍。那么，至此青岛大学数软学院18级最强队伍——AC钙奶，成立！我们顺次前往了西安参加EC-Final，并获得银牌一枚，这是我们学校首次在EC-Final上拿到银牌。但是这很难说是我的功劳，鑫爷真的能把人带到起飞。于是到此时，我又迎来了我的一个低谷，没错，是低谷，因为在这个数软1队的位置，给了我很大的压力，我必须对这个位置负责。但是就这此时，我又觉得我不行了，我开始堕落，我发现我是功利的，而不是一个热诚者。直到很久我才走出这片阴霾——理由很简单：我想证明我自己，证明我留下的哪一个暑假是值得的。 然后就是疫情了，我在家中，非常自在，可是那确实我表现的最好的一个学期，分数也是有史以来最高。但是很遗憾，这场疫情摧垮了我和她最后一点留念，分手了，不过这应该对谁都好。随后我又是堕落了一一段时间，然后就开始打多校了，此时因为yh想要去就业，没有接着打竞赛，于是rsb大佬和我与鑫爷组成了新AC钙奶，开启了一段传奇历程。 在20年的6月份，张老师突然找到我说，第一：她非常期待我们队能在今年拿到青大首金，第二：她认为我可以保研。这两点都激励了我，之前我从来没想过我可以保研，因为我大一下学期的成绩非常的糟糕，可是张老师从名单上查看，我的考试课平均成绩排名是第4名（当时预计保3个）。于是我就开始了筹备弯道超车和保研。9月开学后，我迎来了我最忙的学期，但是上来一个蓝桥国二把我摔了个狗啃屎，失败原因之前的博客分析过了，我也就不在说了。我只知道，这可能是我大学最大的一个遗憾，因为ICPC都是团体赛，你如果想证明自己的实力，只能通过蓝桥，而蓝桥的失利，让我又陷入了对自己德不配位的恐惧。不过还好，在最后的天梯赛中，我拿到了全校唯一的个人国一，打了一针缓心剂，然后，AC钙奶的征途正式开始了！直到2021年6月，我们队伍依次取得了CCPC长春银、ICPC上海银、CCPC总决赛铜、ICPC银川银的成绩。其中我们队伍更是本校历史上首次进入CCPC总决赛的队伍，也是历史上首个拿到ICPC银牌的大二队伍，更是本校历史上拿到牌最多、最好的队伍。这真是我们队伍高光时刻了。然后我也弥补了蓝桥杯的遗憾，我在21年4月以山东省第一名的成绩晋级蓝桥杯b组决赛，并在最后6月的决赛中获得全国第十八名。 时间倒回到21年3月，我返校后，鑫爷给我发消息，确认了我当时的排名为第3名，经过我大二下和大三上的追赶，我的考试课平均成绩从第4追到第3，平均绩点从第7追到第3，全部课程平均分从第6追到第3。现在挡在我面前的，只有一场六级考试。。这里简单的介绍一下我们学校的保研政策——分为两种保研途径：1、普通保研，按照考试课成绩排名，需要过六级；2、特长保研，按照竞赛科研积分排名，不需要过6级。但是无奈，鑫爷的英语也不是太好，没有过六级，如果按照第二种保研方式，鑫爷的优先级高于我，但是只有一个名额。所以只有我和鑫爷至少一个人过了六级，我们才都能保研。 于是大三下学期，我发疯似的学六级，连课都不上的那种。连着比赛，最后考完六级，情况非常不好，我觉得肯定过不了。于是便收拾收拾开始准备考研了，并寄希望于鑫爷能过了六级。但是最后学院突然说要该政策，取消了特长保研，所以我们别无选择，只能过六级，我当时呵呵一笑，因为那时的我早已放弃了保研，投入到了考研的战斗中了。 21年7月，我第二次选择留校，这次是为了考研，我开始了漫无目的的复习，准备考数二+408，这期间精神状态真的不是太好，每当我想着自己熬了4个月的六级竟是这种模样，我就有点反胃。毕竟内心深处还是想保研的啊。直到8月26号出六级成绩的那天，我实在学不下去了，于是自己一个人跑到了小麦岛，面朝着大海，准备查分，10点整，我点击按钮，随着页面的跳转——459。 我哭出来了，好大声，直接社死，旁边的老大爷一直盯着我看。我真的没有想着我能过，我只是遵循着内心中人类天生的对希望的渴望。但是，它过了。顺便一提，8.26是我的生日。 随后经历了不堪回首的预推免阶段，我也是几近崩溃，因为面试大多数连初筛都过不了。不过最后还是去了国科大信工所，还行吧。 检哥说，人要摸自己的天花板，但是显然，我没有办到，我现在只是尽自己最大的努力，向前冲，希望明天会更好吧。 最后感谢一直陪伴着我的人，我的父母，我的老师（张老师-zzm、检哥-zpj、赵老师-zn），各位带过我，或者指点过我学长学姐（lz、qsh、xr、wjy、qqa、mmk、lgz、dks、dpc、jxy），感谢我的队友们（鑫爷-zx、rsb、yh），最后，感谢之前那个不肯放弃的自己。","categories":[{"name":"杂文","slug":"杂文","permalink":"http://kalzncc.github.io/categories/%E6%9D%82%E6%96%87/"}],"tags":[{"name":"总结","slug":"总结","permalink":"http://kalzncc.github.io/tags/%E6%80%BB%E7%BB%93/"}]},{"title":"KalznOJ评测机，有待完善的一个OnlineJudge评测机","slug":"118660466","date":"2021-07-11T13:41:09.000Z","updated":"2024-11-27T04:57:46.343Z","comments":true,"path":"2021/07/11/118660466/","link":"","permalink":"http://kalzncc.github.io/2021/07/11/118660466/","excerpt":"","text":"暂时搞完了，准备考研了。考完研在搞。 github项目地址 # Kalzn_Code_Judger ## 简介 这是一个使用c编写的online judge的评测机，将在完善优化后作为KalznOJ的评测沙盒。Judger每次从一个json文件中读入任务的配置信息。然后生成评测结果，在测试例中，结果将写入工作区目录下的result.txt文本文件中。在正式使用时可以将结果写入json。 ## 准备 目前Judger仅在centOS7以及ubnutu20.04中测试过，理论上适用于所有支持seccomp沙盒机制的linux版本。在进行编译前，请确保已经安装了seccomp库。 seccomp库安装方法（以ubuntu为例） 1sudo apt install libseccomp-dev libseccomp2 seccomp 编译代码 请连接seccomp库进行编译。在toolVersion目录下 1make makefile将会对代码进行编译，并将产物kalznjudger移动至/usr/bin目录下。目前版本均为测试版本，错误和调试信息将全部计入log并显示在屏幕上。 开始使用 开始使用 使用时，请输入 1sudo kalznjudger &lt;json file path&gt; [log path] 其中如果省略log path，在json解析成功之前，log目录将默认设置为Judger同目录下的log.log，当json解析成功后，log路径将采用json配置中的log。这里不建议省略log path，建议指令中log path与json中配置的log path保持一致。执行kalznjudger时，应使用root或sudo。否则judger将会报错。Judger评测完成后，会在工作区的RESULT_FILE_PATH目录下生成结果json文件。 ### 删除kalznjudger 删除/usr/bin目录中的kalznjudger即可。 1sudo rm -f /usr/bin/kalznjudger ### JSON文件 这里使用一个JSON文件作为示例，数据项的意义及注意事项见注释。由于cJSON库对long long int 型变量不支持，这里long long int型变量用字符串表示。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100{ \"Judger\": { // 评测机相关配置 \"maxCharBuffer\" : \"10000000\", //字符串最大缓存 必选项 \"maxSPJTime\" : 10000, // SPJ时限，默认为 MAX_SPJ_TIME_LIMIT \"maxSPJMemory\": \"102400000\" // SPJ内存限制 默认 MAX_SPJ_MEMORY_LIMIT }, \"Task\" : { // 任务相关配置 \"taskID\":\"100031\", // 任务ID号 必选项，务必从1开始。0视为无效ID号。 \"judgeMode\": 0, // 评测模式 默认为SINGLE_RESULT_MODE 具体见下表格 \"iOMode\": 0, // IO模式 默认为STD_IO 见下表 \"gid\" : 65534, // gid 默认为DEFAULT_UID 评测时的进程的effective gid \"uid\" : 65534,// uid 默认为DEFAULT_UID 评测时的进程的effective uid \"strictMode\" : true, // 严格模式，默认为NOT_STRICT_MODE 见下表 \"workSpacePath\":\"/home/kalzn/Desktop/testworkspace/\", // 工作区目录 必选项 评测该任务的工作区目录，以下涉及到目录的配置，均必须是相对工作区的目录，或者绝对目录。 \"logPath\":\"/home/kalzn/Desktop/testworkspace/log.log\", // log目录 必选项 \"isSPJ\": true, // 是否启用SPJ，默认为false \"spjExePath\":\"/home/kalzn/Desktop/testworkspace/spj\", // SPJ目录，当isSPJ=true时，必填项 \"spjExeName\":\"spj\", // SPJ可执行文件名字，当isSPJ=true时，必填项 \"translator\": { // 翻译选项 \"mode\": 2, // 翻译模式 必选项 见下表 \"compilerPath\": \"/usr/bin/javac\", // 编译器路径 当翻译模式==COMPILER_MODE或者COMPILER_INTERPRETER_MODE时，必选项 \"compilerOptions\":[ // 编译器选项 当翻译模式==COMPILER_MODE或者COMPILER_INTERPRETER_MODE时，必选项 \"javac\", \"Main.java\" ], \"compilerProductName\":\"Main.class\", // 编译产物名 当翻译模式!=INTERPRETER_MODE时，必选项，Judger编译后，将确认工作区目录下是否生成了名为compilerProductName的文件，以此判定编译是否正确。 \"interpreterPath\":\"/usr/bin/java\", // 解释器路径，当翻译模式==INTERPRETER_MODE,或者COMPILER_INTERPRETER_MODE时 必选项。 \"interpreterOptions\":[ // 解释器选项，当翻译模式==INTERPRETER_MODE或者或者COMPILER_INTERPRETER_MODE时 必选项。 \"java\", \"Main\" ] }, \"data\" : [ // 数据配置，这里数据的数量不超过MAX_DATA_CASE_NUMBER个 { \"inputData\":\"data/1.in\", // 输入数据 \"outputData\":\"data/output.out\", // 输出文件（一般所有数据填一个即可） \"stdAnswer\":\"data/1.out\", // 标准输出 \"maxCPUTime\": 1000, //时限 \"maxMemory\" : \"102400000000\", // 内存限制 \"maxStack\" : 1024000 //Stack数量限制。 }, { \"inputData\":\"data/2.in\", \"outputData\":\"data/output.out\", \"stdAnswer\":\"data/2.out\", \"maxCPUTime\": 1000, \"maxMemory\" : \"102400000000\", \"maxStack\" : 1024000 }, { \"inputData\":\"data/3.in\", \"outputData\":\"data/output.out\", \"stdAnswer\":\"data/3.out\", \"maxCPUTime\": 1000, \"maxMemory\" : \"102400000000\", \"maxStack\" : 1024000 }, { \"inputData\":\"data/4.in\", \"outputData\":\"data/output.out\", \"stdAnswer\":\"data/4.out\", \"maxCPUTime\": 1000, \"maxMemory\" : \"102400000000\", \"maxStack\" : 1024000 } ] }} ### 一些配置选项的说明 选项 取值 意义 Task.judgeMode SINGLE_RESULT_MODE(0) 单一结果模式，且若某样例没有AC，之后的样例直接跳过 POINTS_MODE(1) 积分模式，返回每个样例的结果，即使某样例没有AC，也会接着评测后面的样例。 ONLY_COMPILE_MODE(2) 只编译模式 （详见文档 并发评测与解释 了解详情） Task.iOMode STD_IO(0) 评测时使用标准读入输出 FILE_IO(1) 评测时使用文件读入输出，文件路径为FILEIO_INPUT_PATH以及FILEIO_OUTPUT_PATH Task.strictMode NOT_STRICT_MODE(0) 非严格模式： 1、对字符串进行变换，把答案和输出数据中的\"\"，用\"\"替代 2、如果输出或者答案最后有一个''，则删掉一个''。 3、将答案和输出的所有连续空白字符都用一个空格替代。 4、如果此时输出和答案相等，则AC。 5、否则WA。 STRICT_MODE(1) 严格评测模式： 如果为true，则启用严格评测模式，在严格模式下，按照以下顺序比对答案和输出： 1、对字符串进行变换，把答案和输出数据中的\"\"，用\"\"替代 2、如果输出或者答案最后有一个''，则删掉一个''。 3、如果输出和答案相等，则AC。 4、否则：将答案和输出的所有连续空白字符都用一个空格替代。 5、如果此时输出和答案相等，则PE。 6、否则WA。 Task.translator.mode COMPILER_MODE(0) 待测代码是工作区下Main.x, x为后缀名 1、compiler mode, 编译模式 此模式下，judger先切换到work space目录下，执行 [compilerCmd] 指令， 这里规定产生物的名字应为compilerProductName，此后judger将检测目录下是否成功生成名字为 compilerProductName的文件，以判定编译是否成功。如果失败则报告编译失败，否则执行runner开始评测。 这里runner经初始化，会直接将进程execute到编译后的产物。 INTERPRETER_MODE(1) 2、interpreter mode 解释模式 此模式下，judger先切换到work space目录下，直接开始执行runner，在runner初始化成功后，将会执行语句 [interpreterCmd] ,启用解释器运行代码，报错退出将按照runner的自行处理。 COMPILER_INTERPRETER_MODE(2) 3、compiler interpreter mode 编译解释模式 此模式下，judger先切换到work space目录下，执行 [compilerCmd] 指令 这里规定产生物的名字应为compilerProductName，此后judger将检测目录下是否成功生成名字为 compilerProductName的文件，以判定编译是否成功。如果失败则报告编译失败，否则执行runner开始评测。 在runner初始化成功后，将会执行语句 [interpreterCmd], 启用解释器运行代码，报错退出将按照runner的自行处理。 不过要明确的是，此部分的配置应该由系统的部署人员完成，此部分的配置一般不会修改 除非要改动OJ的编译指令，或者添加、删减某种语言。 DO_NOT_TANSLATE_MODE(3) 4、do not tanslate mode 不做翻译模式 直接运行compilerProductName，不做任何处理，详见文档 并发评测与解释 了解详情 编译和解释过程中产生的输出信息会分别记录到COMPILER_INFO_PATH 和 INTERPRETER_INFO_PATH下，它将和评测结果文件，一同交由高层的评测队列管理模块回收处理。 如果出现某种语言无法适配的情况，就劳烦自行编写了。这里推荐在judger.h中声明专用的编译流程函数，在box初始化后调用。目前来说，常规的语言都可以适配。 工作区 工作区是Judger在评测时的工作目录，与评测有关的数据、待测源程序等最好都在此目录下，Judger所生成的编译器和解释器信息，以及最终结果都将会存储在此。当高层管理程序回收时，应该从工作区目录回收评测结果，并做好工作区的清理。 并发评测与解释 v0.2.0版本发布的重要功能 相信大家都注意到了，在评测选项中，有几处看起来令人困惑的内容。 第一处是Task.judgeMode，评测模式中的ONLY_COMPILE_MODE。在此模式下judger仅仅对目标代码进行编译，只返回编译成功或者编译失败。不进行真正的评测。 第二处是Task.translator.mode，翻译模式的DO_NOT_TANSLATE_MODE，在此模式下，judger直接运行compilerProduct，而不进行编译或者解释工作。 这两者都是为了高层的并发评测调度准备的。首先，为了更好的对大量任务进行评测，并发评测应由高层的任务队列管理器进行调配。究其原因是，高层的任务队列管理器知晓目前待测的所有任务，相较于底层judger，它可以更好的对任务调配。 为了更好的利用处理机，judger允许高层将评测任务拆解为编译过程和执行过程。对于一个评测任务，它只要编译过一次，就可以对一组样例执行评测。 试想这么一个场景：高层队列管理模组接收到一个c++代码的评测任务，它有10组数据。此时评测机不是太繁忙。所以高层决定对其并发评测。它先向judger发送一个评测模式为ONLY_COMPILE_MODE的任务。judger完成编译后就向高层返回编译是否正确。当编译正确时，高层并发地执行10个评测任务，每个包含1组样例。而这10个任务的翻译模式均为DO_NOT_TANSLATE_MODE。然后高层接受10组样例的返回结果就OK了。 评测结果 结果名 结果代码 说明 ACCEPTED 0 该测试点通过了测试 WRONG_ANSWER 1 该测试点输出与标准答案不一致，或spj任何该待测程序答案错误 TIME_LIMIT_EXCEEDED 2 待测程序没有在时间限制内给出答案 MEMORY_LIMIT_EXCEEDED 3 待测程序没有在内存限制内给出答案 RUNTIME_ERROR 4 待测程序崩溃 PRESENTATION_ERROR 5 待测程序格式错误，此结果只在严格模式生效 OUTPUT_LIMIT_EXCEEDED 6 待测程序输出字符数大于maxCharBuffer COMPILE_ERROR 7 待测程序没有通过编译 SKIP 8 跳过，当评测模式为SINGLE_RESULT_MODE时，如果一个测试点不为AC或者PE，则后面的测试点跳过 SYSTEM_ERROR 9 系统错误，执行log 系统在得出评测结果时按照以下顺序： 首先查看box是否正常退出，检查是否系统错误。然后检查待测程序返回码和信号量，查看是否RE，然后比较其使用的CPU时间和规定限制，查看是否超时，此后比较其使用的内存和规定限制，查看是否超内存。最后调用matcher或者spj，对比输出和答案，查看是否WA，或者PE。在single result mode下，如果一个测试点为AC或者PE，才会接着评测下一个用例。否则直接退出。 报错 Judger产生的所有System Error都将会尽最大努力的存储到指定的log文件中。这里提供错误代码对照。 错误名 错误代码 说明 INVALID_JUDGE_CONFIG -100 评测配置不合法 WAIT_BOX_FAILED -101 无法收集box进程资源统计， WAIT_KILLER_FAILED -102 无法wait killer进程终止 FORK_BOX_FAILED -103 无法fork box进程 FORK_KILLER_FAILED -104 无法fork killer进程 FORK_KILLER_FOR_SPJ_FAILED -106 无法fork用于监控spj的killer进程 WAIT_SPJ_FAILED -107 无法收集spj进程资源统计 WAIT_KILLER_FOR_SPJ_FAILED -108 无法wait用于监控spj的killer进程终止 COMPILER_RUN_FAILED -109 编译器无法启动 PERMISSION_ERROR -110 judge进程不是root ACCESS_WORKSPACE_FAILED -111 无法访问工作区目录 BOX_SECURITY_CONFIG_LOAD_FAILED -200 安全配置加载失败 BOX_DATA_REDIRECT_FAILED -201 评测数据重定向失败 BOX_EXE_RUN_FAILED -202 无法启动待测程序 BOX_SET_UID_FATLED -203 无法设置用户及用户组 BOX_SET_LIMIT_FAILED -204 无法设置资源限制 KILLER_SLEEP_FAILED -300 killer无法阻塞 KILLER_KILL_FAILED -301 killer无法kill掉目标进程 MATCHER_OPEN_DATA_FAILED -400 matcher无法打开数据文件 MATCHER_STD_DATA_TOO_LARGE -401 标准答案文件字符数大于maxCharbuffer LOG_IDENTIFY_ERROR_FAILED -500 log无法识别错误 LOG_FILE_OPEN_FAILED -501 无法打开log文件 其中，-50系列报错将直接输出至stderr，其他错误将记录到log文件 安全机制 Judger采用seccomp沙盒机制，但是目前还没有配置好，所以在本文档更新之前，请不要将此项目用在公开服务器上。 SPJ说明 SPJ程序使用C++书写，这里占用SPJ程序的Exit Code作为评测的结果，SPJ的返回值为ACCEPTED，则Judger认为待测程序在此样例下通过，其他情况均为WRONG_ANSWER。SPJ程序需要引入spjlib.h文件，然后在开始调用START_JUDGE(),另外，input,output,stdoutput分别是输入数据，待测程序输出数据以及标准输出的文件指针。在得到评测结果后，应调用EXIT_JUDGE()返回结果。无需return。这里要注意的是，如果SPJ程序崩溃、超时、超出内存限制，均视为源程序WRONG_ANSWER。这里给一个SPJ程序的示例。 123456789101112131415161718#include \"spjlib.h\"int main(int argc, char * argv[]) { START_JUDGE();//------------SPJ--CODE-------------------- int a; fscanf(input, \"%d\", &amp;a); int b; fscanf(output, \"%d\", &amp;b); int c; fscanf(stdoutput, \"%d\", &amp;c); if (/*some conditions*/ ) EXIT_JUDGE(ACCEPTED); else EXIT_JUDGE(WRONG_ANSWER); //------------SPJ--CODE-------------------- EXIT_JUDGE(ACCEPTED); } 这里也明确SPJ出现的宏定义常量、函数的意义 1234#define ACCEPTED 0#define WRONG_ANSWER 1#define START_JUDGE() FILE * input = fopen(argv[1], \"r\"); FILE * stdoutput = fopen(argv[2], \"r\"); FILE * output = fopen(argv[3], \"r\");#define EXIT_JUDGE(result) fclose(input); fclose(output); fclose(stdoutput); return result; 简单演示 这里对一个java源程序进行评测，源代码如下 123456789 import java.util.*;public class Main { public static void main(String[] args) { Scanner in = new Scanner(System.in); int a = in.nextInt(), b = in.nextInt(); System.out.println(a+b); System.out.println(a-b); }} 这里将Main.java以及对其评测的数据放到同一目录下，组成工作区。 image 然后配置json文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556{ \"Judger\": { \"maxCharBuffer\" : \"10000000\" }, \"Task\" : { \"taskID\":\"100031\", \"workSpacePath\":\"/home/kalzn/Desktop/testworkspace/\", \"logPath\":\"/home/kalzn/Desktop/testworkspace/log.log\", \"translator\": { \"mode\": 2, \"compilerPath\": \"/usr/bin/javac\", \"compilerOptions\":[ \"javac\", \"Main.java\" ], \"compilerProductName\":\"Main.class\", \"interpreterPath\":\"/usr/bin/java\", \"interpreterOptions\":[ \"java\", \"Main\" ] }, \"data\" : [ { \"inputData\":\"data/1.in\", \"outputData\":\"data/output.out\", \"stdAnswer\":\"data/1.out\", \"maxCPUTime\": 1000, \"maxMemory\" : \"102400000000\", \"maxStack\" : 1024000 }, { \"inputData\":\"data/2.in\", \"outputData\":\"data/output.out\", \"stdAnswer\":\"data/2.out\", \"maxCPUTime\": 1000, \"maxMemory\" : \"102400000000\", \"maxStack\" : 1024000 }, { \"inputData\":\"data/3.in\", \"outputData\":\"data/output.out\", \"stdAnswer\":\"data/3.out\", \"maxCPUTime\": 1000, \"maxMemory\" : \"102400000000\", \"maxStack\" : 1024000 }, { \"inputData\":\"data/4.in\", \"outputData\":\"data/output.out\", \"stdAnswer\":\"data/4.out\", \"maxCPUTime\": 1000, \"maxMemory\" : \"102400000000\", \"maxStack\" : 1024000 } ] }} 评测结束后，工作区目录下生成文件 image 其中result.json 内容如下 123456789101112131415161718192021222324252627282930313233{ \"taskID\": 100031, \"time\": \"2021-07-10 03:35:56\", \"result\": [{ \"time\": 65, \"memory\": 37664, \"signal\": 0, \"code\": 0, \"result\": 0, \"detail\": \"No info\" }, { \"time\": 74, \"memory\": 37524, \"signal\": 0, \"code\": 0, \"result\": 1, \"detail\": \"No info\" }, { \"time\": 0, \"memory\": 0, \"signal\": 0, \"code\": 0, \"result\": 8, \"detail\": \"No info\" }, { \"time\": 0, \"memory\": 0, \"signal\": 0, \"code\": 0, \"result\": 8, \"detail\": \"No info\" }]}","categories":[{"name":"工程","slug":"工程","permalink":"http://kalzncc.github.io/categories/%E5%B7%A5%E7%A8%8B/"}],"tags":[{"name":"oj","slug":"oj","permalink":"http://kalzncc.github.io/tags/oj/"}]},{"title":"我的明天","slug":"112297802","date":"2021-01-06T14:00:35.000Z","updated":"2024-11-27T03:53:21.935Z","comments":true,"path":"2021/01/06/112297802/","link":"","permalink":"http://kalzncc.github.io/2021/01/06/112297802/","excerpt":"","text":"先报一下自己的成果吧，挺丢人的。 2019 ACM山东省省赛 银奖 2019 ICPC区域赛 银川 铜 2019 ICPC区域赛 EC-Final 银 2020 蓝桥杯 B组 国二（丢人） 2020 CCPC 长春 银奖 2020 天梯赛 个人国一 2020 ICPC区域赛 上海 银奖（第38名） 接触算法比赛已经两年半了（上大学两年半了），算是我这篇博客的续集了，这半年里经历了很多事情。理论上也该退役了，但是因为疫情的影响，ICPC部分场次被推到了年后。不过年后真的就有点紧张了（要考研了嘛）。我是不太想找工作，毕竟顶着一个双非本科的学历，指不定以后有什么上升渠道的闭塞。（虽然说来有点惭愧，但是自我感觉进个好点的厂子可能性还是很大的）还是要读研了。保研啥的，现在的我不敢想，因为全院只有一个竞赛推免的名额，我的四级成绩还没有达到最低要求。（不过还有一次机会）走成绩成绩推免也是不够，本人现在专业第7的样子，成绩推免只有3个。。哈哈。 每当和队友聊起这，就有点迷茫，前途考虑起来还是比这比赛残酷的多。我的队友竞赛积分都够保研，但是英语也都是没有达到最低要求。所以现在都在考虑考研的事情。还记得前几周，2021考研结束的那天，整个教学楼瞬间人去楼空。晚上我看时间差不多了，准备关灯离开实验室。发现过道走廊上一张张桌子，只剩下了一摞摞的书。脑子突然一热——昨天这里还都是背书的学长学姐们，唉，这么快，就轮到我们了。我感觉有点伤感，转眼间，我的大学生活就该告一段落了。（仿佛高考还在去年的样子。。）我回忆了我的3年大学生活，其实还是很后悔的，真的还是做的不够。检哥上课时候说：人要尝试摸自己的天花板。而现在的我，也不清楚是不是已经达到我的天花板了，自我感觉是大概率没有。我不敢说卷，一个双非本科谈什么卷，只不过是自己不努力罢了。 事到如今，我也只能在此记录一下我大学的经过。 自上次写完博客后，经历了四场大比赛，蓝桥、ICPC、CCPC、天梯赛。蓝桥，刚刚也说了，国二。得知成绩那天，我们在调试天梯赛的机器。我走出天梯赛热身的考场后，我队友在外面等着我，一会我们要去另一个教学楼监考，因为有个ICPC的校内排位赛啥的。 当时我队友看着我： “蓝桥成绩出了。。。” “哦？怎么样。”我那时以为我国一很稳。 “你，，，可以接受你不是国一的事实嘛。。” 我tmd，我看了名单后，在一堆国一的簇拥下，都不知道自己是怎么走到另一栋楼的。真的，太难受了，我之前梦见我的失利，但是现实要远比梦境刺痛的多，好家伙，当场开始网易云。后来听我队友说，他考虑了很久，该怎么把这个事情给我说。emmm，然后当晚就是直接翘了监考，和我那个队友出去吃了一顿。。。。 说一下翻车的原因： 填空，一个100！的因子个数，直接算错，好家伙，不知道怎么了，质因子分解敲错了？？？？我的天，我上去给我两个大嘴巴子。最后一填空，搜错了。第二编程线段树，好家伙直接字符串hash了比字典序，我靠，我tm，我考蓝桥那天早上是没吃早饭，但也不至于把昨天的饭都tmd反刍到脑子里了吧。然后第三贪心也不知我那种写法是不是可以得分。。。最后我是国二第3还是第4来着，我tmd后来一想，我就是第二个编程写个暴力上去也tm是国一了吧。唉~ “人事无常”，这是我大学悟出的第二个道理，第一个是“希望越大，失望就越大”。（靠，我的大学经历了什么。）蓝桥考完后，我颓废了2个星期，我敢保证，这是应该是我大学最大的遗憾之一，直到天梯赛，一切才峰回路转。拿了个个人国一，全校唯一一个个人国一。虽然不及蓝桥的含金量，但也足以给我打一针缓心药了。然后就是ICPC上海了，真的卷，我们7题38名，35个金，，好家伙直接把我们的金给硬生生卷没了。其实说起这次比赛，最遗憾的应该是我的队友，因为最后我手里的题都出了，我最后出了那个圆和十字路口的题目，而两个队友卡到了那道餐桌构造上了，最后一直都没推出了贪心。我是站在他们身后，也没啥办法。赛后才发现结论很简单的样子。我其实最后的遗憾不是太大。如果这个题出了就当场8题金，直接退役了。其实最后一看排名，金和银的分界正好差了2个小时的罚时，就算没有失误也很难是金。也只能这样了。 比赛其实收益小于付出，看我现在的样子就知道了。不过现在想起来，感觉还是不错的，虽不耀眼，但起码有些成绩。记得前两天刷知乎，看到以为老哥的提问，问怎么调和acm队友之间的关系，据他所说，自己很想打比赛，但是学校不强，没有厉害的队友，队友都不想练，最后也遗憾打铁了。现在他也只能自己孤军奋战。我当时想，好家伙，如果是我，我肯定不会打了，像我这么功利的人，这些没有利益的事情，我是绝对不去干的。但是转念一想，发现自己还是很幸运的啊，全校不强不弱，我进校前好歹稳定每年都有银。而且被nb的学长带了一路，还有个很负责的教练。这一切的大环境和那位题主比起来，真的好太多了——学校不弱，起码让我这种功利的人，有种念想，学校不强，起码让我这种废柴也能冲出学校，拿到名额。教练负责，让我这种懒惰的人被逼的每天也有训练。学长nb，我在校时，每周都会有学长给我们上课，暑假集训队也会组织集训。更重要的是，我从大一进校以来，被各路学长带着起飞。哈哈哈，每年都是，现在是17级学长带19级，明年就该我们带20级了。 人的成绩到底多大程度上取决于努力？——又回归到最老套的那个问题，天赋和努力的关系。以目前我刚刚20年出头的阅历应该的不出什么答案来。我又是那种特别懒的人，无论我现在想说些什么东西，怎么看都像是为自己的懒惰找些推脱的借口。不过，从进入大学以来，我看到了很多人，他们的能力是我难以想象的，他们能在半年的时间里撵上我两年做的功，能在一周的时间内复习考取专业第一。每当我想起：“这才是一个双非本科”。我就倍感绝望。在加上知乎上c9人上人老哥的分析得出的“上211有手就行”的结论。我也不敢把什么狗屁原因都归结为智商，或是其他的什么原因。还是自己懒呗，自己手贱呗。不过无论怎样，我现在认为“卷”这个概念不应该存在于我校。或是说，目前我们这所做的最好的学生也只是完成他应该做的任务而已。而“卷”也只是更高层的概念而已。现在提及尚且过早。也只是一种推脱的借口罢了。我亲眼看着一些人明明连最基本的任务都无法完成，却总是想着“卷”为自己做推脱，而这其中就包括我自己。 我没有权力指任责别人，我自己就是这类人。我也不指望这篇博客能把我自己骂醒，如果我能把自己骂醒，那我应该早就醒了，哈哈。我回忆了一下当时一起练习竞赛的那一批人。落差很大。最好的，拿着数块银牌和国一，拿着国家奖学金，坐拥专业第一。最坏的，一块像样的奖项都没有拿到。是什么导致现在的情况？最好的尚且不谈。我明明看着所有人，一些和我们一起努力的人，同样没有错过一丝时间的人。却被一些半路起家的吊子，甚至没有起家的吊尾超过。我也一样，我前面说过“他们能在半年的时间里撵上我两年做的功”即指此事。也许只有自己才能知道答案。对我自己而已，我恐于这是我高三的复现。我在蓝桥出成绩后，跟着我的队友出去吃饭。我琢磨着我失败的原因。忽然想到了这个问题。然后真的是脊背发凉。我至今不知道为什么我的高三会变成那样，更别提什么解决方案。我想，如果我的大三，又一次复现了高三的模样，我该怎么办。我不知道该怎么办。所以愚蠢和懒惰的我选择了理解“希望越大，失望就越大”。如果不能得到，我只能在最大限度上保证自己的心态不受影响。放弃希望还是比较绝妙的注意。至少不会再像这次蓝桥一样，像高考一样。像之前的每一次失败一样，心疼。 算了，还是。 说到这，气氛好像变了。变成一个丑角在自述他的负能量，哈哈。 nb的人太多，我争不过，那就不争了，省的争不上心里难受。就是这样。 没有什么救赎过程，算了吧。 待更了。。。。","categories":[{"name":"杂文","slug":"杂文","permalink":"http://kalzncc.github.io/categories/%E6%9D%82%E6%96%87/"}],"tags":[{"name":"总结","slug":"总结","permalink":"http://kalzncc.github.io/tags/%E6%80%BB%E7%BB%93/"}]},{"title":"支配树学习思路/模板","slug":"102986961","date":"2020-10-09T05:56:40.000Z","updated":"2024-11-27T03:53:04.153Z","comments":true,"path":"2020/10/09/102986961/","link":"","permalink":"http://kalzncc.github.io/2020/10/09/102986961/","excerpt":"","text":"首先解释什么是支配树。 首先我们先看一下DAG，我们现在有一个DAG： 如果我们从1出发，对于图中的一个点,在从1到的不同路径中，总有一些点是必经的，例如图中的8号点，我们发现在从1到8的不管是那一条路径上，5都是必须经过的。（当然1号点和8号点也可以理解为必经的）。对于每一个点，如果把该点向上最近的一个必经点和该点连有向边。我们就得到了这个图的支配树。 还是那这个DAG举例，我们按照上述的方法连边（红线）： 红边就是该DAG的支配树。对于一个点，从其到1的树链上的每一个点，都是1到的必经点。 我们仔细观察这个图，我们发现，对于一个点，他最近的必经点（支配树父亲）都是他的所有入点的“LCA”。例如，5号点的入点V= { 6,2,3 },其”LCA”为1。同理8号点，入点的“LCA”为5。那么我们怎么求这个所谓的“LCA”呢？ 我们都知道，“LCA”的概念仅存在于树上，对于DAG，对于一个点集没有所谓固定的“LCA”（因为一个点可能不止一个父亲（入点））。但是对于上图，我们可以考虑，如果一个点的所有入点向上的支配树已经建成，那么该点的最近必经点就是这些入点在当前已建支配树上的LCA 有点绕。。。我们看例子，比如现在我们要确定5号点的最近必经点。且V= { 6,2,3 }向上的支配树已经建成。那么此时图是这样的： 从图上非常明显的知道：V= { 6,2,3 }的在已建成的支配树上的LCA为1。这时我们连边&lt;1, 5&gt; 对于其他的点，同理。所有我们知道，我们在依次建立支配树的边时，必须保证该点的所有入点的支配树都已建成。所以，我们必须先处理每个点的入点，在处理该点。。这不就是 拓扑排序么？我们可以按照拓扑顺序处理完这个DAG，建成支配树。下面看一个例题。 P2597 [ZJOI2012]灾难 相信这个题，已经在各种大佬博客、题解中看了不止一遍了。我们如果用上述方法建成该食物网的支配树。那么每个点的答案，就该点的支配树子树的大小了。 我们看代码：首先建图： 1234567891011121314151617void add(int x, int y){ ver[++tot] = y; ne[tot] = he[x]; he[x] = tot; verf[tot] = x; nef[tot] = hef[y]; hef[y] = tot;}scanf(\"%d\", &amp;n);for (int i = 1; i &lt;= n; i++){ int x; while(scanf(\"%d\", &amp;x), x) {di[i]++;add(x, i);}} 可以看到，在建图的时候，我们统计入度，并同时建出反图（一会提到为什么） 然后我们拓扑排序，得到点的拓扑序： 123456789101112131415161718void topu(){ for (int i = 1; i &lt;= n; i++) if (!di[i]) q.push(i); while(q.size()) { int now = q.front(); q.pop(); topp[++cnt] = now;//记录拓扑序 for (int i = he[now]; i; i = ne[i]) { int y = ver[i]; di[y]--; if (!di[y]) q.push(y); } }} 然后我们我们按照拓扑顺序建立支配树: 1234567891011121314151617void adda(int x, int y){ vera[++tot] = y; nea[tot] = hea[x]; hea[x] = tot;}for (int i = 1; i &lt;= n; i++){ int x = verf[hef[topp[i]]];//利用反图，找到topp[i]点的入点 for (int j = hef[topp[i]]; j; j = nef[j]) x = lca(x, verf[j]);//遍历所有入点，算出lca adda(x, topp[i]);//联边建树 d[topp[i]] = d[x] + 1; f[topp[i]][0] = x; for (int j = 1; j &lt;= 25; j++) f[topp[i]][j] = f[f[topp[i]][j-1]][j-1];//边建树便记录f数组} 此时hea系列数组记录的就是支配树信息。 最后我们dfs一下支配树，记录子树大小就可以了。 下面是完整ac代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;queue&gt;#include &lt;algorithm&gt;#include &lt;cmath&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;map&gt;#include &lt;cstdlib&gt;#define ll long longusing namespace std;const int N = 2e5+5;int tot, he[N], ver[N], ne[N];int hef[N], verf[N], nef[N];int tota, hea[N], vera[N], nea[N];int f[N][30], d[N];int di[N];int n,m, cnt, topp[N];queue&lt;int&gt; q;void add(int x, int y){ ver[++tot] = y; ne[tot] = he[x]; he[x] = tot; verf[tot] = x; nef[tot] = hef[y]; hef[y] = tot;}void adda(int x, int y){ vera[++tot] = y; nea[tot] = hea[x]; hea[x] = tot;}void topu(){ for (int i = 1; i &lt;= n; i++) if (!di[i]) q.push(i); while(q.size()) { int now = q.front(); q.pop(); topp[++cnt] = now; for (int i = he[now]; i; i = ne[i]) { int y = ver[i]; di[y]--; if (!di[y]) q.push(y); } }}int lca(int x, int y){ if (d[x] &gt; d[y]) swap(x, y); for (int i = 25; i &gt;= 0; i--) { if (d[f[y][i]] &lt; d[x]) continue; y = f[y][i]; } if (x == y) return x; for (int i = 25; i &gt;= 0; i--) if (f[x][i] != f[y][i]) x = f[x][i], y = f[y][i]; return f[x][0];}int siz[N];int dfs(int now){ siz[now] = 1; for (int i = hea[now]; i; i = nea[i]) { siz[now] += dfs(vera[i]); } return siz[now];}int main(){ scanf(\"%d\", &amp;n); for (int i = 1; i &lt;= n; i++) { int x; while(scanf(\"%d\", &amp;x), x) {di[i]++;add(x, i);} } topu(); for (int i = 1; i &lt;= n; i++) { int x = verf[hef[topp[i]]]; for (int j = hef[topp[i]]; j; j = nef[j]) x = lca(x, verf[j]); adda(x, topp[i]); d[topp[i]] = d[x] + 1; f[topp[i]][0] = x; for (int j = 1; j &lt;= 25; j++) f[topp[i]][j] = f[f[topp[i]][j-1]][j-1]; } dfs(0); for (int i = 1; i &lt;= n; i++) printf(\"%d\\n\", siz[i]-1); return 0;} 很好，我们现在探讨完DAG的情况了，终于进入最普遍的支配树的学习了。即：一般有向图的支配树与支配点（即必经点）。 下面有一个有向图： （蓝色边为其dfs搜索树的边，为方便每个点的编号都是它的dfn） 这里我引入半支配点的概念：对于图，若存在一个简单路径&lt;x,y&gt;。如果从x到y所经历的所有点（除了x，y）的时间戳都大于y的时间戳，我们认为x为y的半支配点 例如图中的6号点，他的半支配点集为V = {4，7，8，1}。因为从这些点出发都可以找到一个简单路径到达6，且满足上述条件（如图红边所示）： 对于每一个点，我们找到他的半支配点集中的dfn最小的一个，记做 然后对于每一个&lt;, &gt;连边。（如图红边所示） 为什么要这么做？因为我们如果把所有非搜索树的边删去，链接&lt;, &gt;，那么对于每个点，其支配性不变。而又因为，对于每个点，都是它搜索树上的祖先。 对于一个点找出所有的边中对应的 若 且比当前找到的的小 那么就用 若找打树上的一个祖先 并且比较同决定是否用前者更新后者。 这时，我们发现图变成了下面的样子： 没错，它变成了一个DAG。结合上述定理（支配性不变）。我直接按照DAG的支配树求法去求这个图的支配树。除此之外，但是我们有更好的办法。 对于一个点的最近支配点，我们记为，我们知道，如果求出这个玩意，然后对于每个点建边&lt;&gt;就是支配树了。。那么我们怎么求呢？ （摘自洛谷） 我们令是从到的搜索树上路径点集(不包括) 而且是中最小的点。如果那么否则就是。 我们标注出每个点的支配点（逗号后面）： 最后连边建成支配树： 万事大吉了。： 这里给出几个性质： 1、每个点的是唯一 的。 2、一个点的一定是其dfs树祖先。 3、x的半支配点不一定是x的支配点。 4、semi的深度大于idom的深度 5、如果节点U，V满足，V是U的祖先。那么：可以 得出V是的祖先，或者是的祖先。 P5180 【模板】支配树 下面是ac代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132// % everyone#include &lt;cstdio&gt;#include&lt;iostream&gt;#include&lt;cstring&gt;#include &lt;map&gt;#include &lt;queue&gt;#include &lt;set&gt;#include &lt;cstdlib&gt;#include &lt;cmath&gt;#include &lt;algorithm&gt;#include &lt;vector&gt;#include &lt;string&gt;#include &lt;list&gt;#include &lt;bitset&gt;#include &lt;array&gt;#include &lt;cctype&gt;#include &lt;unordered_map&gt;#include &lt;time.h&gt;namespace OI { double start_time = 0.0; void read_f(int flag = 0) { freopen(\"0.in\", \"r\", stdin); if(!flag) freopen(\"0.out\", \"w\", stdout); } void fast_cin() { std::ios::sync_with_stdio(false); std::cin.tie(); } void run_time() { std::cout &lt;&lt; \"\\nESC in : \" &lt;&lt; ( clock() - start_time ) * 1000.0 / CLOCKS_PER_SEC &lt;&lt; \"ms\" &lt;&lt; std::endl; } void ct() { start_time = clock(); return; }}using namespace OI;template &lt;typename T&gt;bool bacmp(const T &amp; a, const T &amp; b) { return a &gt; b; }template &lt;typename T&gt;bool pecmp(const T &amp; a, const T &amp; b) { return a &lt; b; }#define ll long long#define ull unsigned ll#define _min(x, y) ((x)&gt;(y)?(y):(x))#define _max(x, y) ((x)&gt;(y)?(x):(y))#define max3(x, y, z) ( max( (x), max( (y), (z) ) ) )#define min3(x, y, z) ( min( (x), min( (y), (z) ) ) )#define pr make_pair#define pb push_backusing namespace std;const int N = 2e5+5;int n, m;struct Node{ int tot = 0; int ver[N&lt;&lt;1], he[N], ne[N&lt;&lt;1]; void add(int x, int y) { ver[++tot] = y; ne[tot] = he[x]; he[x] = tot; }}a, b, c, d;int dfn[N], id[N], fa[N], cnt;void dfs(int u){ dfn[u] = ++cnt; id[cnt] = u; for (int i = a.he[u]; i; i = a.ne[i]) { int y = a.ver[i]; if (dfn[y]) continue; fa[y] = u; dfs(y); }}int semi[N], idom[N], bel[N], val[N];int fi(int x){ if (x == bel[x]) return x; int fs = fi(bel[x]); if (dfn[semi[ val[bel[x] ] ] ] &lt; dfn[ semi[val[x] ] ]) val[x] = val[bel[x]]; return bel[x] = fs;}void tarjan(){ for (int s = cnt; s&gt;1; s--) { int u = id[s]; for (int i = b.he[u]; i; i = b.ne[i]) { int y = b.ver[i]; fi(y); if (dfn[semi[val[y]]] &lt; dfn[semi[u]]) semi[u] = semi[val[y]]; } c.add(semi[u], u); bel[u] = fa[u]; u = fa[u]; for (int i = c.he[u]; i; i = c.ne[i]) { int y = c.ver[i]; fi(y); if (semi[val[y]] == u) idom[y] = u; else idom[y] = val[y]; } } for (int i = 2; i &lt;= cnt; i++) { int u = id[i]; if (idom[u] != semi[u]) idom[u] = idom[idom[u]]; }}int ans[N];void dfs_ans(int u){ ans[u] = 1; for (int i = d.he[u]; i; i = d.ne[i]) { int y = d.ver[i]; dfs_ans(y); ans[u] += ans[y]; }}int main(){ scanf(\"%d%d\", &amp;n, &amp;m); for (int i = 1; i &lt;= m; i++) { int x, y; scanf(\"%d%d\", &amp;x, &amp;y); a.add(x, y); b.add(y, x); } for (int i = 1; i &lt;= n; i++) semi[i] = bel[i] = val[i] = i; dfs(1); tarjan(); for (int i = 2; i &lt;= n; i++) d.add(idom[i], i); dfs_ans(1); for (int i = 1; i &lt;= n; i++) printf(\"%d \", ans[i]); puts(\"\"); return 0;}","categories":[{"name":"算法竞赛","slug":"算法竞赛","permalink":"http://kalzncc.github.io/categories/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B/"}],"tags":[{"name":"ICPC","slug":"ICPC","permalink":"http://kalzncc.github.io/tags/ICPC/"},{"name":"图论","slug":"图论","permalink":"http://kalzncc.github.io/tags/%E5%9B%BE%E8%AE%BA/"}]},{"title":"FFT前置知识及FFT\\FFT分治","slug":"104524783","date":"2020-02-26T14:35:08.000Z","updated":"2024-11-27T03:53:07.162Z","comments":true,"path":"2020/02/26/104524783/","link":"","permalink":"http://kalzncc.github.io/2020/02/26/104524783/","excerpt":"","text":"首先依次介绍FFT(快速傅里叶变换)前置知识: 复数及单位根 复变函数欧拉定理 单位根三大引理 多项式的系数与点值表示法 多项式的求值与插值(顺介绍拉格朗日插值法) 向量卷积 复数及单位根 我们知道复数可以写成,其中为实部,为虚部.而且一个复数可以在一个复平面上表示出来,而我们可以将其写成极坐标的形式而根据欧拉定理: 则有:,这里给出乘法的例子: 下面介绍单位根: 如果存在复数,则其根被称作单位根,显然单位根的模为1,其中我们定义单位根: 其中定义主n次单位根(当k==1时): 而在程序中我们一般写成三角函数形式: 这里给出复数运算模板代码: 123456789101112struct Complex{ double r, i; Complex() {}//无参函数不要写东西!易超时 Complex(double r, double i) :r(r), i(i) {}}f[N], g[N];Complex operator + (const Complex &amp; a, const Complex &amp; b){return Complex(a.r + b.r, a.i + b.i);}Complex operator - (const Complex &amp; a, const Complex &amp; b){return Complex(a.r - b.r, a.i - b.i);}Complex operator * (const Complex &amp; a, const Complex &amp; b) 下面给出单位根的三大引理 多项式的两种表示方法: 第一种非常常见的系数表示法,及,,另外我们给出另一种表示方法,点值表示法,及用n+1种不同的取值代入,组成的集合: 我们分析两种表示方法: 系数表达式: 求值:我们可以使用秦九昭算法得出, 求和:两个表达式的各项系数相加,是的 求积:一个表达式相乘的各项都需要和另一个的各项相乘,是的 点值表达式: 求值:我们使用拉格朗日插值法可以在的出系数表达式并求值(插值的定义一会给出) 这里给出拉格朗日插值法的公式(n项表达式): 并有模板: P4781 【模板】拉格朗日插值 下面是模板代码: 123456789101112131415161718192021222324252627282930313233343536const int N = 2e3+5;const ll mod = 998244353;ll a[N], b[N];ll inv(ll a, ll b){ ll res = 1; while(b) { if (b&amp;1) res = res * a % mod; b &gt;&gt;= 1; a = a * a % mod; } return res % mod;}int main(){ int n; ll k; cin &gt;&gt; n &gt;&gt; k; for (int i = 1; i &lt;= n; i++) scanf(\"%d%d\", &amp;a[i], &amp;b[i]); ll sum = 0; for (int i = 1; i &lt;= n; i++) { ll ans = b[i]; ll fa = 1, fb = 1; for (int j = 1; j &lt;= n; j++) { if (j == i) continue; fa = (fa * (k - a[j] + mod)%mod)%mod; fb = (fb * (a[i] - a[j] + mod)%mod)%mod; } ans = (ans * fa % mod * inv(fb, mod-2)%mod)%mod; sum = (sum + ans)%mod; } printf(\"%lld\\n\", sum);} 求和:两个表达式的各项点值的值相加,是的 求积:两个表达式的各项点值的值相乘,是的 我们不难发现,如果我们相求两个多项式的积(系数向量分别是),在点值表达式的情况下将十分高效.这时新表达式(系数向量是c)的第i项系数为: 我们则称为的卷积,记作,两个多项式相乘,就是对应的两个系数向量的卷积, 我们将一个点值表达式转化为系数表达式称为插值. 由此可见:如何提高多项式求值与插值的效率.决定着两个表达式相乘的效率! 话讲完,正式下面介绍FFT 首先看DFT(离散傅里叶变换) 我们将单位根带入到系数表达式(方便起见下式中用替代)中: 记作 每次求值为所以离散傅里叶变换最终时间复杂度为 这样显然是不行的,毕竟直接相乘的时间复杂度都是 然后就有了FFT: 我们对于一个n项系数表达式(n为2的幂数): 可以分成: 这时我们发现一个及其有趣的事实: 而根据(1),(2)两个引理:我们最终有: $$ { . $$ 于是问题得以递归解决: 时间复杂度为 ###### 逆FFT 我们的多项式不可以FFT过去弄不过来了!比较简单, 因为: 所以: 证明略,总之就是证明原向量矩阵可逆 所以我们稍加改动就可以逆FFT,就是将单位根的指数取相反数,最后结果再乘1/n 所以两个多项式的乘积,使其对应系数向量的卷积!可以有: 不过我们很少书写递归代码,这里使用迭代写法; 这里还牵扯到两个点:位逆序置换 蝴蝶操作,不说了...直接上代码吧 P3803 【模板】多项式乘法（FFT） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960const int N = 3e6+5;const double pi = acos(-1);struct Complex{ double r, i; Complex() {} Complex(double r, double i) :r(r), i(i) {}}f[N], g[N];Complex operator + (const Complex &amp; a, const Complex &amp; b){return Complex(a.r + b.r, a.i + b.i);}Complex operator - (const Complex &amp; a, const Complex &amp; b){return Complex(a.r - b.r, a.i - b.i);}Complex operator * (const Complex &amp; a, const Complex &amp; b){return Complex(a.r * b.r - a.i * b.i, a.i * b.r + a.r * b.i);}int rev[N];int len, lim = 1;void init(int n){ while(lim &lt;= n) lim &lt;&lt;= 1, len++; for (int i = 0; i &lt; lim; i++) rev[i] = (rev[i &gt;&gt; 1] &gt;&gt; 1) | ((i &amp; 1) &lt;&lt; (len-1));}void FFT(Complex *a, int op)//op为1是FFT运算,-1是FFT逆运算{ for (int i = 0; i &lt; lim; i++) if (i &lt; rev[i]) swap(a[i], a[rev[i]]); for (int dep = 1; dep &lt;= log2(lim); dep++) { int m = 1 &lt;&lt; dep; Complex wn = Complex(cos(2.0 * pi / m), op * sin(2.0 * pi / m)); for (int k = 0; k &lt; lim; k += m) { Complex w = Complex(1, 0); for (int j = 0; j &lt; m / 2; j++) { Complex t = w * a[k + j + m / 2]; Complex u = a[k + j]; a[k + j] = u + t; a[k + j + m / 2] = u - t; w = w * wn; } } } if (op == -1) for (int i = 0; i &lt; lim; i++) a[i].r /= lim;}int main(){ int n, m; cin &gt;&gt; n &gt;&gt; m; init(n + m); for (int i = 0; i &lt;= n; i++) scanf(\"%lf\", &amp;f[i].r); for (int i = 0; i &lt;= m; i++) scanf(\"%lf\", &amp;g[i].r); FFT(g, 1); FFT(f, 1); for (int i = 0; i &lt;= lim; i++) f[i] = f[i] * g[i]; FFT(f, -1); for (int i = 0; i &lt;= n + m; i++) printf(\"%d \", (int)(f[i].r + 0.5)); return 0;} FFT分治 【模板】分治 FFT 根据cdq分治思想, 我们在计算多项式的一个系数的时候，要统计之前的所有影响。我们区间折半递归解决，先解决左区间的数值，然后统计其对右区间的影响，累加到右区间。 洛谷模板需要取模，故模板代码使用NTT，值得注意的是，洛谷模板的模数998244353，符合NTT所要求的素数类型，且存在原根为3。 下面是模板代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859const int N = 1e6+5;const int G = 3;const ll mod = 998244353;ll f[N], g[N];ll a[N], b[N];int rev[N], n;int len, lim = 1;void init(int n){ lim = 1; len = 0; while(lim &lt;= n) lim &lt;&lt;= 1, len++; for (int i = 0; i &lt; lim; i++) rev[i] = (rev[i &gt;&gt; 1] &gt;&gt; 1) | ((i &amp; 1) &lt;&lt; (len-1));}ll _pow(ll a, ll b) { //....}inline void calcrev(int logn){ rev[0]=0; for(int i = 1; i &lt; (1 &lt;&lt; logn); i++) rev[i]=(rev[i&gt;&gt;1]&gt;&gt;1)|((i&amp;1)&lt;&lt;(logn-1));}void NTT(ll *a, int led, int op)//op为1是FFT运算,-1是FFT逆运算{ int lim = 1 &lt;&lt; led; //......}void cdq_fft(int l, int r, int logn){ if (logn &lt;= 0) return ; if (l &gt;= n) return ; int mid = (l + r) &gt;&gt; 1; ll t = _pow(r - l, mod-2); cdq_fft(l, mid, logn - 1); calcrev(logn); memset(a + (r - l) / 2, 0, sizeof(ll) * (r - l) / 2); memcpy(a, f+l, sizeof(ll) * (r - l) / 2); memcpy(b, g, sizeof(ll) * (r - l) ); NTT(a, logn, 1); NTT(b, logn, 1); for (int i = 0; i &lt; r - l; i++) a[i] = a[i] * b[i] % mod; NTT(a, logn, -1); for (int i = (r - l) / 2; i &lt; r - l; i++) f[l + i] = (f[l+i] + a[i]) % mod; cdq_fft(mid, r, logn-1);}int main(){ cin &gt;&gt; n; init(n); for (int i = 1; i &lt; n; i++) scanf(\"%lld\", &amp;g[i]); f[0] = 1; cdq_fft(0, lim, len); for (int i = 0; i &lt; n; i++) printf(\"%lld \", (f[i] + mod) % mod); puts(\"\"); return 0;}","categories":[{"name":"算法竞赛","slug":"算法竞赛","permalink":"http://kalzncc.github.io/categories/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B/"}],"tags":[{"name":"ICPC","slug":"ICPC","permalink":"http://kalzncc.github.io/tags/ICPC/"},{"name":"数论","slug":"数论","permalink":"http://kalzncc.github.io/tags/%E6%95%B0%E8%AE%BA/"}]}],"categories":[{"name":"项目","slug":"项目","permalink":"http://kalzncc.github.io/categories/%E9%A1%B9%E7%9B%AE/"},{"name":"八股","slug":"八股","permalink":"http://kalzncc.github.io/categories/%E5%85%AB%E8%82%A1/"},{"name":"杂文","slug":"杂文","permalink":"http://kalzncc.github.io/categories/%E6%9D%82%E6%96%87/"},{"name":"AI","slug":"AI","permalink":"http://kalzncc.github.io/categories/AI/"},{"name":"博客改造","slug":"博客改造","permalink":"http://kalzncc.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%94%B9%E9%80%A0/"},{"name":"算法竞赛","slug":"算法竞赛","permalink":"http://kalzncc.github.io/categories/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B/"},{"name":"工程","slug":"工程","permalink":"http://kalzncc.github.io/categories/%E5%B7%A5%E7%A8%8B/"}],"tags":[{"name":"置顶","slug":"置顶","permalink":"http://kalzncc.github.io/tags/%E7%BD%AE%E9%A1%B6/"},{"name":"工具","slug":"工具","permalink":"http://kalzncc.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"八股","slug":"八股","permalink":"http://kalzncc.github.io/tags/%E5%85%AB%E8%82%A1/"},{"name":"总结","slug":"总结","permalink":"http://kalzncc.github.io/tags/%E6%80%BB%E7%BB%93/"},{"name":"机器学习","slug":"机器学习","permalink":"http://kalzncc.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"python","slug":"python","permalink":"http://kalzncc.github.io/tags/python/"},{"name":"博客","slug":"博客","permalink":"http://kalzncc.github.io/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"蓝桥","slug":"蓝桥","permalink":"http://kalzncc.github.io/tags/%E8%93%9D%E6%A1%A5/"},{"name":"ICPC","slug":"ICPC","permalink":"http://kalzncc.github.io/tags/ICPC/"},{"name":"数据结构","slug":"数据结构","permalink":"http://kalzncc.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"oj","slug":"oj","permalink":"http://kalzncc.github.io/tags/oj/"},{"name":"图论","slug":"图论","permalink":"http://kalzncc.github.io/tags/%E5%9B%BE%E8%AE%BA/"},{"name":"数论","slug":"数论","permalink":"http://kalzncc.github.io/tags/%E6%95%B0%E8%AE%BA/"}]}